{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6066205d-d0c7-4987-8de3-2eaef38061d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** 开始处理SaoPaulo的数据 ********************\n",
      "---------- 读取SaoPaulo原数据 ----------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "废弃！！！！\n",
    "这个CurLink是尝试在train_test_split_edges_m中考虑新产生的社交链接，让负样本不包含新链接\n",
    "该方法不科学，但可能会有更好的效果\n",
    "\"\"\"\n",
    "# 为了方便GAT训练，这里把用户的id都-1，让id从0开始\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling,to_undirected\n",
    "import heapq\n",
    "import random\n",
    "from GATmodel import GATNet\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# 转换lable\n",
    "def get_link_labels(pos_edge_index, neg_edge_index):\n",
    "    num_links = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
    "    link_labels = torch.zeros(num_links, dtype=torch.float)\n",
    "    link_labels[:pos_edge_index.size(1)] = 1.\n",
    "    return link_labels\n",
    "\n",
    "# 读取数据\n",
    "def get_data(city):\n",
    "    with open('data_proces/'+ city +'data_heterHyper.pickle', 'rb') as file:\n",
    "        data_social = pickle.load(file)\n",
    "\n",
    "    friendship_new_df = data_social['friendship_new_df']\n",
    "    friendship_old_df = data_social['friendship_old_df']\n",
    "    checkins_df = data_social['checkins_df']\n",
    "    All_N_O_list_list = data_social['All_N_O_list_list']\n",
    "    All_O_N_list_list = data_social['All_O_N_list_list']\n",
    "    hyperBip_id_vec_list = data_social['hyperBip_id_vec_list']\n",
    "    social_id_vec_list = data_social['social_id_vec_list']\n",
    "    HeterHyper_id_vec_list = data_social['HeterHyper_id_vec_list']\n",
    "\n",
    "    # 为了方便GAT训练，这里把用户的id都-1，让id从0开始\n",
    "    hyperBip_id_vec_list.pop(0)\n",
    "    social_id_vec_list.pop(0)\n",
    "    HeterHyper_id_vec_list.pop(0)\n",
    "    for ii in range(len(friendship_old_df)):\n",
    "        friendship_old_df['uid1'][ii] -= 1\n",
    "        friendship_old_df['uid2'][ii] -= 1\n",
    "    for ii in range(len(friendship_new_df)):\n",
    "        friendship_new_df['uid1'][ii] -= 1\n",
    "        friendship_new_df['uid2'][ii] -= 1\n",
    "\n",
    "    return friendship_new_df, friendship_old_df, checkins_df, All_N_O_list_list, All_O_N_list_list, hyperBip_id_vec_list, social_id_vec_list, HeterHyper_id_vec_list\n",
    "\n",
    "# GAT训练函数\n",
    "def train(data, model, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    # 进行节点负采样 正负样本1:nn\n",
    "    nn = 10\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=data.edge_index,\n",
    "        num_nodes=data.num_nodes,\n",
    "        num_neg_samples=data.train_pos_edge_index.size(1) * nn)\n",
    "\n",
    "    # train_neg_edge_set = set(map(tuple, neg_edge_index.T.tolist()))\n",
    "    # val_pos_edge_set = set(map(tuple, data.val_pos_edge_index.T.tolist()))\n",
    "    # test_pos_edge_set = set(map(tuple, data.test_pos_edge_index.T.tolist()))\n",
    "    #     if (len(train_neg_edge_set & val_pos_edge_set) > 0) or (len(train_neg_edge_set & test_pos_edge_set) > 0):\n",
    "    #         # 训练集负样本与验证集负样本存在交集，或训练集负样本与测试集负样本存在交集\n",
    "    #         print('wrong!')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.train_pos_edge_index)\n",
    "    link_logits = model.decode(z, data.train_pos_edge_index, neg_edge_index)\n",
    "    link_labels = get_link_labels(data.train_pos_edge_index, neg_edge_index).to(data.x.device)\n",
    "    loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "# 课程学习的训练函数\n",
    "def train_diff(data, model, optimizer, nowDiff):\n",
    "    model.train()\n",
    "\n",
    "    # 进行节点负采样 正负样本1:nn\n",
    "    nn = 10\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=data.edge_index,\n",
    "        num_nodes=data.num_nodes,\n",
    "        num_neg_samples=data.train_Diff_pos_edge_index[nowDiff].size(1) * nn)\n",
    "\n",
    "    # num_neg_samples = data.train_Diff_pos_edge_index[nowDiff].size(1) * nn #采样个数\n",
    "    # neg_row, neg_col = data.train_neg_edge_index\n",
    "    # perm = torch.randperm(neg_row.size(0))\n",
    "    # neg_row, neg_col = neg_row[perm][:num_neg_samples], neg_col[perm][:num_neg_samples]\n",
    "    # neg_edge_index = torch.stack([neg_row, neg_col], dim=0)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.train_Diff_pos_edge_index[nowDiff])\n",
    "    link_logits = model.decode(z, data.train_Diff_pos_edge_index[nowDiff], neg_edge_index)\n",
    "    link_labels = get_link_labels(data.train_Diff_pos_edge_index[nowDiff], neg_edge_index).to(data.x.device)\n",
    "    loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "# 定义单个epoch验证过程\n",
    "@torch.no_grad()\n",
    "def val(data, model):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.train_pos_edge_index)\n",
    "\n",
    "    prefix = 'val'\n",
    "    pos_edge_index = data[f'{prefix}_pos_edge_index']\n",
    "    neg_edge_index = data[f'{prefix}_neg_edge_index']\n",
    "    link_logits = model.decode(z, pos_edge_index, neg_edge_index)\n",
    "    link_probs = link_logits.sigmoid()\n",
    "    link_labels = get_link_labels(pos_edge_index, neg_edge_index)\n",
    "    return roc_auc_score(link_labels.cpu(), link_probs.cpu())\n",
    "\n",
    "# # 余弦距离\n",
    "# def countCos(x, y):\n",
    "#     return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "\n",
    "# 计算余弦相似度\n",
    "def cosinematrix(A):\n",
    "    prod = torch.mm(A, A.t())  # 分子\n",
    "    norm = torch.norm(A, p=2, dim=1).unsqueeze(0)  # 分母\n",
    "    cos = prod.div(torch.mm(norm.t(), norm))\n",
    "    return cos\n",
    "\n",
    "# 计算sigmoid\n",
    "def countSigmoid(x_list):\n",
    "    sig_x = []\n",
    "    for x in x_list:\n",
    "        sig_x.append(1 / (1 + math.exp(-x)))\n",
    "    return sig_x\n",
    "\n",
    "# 用来给数据分训练集验证集(测试集用新的社交链接）\n",
    "def train_test_split_edges_m(data, val_ratio, neg_candidates_num):\n",
    "    \"\"\"\n",
    "    val_ratio:验证集比例\n",
    "    test_ratio：测试集比例\n",
    "    val_neg_ratio:验证集负样本比例\n",
    "    test_neg_candidates_num：测试集负样本数量（SOTA为50）\n",
    "    \"\"\"\n",
    "    num_nodes = data.num_nodes\n",
    "    row, col = data.edge_index\n",
    "    row_all, col_all = data.edge_new_index # 新旧社交链接\n",
    "    mask = row < col\n",
    "    row, col = row[mask], col[mask]\n",
    "    n_v = int(math.floor(val_ratio * row.size(0)))\n",
    "\n",
    "    # Positive edges.\n",
    "    perm = torch.randperm(row.size(0))\n",
    "    row, col = row[perm], col[perm]\n",
    "\n",
    "    r, c = row[:n_v], col[:n_v]\n",
    "    data.val_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "\n",
    "    r, c = row[n_v :], col[n_v :]\n",
    "    data.train_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "    data.train_pos_edge_index = to_undirected(data.train_pos_edge_index)\n",
    "\n",
    "    # Negative edges.\n",
    "    neg_adj_mask = torch.ones(num_nodes, num_nodes, dtype=torch.uint8)\n",
    "    neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)\n",
    "    neg_adj_mask[row_all, col_all] = 0\n",
    "\n",
    "    neg_row, neg_col = neg_adj_mask.nonzero(as_tuple=False).t()\n",
    "    perm = torch.randperm(neg_row.size(0))\n",
    "    neg_row, neg_col = neg_row[perm], neg_col[perm]\n",
    "    # data.train_neg_edge_index = torch.stack([neg_row, neg_col], dim=0) # 训练负采样的样本\n",
    "\n",
    "    neg_adj_mask[neg_row, neg_col] = 0\n",
    "    data.train_neg_adj_mask = neg_adj_mask\n",
    "\n",
    "    \"\"\"\n",
    "    采样验证集的负样本 按照负样本的候选用户数量进行采样\n",
    "    \"\"\"\n",
    "    val_user_list = list(set(data.val_pos_edge_index[0]) | set(data.val_pos_edge_index[1]))  # 先得到test中的用户list\n",
    "\n",
    "    # 只有val中的节点未连接的为1\n",
    "    neg_adj_mask = torch.zeros(num_nodes, num_nodes, dtype=torch.uint8)\n",
    "    neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)\n",
    "    for ii in range(len(val_user_list)):\n",
    "        for jj in range(len(val_user_list)):\n",
    "            if (jj <= ii): continue\n",
    "            neg_adj_mask[val_user_list[ii]][val_user_list[jj]] = 1\n",
    "            neg_adj_mask[val_user_list[jj]][val_user_list[ii]] = 1\n",
    "    row, col = data.val_pos_edge_index\n",
    "    neg_adj_mask[row, col] = 0  # val中有连接的为0\n",
    "    neg_row, neg_col = neg_adj_mask.nonzero(as_tuple=False).t()\n",
    "    perm = torch.randperm(neg_row.size(0))\n",
    "    neg_row, neg_col = neg_row[perm], neg_col[perm]\n",
    "\n",
    "    # 随机采样，大概是每个用户取test_neg_candidates_num(50)个候选\n",
    "    row = neg_row[:n_v * neg_candidates_num]\n",
    "    col = neg_col[:n_v * neg_candidates_num]\n",
    "    data.val_neg_edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    return data\n",
    "\n",
    "# 用来给数据进行难度分级\n",
    "def train_Diff_split_edges(data, node_diff_list, NUM_diff_leve):\n",
    "    num_nodes = data.num_nodes\n",
    "    row, col = data.train_pos_edge_index\n",
    "\n",
    "    data.train_Diff_pos_edge_index = []\n",
    "    for i in range(NUM_diff_leve):\n",
    "        data.train_Diff_pos_edge_index.append([[], []])  # 每一个难度等级有一对列表\n",
    "\n",
    "    for e1, e2 in zip(row, col):\n",
    "        # 假设GAT里边的方向是(a,b) a->b\n",
    "        diff_index = node_diff_list.index(int(e2))\n",
    "        now_node_diff = int(diff_index * NUM_diff_leve / num_nodes)\n",
    "\n",
    "        for ii in range(now_node_diff, NUM_diff_leve): # 大于等于该难度等级的课程都有该节点数据\n",
    "            data.train_Diff_pos_edge_index[ii][0].append(e1)\n",
    "            data.train_Diff_pos_edge_index[ii][1].append(e2)\n",
    "\n",
    "\n",
    "    for i in range(NUM_diff_leve):\n",
    "        data.train_Diff_pos_edge_index[i] = torch.tensor(data.train_Diff_pos_edge_index[i], dtype=torch.long)\n",
    "    return data\n",
    "\n",
    "# 计算count_o2n_Acc_Recall中需要的link_new_labels_M，目的是为了保证计算各方法的结果时负采样一致\n",
    "def count_link_lables(num_user, friendship_new_df, friendship_old_df,neg_num):\n",
    "    # # 社交网络邻接矩阵 考虑id从1开始\n",
    "    link_new_labels_M = np.zeros((num_user, num_user))\n",
    "    for uid1, uid2 in zip(friendship_new_df['uid1'], friendship_new_df['uid2']):\n",
    "        link_new_labels_M[uid1][uid2] = 1\n",
    "        link_new_labels_M[uid2][uid1] = 1\n",
    "    # 旧社交网络邻接矩阵\n",
    "    for uid1, uid2 in zip(friendship_old_df['uid1'], friendship_old_df['uid2']):\n",
    "        link_new_labels_M[uid1][uid2] = 2  # 原new的社交链接中实际上是old+新增的社交链接，所以这里将新增社交链接中的旧链接去掉，防止影响后面预测（特别是召回率分母）\n",
    "        link_new_labels_M[uid2][uid1] = 2\n",
    "    # # 进行负采样，只让采样上的为3，其他为0\n",
    "    # for link_u_new_l in link_new_labels_M:\n",
    "    #     tensor_link_u_new_l = torch.tensor(link_u_new_l)\n",
    "    #     pre_ind = torch.eq(tensor_link_u_new_l, 0).nonzero().numpy().tolist()\n",
    "    #     for preI in random.sample(pre_ind, neg_num):# 负样本随机抽取neg_num(50)个\n",
    "    #         link_u_new_l[preI[0]] = 3\n",
    "    return link_new_labels_M\n",
    "\n",
    "# 计算accuracy，recall计算,考虑旧的社交链接问题\n",
    "def count_o2n_Acc_Recall(K, prob_adj, link_new_labels_M):\n",
    "    P_K_list = []\n",
    "    R_K_list = []\n",
    "    # 计算精确度和召回率\n",
    "\n",
    "    # 对每个user进行计算  这是以前的计算方法，目的是仅采样一部分负样本\n",
    "    prob_adj = prob_adj.detach().numpy()\n",
    "    for link_u_p, link_u_new_l in zip(prob_adj, link_new_labels_M):\n",
    "        # 只对正样本和抽取的负样本进行预测\n",
    "        tensor_link_u_new_l = torch.tensor(link_u_new_l)\n",
    "        pre_ind = torch.eq(tensor_link_u_new_l, 1).nonzero().numpy().tolist()\n",
    "        for preI in pre_ind:\n",
    "            link_u_p[preI[0]] += 1000  # 正样本全参与预测\n",
    "        pre_ind = torch.eq(tensor_link_u_new_l, 0).nonzero().numpy().tolist()\n",
    "        for preI in pre_ind:\n",
    "            link_u_p[preI[0]] += 1000  # 抽取的负样本参与预测\n",
    "\n",
    "        link_u_p = list(link_u_p)  # ndarray 转 list\n",
    "        link_u_l = list(link_u_new_l)\n",
    "        num_1 = list(link_u_l).count(1)  # 该用户新增的链接个数\n",
    "        if (num_1 < 1):\n",
    "            continue\n",
    "        max_num_index_list = list(map(link_u_p.index, heapq.nlargest(K, link_u_p)))\n",
    "        N_u_true = 0\n",
    "        for index in max_num_index_list:\n",
    "            if link_u_l[index] == 1:\n",
    "                N_u_true += 1\n",
    "\n",
    "        P_K_list.append(N_u_true / K)\n",
    "        R_K_list.append(N_u_true / num_1)\n",
    "\n",
    "#     # 在全局中进行预测\n",
    "#     for link_u_p, link_u_new_l in zip(prob_adj, link_new_labels_M):\n",
    "#         link_u_l = list(link_u_new_l)\n",
    "#         num_1 = link_u_l.count(1)  # 计算一下该用户应该有的链接数\n",
    "#         if num_1 == 0:  # 该用户没有新的社交链接 则跳过\n",
    "#             continue\n",
    "#         # 只对正样本和抽取的负样本进行预测\n",
    "#         sort_enu = sorted(enumerate(link_u_p.detach().numpy()), key=lambda link_u_p: link_u_p[1], reverse=True)\n",
    "#         sort_index = [x[0] for x in sort_enu]  # 得到从大到小排序后的坐标\n",
    "    \n",
    "#         tmpK = 0\n",
    "#         N_u_true = 0\n",
    "#         for index in sort_index:\n",
    "#             if link_u_new_l[index] == 2: #旧的社交链接不参与预测\n",
    "#                 continue\n",
    "#             if link_u_new_l[index] == 1:\n",
    "#                 N_u_true += 1\n",
    "#             tmpK += 1\n",
    "#             if tmpK == K:\n",
    "#                 break\n",
    "    \n",
    "#         P_K_list.append(N_u_true / K)\n",
    "#         R_K_list.append(N_u_true / num_1)\n",
    "\n",
    "    P_ = sum(P_K_list) / len(P_K_list)\n",
    "    R_ = sum(R_K_list) / len(R_K_list)\n",
    "    if P_ + R_ != 0:\n",
    "        F1_ = 2 * (P_ * R_) / (P_ + R_)\n",
    "    else:\n",
    "        F1_ = 0\n",
    "\n",
    "    return P_, R_, F1_\n",
    "\n",
    "# 计算节点难度 返回的是按节点难度从小到大排序的节点id\n",
    "def count_diff_of_nodes(num_u, R_ball, userVec, friendship_df):\n",
    "    # 计算各节点间距离  节点id从0开始\n",
    "    disCos_M = 1 - cosinematrix(torch.tensor(np.array(userVec)))\n",
    "    for i in range(len(disCos_M)):\n",
    "        disCos_M[i][i] = 3 # 自己和自己的余弦距离大一点\n",
    "    disCos_M_minR_mask = disCos_M < R_ball\n",
    "    disCos_M_minR_mask = disCos_M_minR_mask.detach().numpy()\n",
    "\n",
    "    # 存储是否有链接的矩阵\n",
    "    SN_link_M = np.zeros((num_u, num_u))\n",
    "    for e1, e2 in zip(friendship_df['uid1'], friendship_df['uid2']):\n",
    "        SN_link_M[e1][e2] = 1\n",
    "        SN_link_M[e2][e1] = 1\n",
    "\n",
    "    diff_node_list = []  # 节点的计算难度\n",
    "    num_inBall_list = []\n",
    "    for index_ii in range(num_u):\n",
    "        count_num = 0  # 计算球体内节点总数\n",
    "        count_inR_link = 0  # 计算球体内有链接的节点数\n",
    "        for index_jj in range(num_u):\n",
    "            if disCos_M_minR_mask[index_ii][index_jj]:\n",
    "                count_num += 1\n",
    "                if SN_link_M[index_ii][index_jj] == 1:\n",
    "                    count_inR_link += 1\n",
    "        count_diff = 0\n",
    "        if (count_num > 0):\n",
    "            count_diff = count_inR_link / count_num\n",
    "        diff_node_list.append(1 - count_diff)  # 数字越大难度越大\n",
    "        num_inBall_list.append(count_num)  ##\n",
    "\n",
    "    node_And_diff_list = [(i, diff_node_list[i]) for i in range(num_u)]\n",
    "    node_And_diff_list.sort(key=lambda x: x[1])\n",
    "    node_diffASC_list = [node_And_diff_list[i][0] for i in range(num_u)]\n",
    "\n",
    "    # print(\"半径内平均个节点数：\", sum(num_inBall_list) / len(num_inBall_list))\n",
    "    # print(\"平均学习难度：\", sum(diff_node_list) / len(diff_node_list))\n",
    "    return node_diffASC_list\n",
    "\n",
    "# 绘制曲线的函数\n",
    "def drawLossVal(x,y,labelName,picName,x_lable,y_lable):\n",
    "    fig, ax_loss = plt.subplots(figsize=(12, 7))\n",
    "    # 绘制曲线\n",
    "    ax_loss.plot(x, y, \"r-\", linewidth=2.0, label=labelName)\n",
    "    # 添加样式\n",
    "    ax_loss.set_title(picName, fontdict={\"fontsize\": 25})  # 标题\n",
    "    ax_loss.set_xlabel(x_lable)  # 添加横轴标签\n",
    "    ax_loss.set_ylabel(y_lable)  # 添加纵轴标签\n",
    "    ax_loss.legend(loc=\"best\", fontsize=16)  # 展示图例\n",
    "    plt.grid(True)\n",
    "\n",
    "city = \"SaoPaulo\"\n",
    "print(\"*\" * 20, \"开始处理\" + city + \"的数据\", \"*\" * 20)\n",
    "# 读取数据\n",
    "print(\"-\" * 10, \"读取\" + city + \"原数据\", \"-\" * 10)\n",
    "# 读取的是已经重新编排ID的数据，且id从0开始\n",
    "friendship_new_df, friendship_old_df, checkins_df, All_N_O_list_list, All_O_N_list_list, hyperBip_id_vec_list, \\\n",
    "social_id_vec_list, HeterHyper_id_vec_list = get_data(city)\n",
    "\n",
    "num_u = len(All_N_O_list_list[0]) - 1  # 用户数量 -1因为考虑了id从0开始\n",
    "link_new_labels_M = count_link_lables(num_u, friendship_new_df, friendship_old_df, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0026b7-61cf-4b70-86d6-df0c574782fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 仅GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9b80a504-0646-4051-a5fa-59abdad0c77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 22.0439, Val: 0.5380\n",
      "Epoch: 002, Loss: 7.4188, Val: 0.5805\n",
      "Epoch: 003, Loss: 2.4605, Val: 0.5931\n",
      "Epoch: 004, Loss: 2.3064, Val: 0.5769\n",
      "Epoch: 005, Loss: 3.0687, Val: 0.5700\n",
      "Epoch: 006, Loss: 3.2775, Val: 0.5707\n",
      "Epoch: 007, Loss: 2.9263, Val: 0.5807\n",
      "Epoch: 008, Loss: 2.3814, Val: 0.5965\n",
      "Epoch: 009, Loss: 1.8780, Val: 0.6060\n",
      "Epoch: 010, Loss: 1.5500, Val: 0.6046\n",
      "Epoch: 011, Loss: 1.3854, Val: 0.6028\n",
      "Epoch: 012, Loss: 1.3292, Val: 0.6042\n",
      "Epoch: 013, Loss: 1.3041, Val: 0.6085\n",
      "Epoch: 014, Loss: 1.2443, Val: 0.6117\n",
      "Epoch: 015, Loss: 1.1480, Val: 0.6158\n",
      "Epoch: 016, Loss: 1.0421, Val: 0.6191\n",
      "Epoch: 017, Loss: 0.9552, Val: 0.6215\n",
      "Epoch: 018, Loss: 0.8990, Val: 0.6234\n",
      "Epoch: 019, Loss: 0.8709, Val: 0.6244\n",
      "Epoch: 020, Loss: 0.8601, Val: 0.6243\n",
      "Epoch: 021, Loss: 0.8572, Val: 0.6231\n",
      "Epoch: 022, Loss: 0.8547, Val: 0.6219\n",
      "Epoch: 023, Loss: 0.8489, Val: 0.6214\n",
      "Epoch: 024, Loss: 0.8420, Val: 0.6222\n",
      "Epoch: 025, Loss: 0.8334, Val: 0.6237\n",
      "Epoch: 026, Loss: 0.8225, Val: 0.6264\n",
      "Epoch: 027, Loss: 0.8101, Val: 0.6303\n",
      "Epoch: 028, Loss: 0.7946, Val: 0.6338\n",
      "Epoch: 029, Loss: 0.7799, Val: 0.6373\n",
      "Epoch: 030, Loss: 0.7660, Val: 0.6392\n",
      "Epoch: 031, Loss: 0.7553, Val: 0.6396\n",
      "Epoch: 032, Loss: 0.7474, Val: 0.6396\n",
      "Epoch: 033, Loss: 0.7414, Val: 0.6396\n",
      "Epoch: 034, Loss: 0.7362, Val: 0.6398\n",
      "Epoch: 035, Loss: 0.7308, Val: 0.6397\n",
      "Epoch: 036, Loss: 0.7255, Val: 0.6395\n",
      "Epoch: 037, Loss: 0.7191, Val: 0.6399\n",
      "Epoch: 038, Loss: 0.7137, Val: 0.6410\n",
      "Epoch: 039, Loss: 0.7093, Val: 0.6424\n",
      "Epoch: 040, Loss: 0.7062, Val: 0.6437\n",
      "Epoch: 041, Loss: 0.7046, Val: 0.6450\n",
      "Epoch: 042, Loss: 0.7036, Val: 0.6463\n",
      "Epoch: 043, Loss: 0.7029, Val: 0.6476\n",
      "Epoch: 044, Loss: 0.7026, Val: 0.6490\n",
      "Epoch: 045, Loss: 0.7022, Val: 0.6504\n",
      "Epoch: 046, Loss: 0.7010, Val: 0.6518\n",
      "Epoch: 047, Loss: 0.7001, Val: 0.6526\n",
      "Epoch: 048, Loss: 0.6990, Val: 0.6527\n",
      "Epoch: 049, Loss: 0.6976, Val: 0.6524\n",
      "Epoch: 050, Loss: 0.6961, Val: 0.6516\n",
      "Epoch: 051, Loss: 0.6953, Val: 0.6510\n",
      "Epoch: 052, Loss: 0.6942, Val: 0.6504\n",
      "Epoch: 053, Loss: 0.6926, Val: 0.6504\n",
      "Epoch: 054, Loss: 0.6914, Val: 0.6508\n",
      "精确度： 0.010732323232323253\n",
      "召回率： 0.049740450672965\n",
      "F1_： 0.017655237551357252\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss曲线' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [110]\u001b[0m, in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m绘制曲线\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m x_epoch \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_val_auc))]\n\u001b[0;32m---> 70\u001b[0m \u001b[43mloss曲线\u001b[49m\n\u001b[1;32m     71\u001b[0m drawLossVal(x_epoch, y_loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOSS_Experiment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# auc曲线\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss曲线' is not defined"
     ]
    }
   ],
   "source": [
    "# 构建训练的data\n",
    "x_GAT = []\n",
    "for _ in range(num_u):\n",
    "    tmp_arr = np.random.rand(3000)\n",
    "    x_GAT.append(list(tmp_arr))\n",
    "x_curLink = torch.tensor(x_GAT, dtype=torch.float32)\n",
    "edge_index = [[], []]\n",
    "for uid1, uid2 in zip(friendship_old_df['uid1'], friendship_old_df['uid2']):\n",
    "    edge_index[0].append(uid1)\n",
    "    edge_index[1].append(uid2)\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "edge_new_index = [[], []]\n",
    "for uid1, uid2 in zip(friendship_new_df['uid1'], friendship_new_df['uid2']):\n",
    "    edge_new_index[0].append(uid1)\n",
    "    edge_new_index[1].append(uid2)\n",
    "edge_new_index = torch.tensor(edge_new_index, dtype=torch.long)\n",
    "data = Data(x=x_curLink, edge_index=edge_index, edge_new_index=edge_new_index)  # 构建data\n",
    "\n",
    "# 网络数据放入GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 使用GPU\n",
    "ground_truth_edge_index = data.edge_index.to(device)  # 数据放入GPU\n",
    "# 样本负采样,测试集验证集分裂,按学习难度分化数据集\n",
    "data = train_test_split_edges_m(data, val_ratio=0.1, neg_candidates_num=int(num_u * 0.1))\n",
    "# data = train_Diff_split_edges(data, node_diffASC_list, NUM_diff_leve)  # 根据学习难度，对边数据进行分级\n",
    "data = data.to(device)  # 将数据放入device\n",
    "\n",
    "# 构建网络\n",
    "num_node_features = len(data.x[0])\n",
    "model = GATNet(num_node_features, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "\n",
    "x_epoch = []\n",
    "y_loss = []\n",
    "y_val_auc = []\n",
    "num_fit = 10\n",
    "fit_x = np.array([i + 1 for i in range(num_fit)])\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    loss = train(data, model, optimizer)\n",
    "    val_auc = val(data, model)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}')\n",
    "    x_epoch.append(epoch)\n",
    "    y_loss.append(float(loss))\n",
    "    y_val_auc.append(float(val_auc))\n",
    "\n",
    "    # 验证集用来控制何时结束训练,拟合直线斜率小于等于0则停止\n",
    "    if len(y_val_auc) > num_fit:\n",
    "        fit_y = np.array(y_val_auc[-num_fit:])\n",
    "        f1 = np.polyfit(fit_x, fit_y, 1)\n",
    "        if f1[0] <= 0: break\n",
    "\n",
    "# print(\"  \")\n",
    "# print(\"result：\")\n",
    "# print(\"loss:\", y_loss[-1])\n",
    "# print(\"val_auc:\", y_val_auc[-1])\n",
    "zzz = model.encode(data.x, data.train_pos_edge_index)\n",
    "prob_adj = zzz @ zzz.t()\n",
    "for i in range(len(prob_adj)):\n",
    "    prob_adj[i][i] = 0\n",
    "\n",
    "K = 10\n",
    "P_K, R_K, F1_ = count_o2n_Acc_Recall(K, prob_adj.cpu(), link_new_labels_M)\n",
    "print(\"精确度：\", P_K)\n",
    "print(\"召回率：\", R_K)\n",
    "print(\"F1_：\", F1_)\n",
    "\n",
    "\"\"\"\n",
    "绘制曲线\n",
    "\"\"\"\n",
    "x_epoch = [i + 1 for i in range(len(y_val_auc))]\n",
    "loss曲线\n",
    "drawLossVal(x_epoch, y_loss, \"loss\", \"LOSS_Experiment\", \"epoch\", \"auc\")\n",
    "\n",
    "# auc曲线\n",
    "drawLossVal(x_epoch, y_val_auc, \"val\", \"val_Experiment\", \"epoch\", \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cc850a-ad91-4ac3-b962-b64d4b1a83a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# CurLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "974606fd-1247-44c8-ac79-749715d081f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- 开始计算CurLink ----------\n",
      "---------- 计算user的学习困难程度 ----------\n"
     ]
    }
   ],
   "source": [
    "# curLink\n",
    "print(\"-\" * 10, \"开始计算CurLink\", \"-\" * 10)\n",
    "R_ball = 0.5  # 超球体半径参数\n",
    "\n",
    "\n",
    "print(\"-\" * 10, \"计算user的学习困难程度\", \"-\" * 10)\n",
    "# 首先计算user的学习困难程度\n",
    "node_diffASC_list = count_diff_of_nodes(num_u, R_ball, HeterHyper_id_vec_list, friendship_old_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "575b6066-a185-42fc-a265-167e73a9d806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82379/2246033257.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  x_curLink = torch.tensor(HeterHyper_id_vec_list, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# 构建训练的data\n",
    "NUM_diff_leve = 15  # 学习难度等级总数\n",
    "num_epoch = 1000 # 学习epoch数\n",
    "x_curLink = torch.tensor(HeterHyper_id_vec_list, dtype=torch.float32)\n",
    "edge_index = [[], []]\n",
    "for uid1, uid2 in zip(friendship_old_df['uid1'], friendship_old_df['uid2']):\n",
    "    edge_index[0].append(uid1)\n",
    "    edge_index[1].append(uid2)\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "edge_new_index = [[], []]\n",
    "for uid1, uid2 in zip(friendship_new_df['uid1'], friendship_new_df['uid2']):\n",
    "    edge_new_index[0].append(uid1)\n",
    "    edge_new_index[1].append(uid2)\n",
    "edge_new_index = torch.tensor(edge_new_index, dtype=torch.long)\n",
    "data = Data(x=x_curLink, edge_index=edge_index, edge_new_index=edge_new_index)  # 构建data\n",
    "\n",
    "# 网络数据放入GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 使用GPU\n",
    "ground_truth_edge_index = data.edge_index.to(device)  # 数据放入GPU\n",
    "# 样本负采样,测试集验证集分裂,按学习难度分化数据集\n",
    "data = train_test_split_edges_m(data, val_ratio=0.1, neg_candidates_num=int(num_u * 0.1))\n",
    "#data = train_test_split_edges_m(data, val_ratio=0.1, neg_candidates_num=50)\n",
    "data = train_Diff_split_edges(data, node_diffASC_list, NUM_diff_leve)  # 根据学习难度，对边数据进行分级\n",
    "data = data.to(device)  # 将数据放入device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4653770-52b5-4c75-830f-0a60872753d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- CurLink(GAT)开始训练 ----------\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:1,Epoch: 001, Loss: 1.2488, Val: 0.6647,\n",
      "diffLevel:1,Epoch: 002, Loss: 1.1872, Val: 0.6804,\n",
      "diffLevel:1,Epoch: 003, Loss: 1.1348, Val: 0.6967,\n",
      "diffLevel:1,Epoch: 004, Loss: 1.0847, Val: 0.7132,\n",
      "diffLevel:1,Epoch: 005, Loss: 1.0403, Val: 0.7297,\n",
      "diffLevel:1,Epoch: 006, Loss: 0.9995, Val: 0.7461,\n",
      "diffLevel:1,Epoch: 007, Loss: 0.9637, Val: 0.7621,\n",
      "diffLevel:1,Epoch: 008, Loss: 0.9316, Val: 0.7775,\n",
      "diffLevel:1,Epoch: 009, Loss: 0.9027, Val: 0.7920,\n",
      "diffLevel:1,Epoch: 010, Loss: 0.8788, Val: 0.8057,\n",
      "diffLevel:1,Epoch: 011, Loss: 0.8550, Val: 0.8184,\n",
      "diffLevel:1,Epoch: 012, Loss: 0.8347, Val: 0.8300,\n",
      "diffLevel:1,Epoch: 013, Loss: 0.8140, Val: 0.8405,\n",
      "diffLevel:1,Epoch: 014, Loss: 0.8011, Val: 0.8500,\n",
      "diffLevel:1,Epoch: 015, Loss: 0.7850, Val: 0.8585,\n",
      "diffLevel:1,Epoch: 016, Loss: 0.7727, Val: 0.8660,\n",
      "diffLevel:1,Epoch: 017, Loss: 0.7628, Val: 0.8727,\n",
      "diffLevel:1,Epoch: 018, Loss: 0.7539, Val: 0.8785,\n",
      "diffLevel:1,Epoch: 019, Loss: 0.7432, Val: 0.8837,\n",
      "diffLevel:1,Epoch: 020, Loss: 0.7351, Val: 0.8881,\n",
      "diffLevel:1,Epoch: 021, Loss: 0.7304, Val: 0.8920,\n",
      "diffLevel:1,Epoch: 022, Loss: 0.7243, Val: 0.8953,\n",
      "diffLevel:1,Epoch: 023, Loss: 0.7199, Val: 0.8983,\n",
      "diffLevel:1,Epoch: 024, Loss: 0.7145, Val: 0.9008,\n",
      "diffLevel:1,Epoch: 025, Loss: 0.7117, Val: 0.9030,\n",
      "diffLevel:1,Epoch: 026, Loss: 0.7076, Val: 0.9049,\n",
      "diffLevel:1,Epoch: 027, Loss: 0.7072, Val: 0.9065,\n",
      "diffLevel:1,Epoch: 028, Loss: 0.7035, Val: 0.9079,\n",
      "diffLevel:1,Epoch: 029, Loss: 0.7010, Val: 0.9091,\n",
      "diffLevel:1,Epoch: 030, Loss: 0.6995, Val: 0.9102,\n",
      "diffLevel:1,Epoch: 031, Loss: 0.6990, Val: 0.9111,\n",
      "diffLevel:1,Epoch: 032, Loss: 0.6968, Val: 0.9120,\n",
      "diffLevel:1,Epoch: 033, Loss: 0.6962, Val: 0.9127,\n",
      "diffLevel:1,Epoch: 034, Loss: 0.6944, Val: 0.9133,\n",
      "diffLevel:1,Epoch: 035, Loss: 0.6945, Val: 0.9139,\n",
      "diffLevel:1,Epoch: 036, Loss: 0.6926, Val: 0.9145,\n",
      "diffLevel:1,Epoch: 037, Loss: 0.6935, Val: 0.9150,\n",
      "diffLevel:1,Epoch: 038, Loss: 0.6930, Val: 0.9155,\n",
      "diffLevel:1,Epoch: 039, Loss: 0.6915, Val: 0.9159,\n",
      "diffLevel:1,Epoch: 040, Loss: 0.6915, Val: 0.9163,\n",
      "diffLevel:1,Epoch: 041, Loss: 0.6925, Val: 0.9167,\n",
      "diffLevel:1,Epoch: 042, Loss: 0.6918, Val: 0.9171,\n",
      "diffLevel:1,Epoch: 043, Loss: 0.6907, Val: 0.9174,\n",
      "diffLevel:1,Epoch: 044, Loss: 0.6910, Val: 0.9177,\n",
      "diffLevel:1,Epoch: 045, Loss: 0.6914, Val: 0.9180,\n",
      "diffLevel:1,Epoch: 046, Loss: 0.6891, Val: 0.9183,\n",
      "diffLevel:1,Epoch: 047, Loss: 0.6907, Val: 0.9186,\n",
      "diffLevel:1,Epoch: 048, Loss: 0.6912, Val: 0.9189,\n",
      "diffLevel:1,Epoch: 049, Loss: 0.6897, Val: 0.9192,\n",
      "diffLevel:1,Epoch: 050, Loss: 0.6906, Val: 0.9195,\n",
      "diffLevel:1,Epoch: 051, Loss: 0.6911, Val: 0.9197,\n",
      "diffLevel:1,Epoch: 052, Loss: 0.6898, Val: 0.9200,\n",
      "diffLevel:1,Epoch: 053, Loss: 0.6909, Val: 0.9202,\n",
      "diffLevel:1,Epoch: 054, Loss: 0.6896, Val: 0.9204,\n",
      "diffLevel:1,Epoch: 055, Loss: 0.6903, Val: 0.9207,\n",
      "diffLevel:1,Epoch: 056, Loss: 0.6905, Val: 0.9209,\n",
      "diffLevel:1,Epoch: 057, Loss: 0.6894, Val: 0.9211,\n",
      "diffLevel:1,Epoch: 058, Loss: 0.6892, Val: 0.9213,\n",
      "diffLevel:1,Epoch: 059, Loss: 0.6902, Val: 0.9215,\n",
      "diffLevel:1,Epoch: 060, Loss: 0.6896, Val: 0.9217,\n",
      "diffLevel:1,Epoch: 061, Loss: 0.6902, Val: 0.9219,\n",
      "diffLevel:1,Epoch: 062, Loss: 0.6886, Val: 0.9221,\n",
      "diffLevel:1,Epoch: 063, Loss: 0.6904, Val: 0.9223,\n",
      "diffLevel:1,Epoch: 064, Loss: 0.6897, Val: 0.9225,\n",
      "diffLevel:1,Epoch: 065, Loss: 0.6890, Val: 0.9227,\n",
      "diffLevel:1,Epoch: 066, Loss: 0.6894, Val: 0.9229,\n",
      "diffLevel:1,Epoch: 067, Loss: 0.6895, Val: 0.9231,\n",
      "diffLevel:1,Epoch: 068, Loss: 0.6891, Val: 0.9234,\n",
      "diffLevel:1,Epoch: 069, Loss: 0.6875, Val: 0.9235,\n",
      "diffLevel:1,Epoch: 070, Loss: 0.6895, Val: 0.9237,\n",
      "diffLevel:1,Epoch: 071, Loss: 0.6890, Val: 0.9239,\n",
      "diffLevel:1,Epoch: 072, Loss: 0.6882, Val: 0.9241,\n",
      "diffLevel:1,Epoch: 073, Loss: 0.6886, Val: 0.9243,\n",
      "diffLevel:1,Epoch: 074, Loss: 0.6882, Val: 0.9245,\n",
      "diffLevel:1,Epoch: 075, Loss: 0.6874, Val: 0.9246,\n",
      "diffLevel:1,Epoch: 076, Loss: 0.6885, Val: 0.9248,\n",
      "diffLevel:1,Epoch: 077, Loss: 0.6876, Val: 0.9250,\n",
      "diffLevel:1,Epoch: 078, Loss: 0.6880, Val: 0.9252,\n",
      "diffLevel:1,Epoch: 079, Loss: 0.6875, Val: 0.9253,\n",
      "diffLevel:1,Epoch: 080, Loss: 0.6871, Val: 0.9255,\n",
      "diffLevel:1,Epoch: 081, Loss: 0.6879, Val: 0.9256,\n",
      "diffLevel:1,Epoch: 082, Loss: 0.6866, Val: 0.9258,\n",
      "diffLevel:1,Epoch: 083, Loss: 0.6877, Val: 0.9259,\n",
      "diffLevel:1,Epoch: 084, Loss: 0.6882, Val: 0.9261,\n",
      "diffLevel:1,Epoch: 085, Loss: 0.6865, Val: 0.9262,\n",
      "diffLevel:1,Epoch: 086, Loss: 0.6868, Val: 0.9263,\n",
      "diffLevel:1,Epoch: 087, Loss: 0.6867, Val: 0.9265,\n",
      "diffLevel:1,Epoch: 088, Loss: 0.6876, Val: 0.9266,\n",
      "diffLevel:1,Epoch: 089, Loss: 0.6872, Val: 0.9267,\n",
      "diffLevel:1,Epoch: 090, Loss: 0.6870, Val: 0.9269,\n",
      "diffLevel:1,Epoch: 091, Loss: 0.6880, Val: 0.9270,\n",
      "diffLevel:1,Epoch: 092, Loss: 0.6866, Val: 0.9271,\n",
      "diffLevel:1,Epoch: 093, Loss: 0.6877, Val: 0.9272,\n",
      "diffLevel:1,Epoch: 094, Loss: 0.6858, Val: 0.9273,\n",
      "diffLevel:1,Epoch: 095, Loss: 0.6864, Val: 0.9274,\n",
      "diffLevel:1,Epoch: 096, Loss: 0.6857, Val: 0.9275,\n",
      "diffLevel:1,Epoch: 097, Loss: 0.6858, Val: 0.9275,\n",
      "diffLevel:1,Epoch: 098, Loss: 0.6862, Val: 0.9276,\n",
      "diffLevel:1,Epoch: 099, Loss: 0.6856, Val: 0.9277,\n",
      "diffLevel:1,Epoch: 100, Loss: 0.6859, Val: 0.9277,\n",
      "diffLevel:1,Epoch: 101, Loss: 0.6860, Val: 0.9278,\n",
      "diffLevel:1,Epoch: 102, Loss: 0.6859, Val: 0.9278,\n",
      "diffLevel:1,Epoch: 103, Loss: 0.6864, Val: 0.9278,\n",
      "diffLevel:1,Epoch: 104, Loss: 0.6851, Val: 0.9278,\n",
      "diffLevel:1,Epoch: 105, Loss: 0.6859, Val: 0.9279,\n",
      "diffLevel:1,Epoch: 106, Loss: 0.6853, Val: 0.9279,\n",
      "diffLevel:1,Epoch: 107, Loss: 0.6849, Val: 0.9279,\n",
      "diffLevel:1,Epoch: 108, Loss: 0.6860, Val: 0.9279,\n",
      "diffLevel:1,Epoch: 109, Loss: 0.6846, Val: 0.9279,\n",
      "diffLevel:1,Epoch: 110, Loss: 0.6843, Val: 0.9279,\n",
      "diffLevel:1,Epoch: 111, Loss: 0.6843, Val: 0.9278,\n",
      "diffLevel:1,Epoch: 112, Loss: 0.6847, Val: 0.9278,\n",
      "diffLevel:1,Epoch: 112, Loss: 0.6847, Val: 0.9278,\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:2,Epoch: 001, Loss: 0.6828, Val: 0.9278,\n",
      "diffLevel:2,Epoch: 002, Loss: 0.6828, Val: 0.9277,\n",
      "diffLevel:2,Epoch: 003, Loss: 0.6831, Val: 0.9277,\n",
      "diffLevel:2,Epoch: 004, Loss: 0.6832, Val: 0.9276,\n",
      "diffLevel:2,Epoch: 005, Loss: 0.6826, Val: 0.9276,\n",
      "diffLevel:2,Epoch: 006, Loss: 0.6816, Val: 0.9275,\n",
      "diffLevel:2,Epoch: 007, Loss: 0.6823, Val: 0.9275,\n",
      "diffLevel:2,Epoch: 008, Loss: 0.6824, Val: 0.9274,\n",
      "diffLevel:2,Epoch: 009, Loss: 0.6822, Val: 0.9273,\n",
      "diffLevel:2,Epoch: 010, Loss: 0.6812, Val: 0.9273,\n",
      "diffLevel:2,Epoch: 011, Loss: 0.6813, Val: 0.9272,\n",
      "diffLevel:2,Epoch: 011, Loss: 0.6813, Val: 0.9272,\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:3,Epoch: 001, Loss: 0.6802, Val: 0.9271,\n",
      "diffLevel:3,Epoch: 002, Loss: 0.6809, Val: 0.9270,\n",
      "diffLevel:3,Epoch: 003, Loss: 0.6798, Val: 0.9270,\n",
      "diffLevel:3,Epoch: 004, Loss: 0.6796, Val: 0.9269,\n",
      "diffLevel:3,Epoch: 005, Loss: 0.6807, Val: 0.9268,\n",
      "diffLevel:3,Epoch: 006, Loss: 0.6802, Val: 0.9267,\n",
      "diffLevel:3,Epoch: 007, Loss: 0.6802, Val: 0.9266,\n",
      "diffLevel:3,Epoch: 008, Loss: 0.6805, Val: 0.9265,\n",
      "diffLevel:3,Epoch: 009, Loss: 0.6799, Val: 0.9264,\n",
      "diffLevel:3,Epoch: 010, Loss: 0.6806, Val: 0.9263,\n",
      "diffLevel:3,Epoch: 011, Loss: 0.6796, Val: 0.9262,\n",
      "diffLevel:3,Epoch: 011, Loss: 0.6796, Val: 0.9262,\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:4,Epoch: 001, Loss: 0.6791, Val: 0.9261,\n",
      "diffLevel:4,Epoch: 002, Loss: 0.6790, Val: 0.9260,\n",
      "diffLevel:4,Epoch: 003, Loss: 0.6789, Val: 0.9259,\n",
      "diffLevel:4,Epoch: 004, Loss: 0.6788, Val: 0.9258,\n",
      "diffLevel:4,Epoch: 005, Loss: 0.6790, Val: 0.9257,\n",
      "diffLevel:4,Epoch: 006, Loss: 0.6786, Val: 0.9256,\n",
      "diffLevel:4,Epoch: 007, Loss: 0.6786, Val: 0.9255,\n",
      "diffLevel:4,Epoch: 008, Loss: 0.6786, Val: 0.9254,\n",
      "diffLevel:4,Epoch: 009, Loss: 0.6787, Val: 0.9253,\n",
      "diffLevel:4,Epoch: 010, Loss: 0.6780, Val: 0.9252,\n",
      "diffLevel:4,Epoch: 011, Loss: 0.6783, Val: 0.9251,\n",
      "diffLevel:4,Epoch: 011, Loss: 0.6783, Val: 0.9251,\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:5,Epoch: 001, Loss: 0.6771, Val: 0.9250,\n",
      "diffLevel:5,Epoch: 002, Loss: 0.6776, Val: 0.9249,\n",
      "diffLevel:5,Epoch: 003, Loss: 0.6766, Val: 0.9248,\n",
      "diffLevel:5,Epoch: 004, Loss: 0.6775, Val: 0.9247,\n",
      "diffLevel:5,Epoch: 005, Loss: 0.6767, Val: 0.9246,\n",
      "diffLevel:5,Epoch: 006, Loss: 0.6773, Val: 0.9245,\n",
      "diffLevel:5,Epoch: 007, Loss: 0.6767, Val: 0.9245,\n",
      "diffLevel:5,Epoch: 008, Loss: 0.6759, Val: 0.9244,\n",
      "diffLevel:5,Epoch: 009, Loss: 0.6769, Val: 0.9243,\n",
      "diffLevel:5,Epoch: 010, Loss: 0.6768, Val: 0.9242,\n",
      "diffLevel:5,Epoch: 011, Loss: 0.6764, Val: 0.9241,\n",
      "diffLevel:5,Epoch: 011, Loss: 0.6764, Val: 0.9241,\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:6,Epoch: 001, Loss: 0.6763, Val: 0.9240,\n",
      "diffLevel:6,Epoch: 002, Loss: 0.6758, Val: 0.9239,\n",
      "diffLevel:6,Epoch: 003, Loss: 0.6761, Val: 0.9238,\n",
      "diffLevel:6,Epoch: 004, Loss: 0.6755, Val: 0.9238,\n",
      "diffLevel:6,Epoch: 005, Loss: 0.6760, Val: 0.9237,\n",
      "diffLevel:6,Epoch: 006, Loss: 0.6761, Val: 0.9236,\n",
      "diffLevel:6,Epoch: 007, Loss: 0.6763, Val: 0.9236,\n",
      "diffLevel:6,Epoch: 008, Loss: 0.6760, Val: 0.9235,\n",
      "diffLevel:6,Epoch: 009, Loss: 0.6760, Val: 0.9234,\n",
      "diffLevel:6,Epoch: 010, Loss: 0.6756, Val: 0.9233,\n",
      "diffLevel:6,Epoch: 011, Loss: 0.6756, Val: 0.9233,\n",
      "diffLevel:6,Epoch: 011, Loss: 0.6756, Val: 0.9233,\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:7,Epoch: 001, Loss: 0.6753, Val: 0.9232,\n",
      "diffLevel:7,Epoch: 002, Loss: 0.6760, Val: 0.9232,\n",
      "diffLevel:7,Epoch: 003, Loss: 0.6750, Val: 0.9231,\n",
      "diffLevel:7,Epoch: 004, Loss: 0.6748, Val: 0.9231,\n",
      "diffLevel:7,Epoch: 005, Loss: 0.6748, Val: 0.9231,\n",
      "diffLevel:7,Epoch: 006, Loss: 0.6755, Val: 0.9230,\n",
      "diffLevel:7,Epoch: 007, Loss: 0.6747, Val: 0.9230,\n",
      "diffLevel:7,Epoch: 008, Loss: 0.6747, Val: 0.9229,\n",
      "diffLevel:7,Epoch: 009, Loss: 0.6740, Val: 0.9228,\n",
      "diffLevel:7,Epoch: 010, Loss: 0.6750, Val: 0.9228,\n",
      "diffLevel:7,Epoch: 011, Loss: 0.6743, Val: 0.9227,\n",
      "diffLevel:7,Epoch: 011, Loss: 0.6743, Val: 0.9227,\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:8,Epoch: 001, Loss: 0.6740, Val: 0.9227,\n",
      "diffLevel:8,Epoch: 002, Loss: 0.6745, Val: 0.9227,\n",
      "diffLevel:8,Epoch: 003, Loss: 0.6740, Val: 0.9226,\n",
      "diffLevel:8,Epoch: 004, Loss: 0.6743, Val: 0.9226,\n",
      "diffLevel:8,Epoch: 005, Loss: 0.6744, Val: 0.9226,\n",
      "diffLevel:8,Epoch: 006, Loss: 0.6741, Val: 0.9226,\n",
      "diffLevel:8,Epoch: 007, Loss: 0.6746, Val: 0.9226,\n",
      "diffLevel:8,Epoch: 008, Loss: 0.6742, Val: 0.9225,\n",
      "diffLevel:8,Epoch: 009, Loss: 0.6750, Val: 0.9225,\n",
      "diffLevel:8,Epoch: 010, Loss: 0.6735, Val: 0.9225,\n",
      "diffLevel:8,Epoch: 011, Loss: 0.6735, Val: 0.9225,\n",
      "diffLevel:8,Epoch: 011, Loss: 0.6735, Val: 0.9225,\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:9,Epoch: 001, Loss: 0.6737, Val: 0.9225,\n",
      "diffLevel:9,Epoch: 002, Loss: 0.6737, Val: 0.9225,\n",
      "diffLevel:9,Epoch: 003, Loss: 0.6735, Val: 0.9225,\n",
      "diffLevel:9,Epoch: 004, Loss: 0.6737, Val: 0.9225,\n",
      "diffLevel:9,Epoch: 005, Loss: 0.6733, Val: 0.9225,\n",
      "diffLevel:9,Epoch: 006, Loss: 0.6737, Val: 0.9225,\n",
      "diffLevel:9,Epoch: 007, Loss: 0.6728, Val: 0.9225,\n",
      "diffLevel:9,Epoch: 008, Loss: 0.6731, Val: 0.9225,\n",
      "diffLevel:9,Epoch: 009, Loss: 0.6735, Val: 0.9225,\n",
      "diffLevel:9,Epoch: 010, Loss: 0.6731, Val: 0.9225,\n",
      "diffLevel:9,Epoch: 011, Loss: 0.6730, Val: 0.9226,\n",
      "diffLevel:9,Epoch: 012, Loss: 0.6729, Val: 0.9226,\n",
      "diffLevel:9,Epoch: 013, Loss: 0.6735, Val: 0.9226,\n",
      "diffLevel:9,Epoch: 014, Loss: 0.6729, Val: 0.9226,\n",
      "diffLevel:9,Epoch: 015, Loss: 0.6729, Val: 0.9226,\n",
      "diffLevel:9,Epoch: 016, Loss: 0.6730, Val: 0.9226,\n",
      "diffLevel:9,Epoch: 017, Loss: 0.6735, Val: 0.9226,\n",
      "diffLevel:9,Epoch: 018, Loss: 0.6738, Val: 0.9227,\n",
      "diffLevel:9,Epoch: 019, Loss: 0.6734, Val: 0.9227,\n",
      "diffLevel:9,Epoch: 020, Loss: 0.6732, Val: 0.9228,\n",
      "diffLevel:9,Epoch: 021, Loss: 0.6731, Val: 0.9228,\n",
      "diffLevel:9,Epoch: 022, Loss: 0.6729, Val: 0.9228,\n",
      "diffLevel:9,Epoch: 023, Loss: 0.6724, Val: 0.9229,\n",
      "diffLevel:9,Epoch: 024, Loss: 0.6728, Val: 0.9229,\n",
      "diffLevel:9,Epoch: 025, Loss: 0.6731, Val: 0.9230,\n",
      "diffLevel:9,Epoch: 026, Loss: 0.6728, Val: 0.9230,\n",
      "diffLevel:9,Epoch: 027, Loss: 0.6735, Val: 0.9230,\n",
      "diffLevel:9,Epoch: 028, Loss: 0.6726, Val: 0.9231,\n",
      "diffLevel:9,Epoch: 029, Loss: 0.6726, Val: 0.9231,\n",
      "diffLevel:9,Epoch: 030, Loss: 0.6731, Val: 0.9232,\n",
      "diffLevel:9,Epoch: 031, Loss: 0.6732, Val: 0.9232,\n",
      "diffLevel:9,Epoch: 032, Loss: 0.6729, Val: 0.9233,\n",
      "diffLevel:9,Epoch: 033, Loss: 0.6725, Val: 0.9233,\n",
      "diffLevel:9,Epoch: 034, Loss: 0.6729, Val: 0.9234,\n",
      "diffLevel:9,Epoch: 035, Loss: 0.6728, Val: 0.9234,\n",
      "diffLevel:9,Epoch: 036, Loss: 0.6727, Val: 0.9235,\n",
      "diffLevel:9,Epoch: 037, Loss: 0.6731, Val: 0.9236,\n",
      "diffLevel:9,Epoch: 038, Loss: 0.6726, Val: 0.9236,\n",
      "diffLevel:9,Epoch: 039, Loss: 0.6724, Val: 0.9237,\n",
      "diffLevel:9,Epoch: 040, Loss: 0.6728, Val: 0.9238,\n",
      "diffLevel:9,Epoch: 041, Loss: 0.6728, Val: 0.9238,\n",
      "diffLevel:9,Epoch: 042, Loss: 0.6725, Val: 0.9239,\n",
      "diffLevel:9,Epoch: 043, Loss: 0.6725, Val: 0.9239,\n",
      "diffLevel:9,Epoch: 044, Loss: 0.6723, Val: 0.9240,\n",
      "diffLevel:9,Epoch: 045, Loss: 0.6724, Val: 0.9240,\n",
      "diffLevel:9,Epoch: 046, Loss: 0.6724, Val: 0.9241,\n",
      "diffLevel:9,Epoch: 047, Loss: 0.6721, Val: 0.9241,\n",
      "diffLevel:9,Epoch: 048, Loss: 0.6724, Val: 0.9242,\n",
      "diffLevel:9,Epoch: 049, Loss: 0.6721, Val: 0.9243,\n",
      "diffLevel:9,Epoch: 050, Loss: 0.6721, Val: 0.9243,\n",
      "diffLevel:9,Epoch: 051, Loss: 0.6722, Val: 0.9244,\n",
      "diffLevel:9,Epoch: 052, Loss: 0.6721, Val: 0.9244,\n",
      "diffLevel:9,Epoch: 053, Loss: 0.6714, Val: 0.9245,\n",
      "diffLevel:9,Epoch: 054, Loss: 0.6723, Val: 0.9246,\n",
      "diffLevel:9,Epoch: 055, Loss: 0.6723, Val: 0.9246,\n",
      "diffLevel:9,Epoch: 056, Loss: 0.6720, Val: 0.9247,\n",
      "diffLevel:9,Epoch: 057, Loss: 0.6717, Val: 0.9247,\n",
      "diffLevel:9,Epoch: 058, Loss: 0.6724, Val: 0.9248,\n",
      "diffLevel:9,Epoch: 059, Loss: 0.6726, Val: 0.9249,\n",
      "diffLevel:9,Epoch: 060, Loss: 0.6722, Val: 0.9249,\n",
      "diffLevel:9,Epoch: 061, Loss: 0.6724, Val: 0.9250,\n",
      "diffLevel:9,Epoch: 062, Loss: 0.6719, Val: 0.9251,\n",
      "diffLevel:9,Epoch: 063, Loss: 0.6720, Val: 0.9251,\n",
      "diffLevel:9,Epoch: 064, Loss: 0.6719, Val: 0.9252,\n",
      "diffLevel:9,Epoch: 065, Loss: 0.6717, Val: 0.9253,\n",
      "diffLevel:9,Epoch: 066, Loss: 0.6719, Val: 0.9253,\n",
      "diffLevel:9,Epoch: 067, Loss: 0.6714, Val: 0.9254,\n",
      "diffLevel:9,Epoch: 068, Loss: 0.6720, Val: 0.9254,\n",
      "diffLevel:9,Epoch: 069, Loss: 0.6724, Val: 0.9255,\n",
      "diffLevel:9,Epoch: 070, Loss: 0.6721, Val: 0.9256,\n",
      "diffLevel:9,Epoch: 071, Loss: 0.6717, Val: 0.9256,\n",
      "diffLevel:9,Epoch: 072, Loss: 0.6719, Val: 0.9257,\n",
      "diffLevel:9,Epoch: 073, Loss: 0.6717, Val: 0.9258,\n",
      "diffLevel:9,Epoch: 074, Loss: 0.6717, Val: 0.9258,\n",
      "diffLevel:9,Epoch: 075, Loss: 0.6710, Val: 0.9259,\n",
      "diffLevel:9,Epoch: 076, Loss: 0.6717, Val: 0.9260,\n",
      "diffLevel:9,Epoch: 077, Loss: 0.6713, Val: 0.9260,\n",
      "diffLevel:9,Epoch: 078, Loss: 0.6714, Val: 0.9261,\n",
      "diffLevel:9,Epoch: 079, Loss: 0.6717, Val: 0.9261,\n",
      "diffLevel:9,Epoch: 080, Loss: 0.6717, Val: 0.9262,\n",
      "diffLevel:9,Epoch: 081, Loss: 0.6715, Val: 0.9263,\n",
      "diffLevel:9,Epoch: 082, Loss: 0.6708, Val: 0.9263,\n",
      "diffLevel:9,Epoch: 083, Loss: 0.6713, Val: 0.9264,\n",
      "diffLevel:9,Epoch: 084, Loss: 0.6716, Val: 0.9265,\n",
      "diffLevel:9,Epoch: 085, Loss: 0.6715, Val: 0.9265,\n",
      "diffLevel:9,Epoch: 086, Loss: 0.6719, Val: 0.9266,\n",
      "diffLevel:9,Epoch: 087, Loss: 0.6712, Val: 0.9266,\n",
      "diffLevel:9,Epoch: 088, Loss: 0.6710, Val: 0.9267,\n",
      "diffLevel:9,Epoch: 089, Loss: 0.6712, Val: 0.9268,\n",
      "diffLevel:9,Epoch: 090, Loss: 0.6713, Val: 0.9268,\n",
      "diffLevel:9,Epoch: 091, Loss: 0.6705, Val: 0.9269,\n",
      "diffLevel:9,Epoch: 092, Loss: 0.6708, Val: 0.9270,\n",
      "diffLevel:9,Epoch: 093, Loss: 0.6712, Val: 0.9270,\n",
      "diffLevel:9,Epoch: 094, Loss: 0.6717, Val: 0.9271,\n",
      "diffLevel:9,Epoch: 095, Loss: 0.6718, Val: 0.9272,\n",
      "diffLevel:9,Epoch: 096, Loss: 0.6709, Val: 0.9272,\n",
      "diffLevel:9,Epoch: 097, Loss: 0.6711, Val: 0.9273,\n",
      "diffLevel:9,Epoch: 098, Loss: 0.6714, Val: 0.9273,\n",
      "diffLevel:9,Epoch: 099, Loss: 0.6711, Val: 0.9274,\n",
      "diffLevel:9,Epoch: 100, Loss: 0.6709, Val: 0.9275,\n",
      "diffLevel:9,Epoch: 101, Loss: 0.6714, Val: 0.9275,\n",
      "diffLevel:9,Epoch: 102, Loss: 0.6704, Val: 0.9276,\n",
      "diffLevel:9,Epoch: 103, Loss: 0.6711, Val: 0.9276,\n",
      "diffLevel:9,Epoch: 104, Loss: 0.6716, Val: 0.9277,\n",
      "diffLevel:9,Epoch: 105, Loss: 0.6701, Val: 0.9278,\n",
      "diffLevel:9,Epoch: 106, Loss: 0.6708, Val: 0.9278,\n",
      "diffLevel:9,Epoch: 107, Loss: 0.6709, Val: 0.9279,\n",
      "diffLevel:9,Epoch: 108, Loss: 0.6704, Val: 0.9280,\n",
      "diffLevel:9,Epoch: 109, Loss: 0.6704, Val: 0.9280,\n",
      "diffLevel:9,Epoch: 110, Loss: 0.6706, Val: 0.9281,\n",
      "diffLevel:9,Epoch: 111, Loss: 0.6711, Val: 0.9281,\n",
      "diffLevel:9,Epoch: 112, Loss: 0.6703, Val: 0.9282,\n",
      "diffLevel:9,Epoch: 113, Loss: 0.6708, Val: 0.9282,\n",
      "diffLevel:9,Epoch: 114, Loss: 0.6708, Val: 0.9283,\n",
      "diffLevel:9,Epoch: 115, Loss: 0.6709, Val: 0.9283,\n",
      "diffLevel:9,Epoch: 116, Loss: 0.6705, Val: 0.9284,\n",
      "diffLevel:9,Epoch: 117, Loss: 0.6708, Val: 0.9284,\n",
      "diffLevel:9,Epoch: 118, Loss: 0.6709, Val: 0.9285,\n",
      "diffLevel:9,Epoch: 119, Loss: 0.6710, Val: 0.9286,\n",
      "diffLevel:9,Epoch: 120, Loss: 0.6706, Val: 0.9286,\n",
      "diffLevel:9,Epoch: 121, Loss: 0.6706, Val: 0.9287,\n",
      "diffLevel:9,Epoch: 122, Loss: 0.6704, Val: 0.9288,\n",
      "diffLevel:9,Epoch: 123, Loss: 0.6709, Val: 0.9288,\n",
      "diffLevel:9,Epoch: 124, Loss: 0.6711, Val: 0.9289,\n",
      "diffLevel:9,Epoch: 125, Loss: 0.6701, Val: 0.9290,\n",
      "diffLevel:9,Epoch: 126, Loss: 0.6707, Val: 0.9290,\n",
      "diffLevel:9,Epoch: 127, Loss: 0.6697, Val: 0.9291,\n",
      "diffLevel:9,Epoch: 128, Loss: 0.6700, Val: 0.9292,\n",
      "diffLevel:9,Epoch: 129, Loss: 0.6701, Val: 0.9292,\n",
      "diffLevel:9,Epoch: 130, Loss: 0.6709, Val: 0.9293,\n",
      "diffLevel:9,Epoch: 131, Loss: 0.6704, Val: 0.9293,\n",
      "diffLevel:9,Epoch: 132, Loss: 0.6706, Val: 0.9294,\n",
      "diffLevel:9,Epoch: 133, Loss: 0.6704, Val: 0.9295,\n",
      "diffLevel:9,Epoch: 134, Loss: 0.6705, Val: 0.9295,\n",
      "diffLevel:9,Epoch: 135, Loss: 0.6703, Val: 0.9296,\n",
      "diffLevel:9,Epoch: 136, Loss: 0.6701, Val: 0.9296,\n",
      "diffLevel:9,Epoch: 137, Loss: 0.6696, Val: 0.9297,\n",
      "diffLevel:9,Epoch: 138, Loss: 0.6705, Val: 0.9297,\n",
      "diffLevel:9,Epoch: 139, Loss: 0.6699, Val: 0.9298,\n",
      "diffLevel:9,Epoch: 140, Loss: 0.6707, Val: 0.9298,\n",
      "diffLevel:9,Epoch: 141, Loss: 0.6703, Val: 0.9299,\n",
      "diffLevel:9,Epoch: 142, Loss: 0.6699, Val: 0.9299,\n",
      "diffLevel:9,Epoch: 143, Loss: 0.6698, Val: 0.9300,\n",
      "diffLevel:9,Epoch: 144, Loss: 0.6700, Val: 0.9300,\n",
      "diffLevel:9,Epoch: 145, Loss: 0.6701, Val: 0.9301,\n",
      "diffLevel:9,Epoch: 146, Loss: 0.6699, Val: 0.9301,\n",
      "diffLevel:9,Epoch: 147, Loss: 0.6698, Val: 0.9302,\n",
      "diffLevel:9,Epoch: 148, Loss: 0.6688, Val: 0.9302,\n",
      "diffLevel:9,Epoch: 149, Loss: 0.6695, Val: 0.9303,\n",
      "diffLevel:9,Epoch: 150, Loss: 0.6708, Val: 0.9303,\n",
      "diffLevel:9,Epoch: 151, Loss: 0.6698, Val: 0.9304,\n",
      "diffLevel:9,Epoch: 152, Loss: 0.6693, Val: 0.9304,\n",
      "diffLevel:9,Epoch: 153, Loss: 0.6696, Val: 0.9305,\n",
      "diffLevel:9,Epoch: 154, Loss: 0.6701, Val: 0.9305,\n",
      "diffLevel:9,Epoch: 155, Loss: 0.6703, Val: 0.9306,\n",
      "diffLevel:9,Epoch: 156, Loss: 0.6705, Val: 0.9306,\n",
      "diffLevel:9,Epoch: 157, Loss: 0.6697, Val: 0.9307,\n",
      "diffLevel:9,Epoch: 158, Loss: 0.6698, Val: 0.9307,\n",
      "diffLevel:9,Epoch: 159, Loss: 0.6701, Val: 0.9308,\n",
      "diffLevel:9,Epoch: 160, Loss: 0.6699, Val: 0.9309,\n",
      "diffLevel:9,Epoch: 161, Loss: 0.6695, Val: 0.9309,\n",
      "diffLevel:9,Epoch: 162, Loss: 0.6694, Val: 0.9310,\n",
      "diffLevel:9,Epoch: 163, Loss: 0.6703, Val: 0.9310,\n",
      "diffLevel:9,Epoch: 164, Loss: 0.6693, Val: 0.9310,\n",
      "diffLevel:9,Epoch: 165, Loss: 0.6698, Val: 0.9311,\n",
      "diffLevel:9,Epoch: 166, Loss: 0.6698, Val: 0.9311,\n",
      "diffLevel:9,Epoch: 167, Loss: 0.6697, Val: 0.9312,\n",
      "diffLevel:9,Epoch: 168, Loss: 0.6703, Val: 0.9312,\n",
      "diffLevel:9,Epoch: 169, Loss: 0.6692, Val: 0.9313,\n",
      "diffLevel:9,Epoch: 170, Loss: 0.6698, Val: 0.9313,\n",
      "diffLevel:9,Epoch: 171, Loss: 0.6698, Val: 0.9314,\n",
      "diffLevel:9,Epoch: 172, Loss: 0.6693, Val: 0.9314,\n",
      "diffLevel:9,Epoch: 173, Loss: 0.6696, Val: 0.9315,\n",
      "diffLevel:9,Epoch: 174, Loss: 0.6697, Val: 0.9315,\n",
      "diffLevel:9,Epoch: 175, Loss: 0.6694, Val: 0.9316,\n",
      "diffLevel:9,Epoch: 176, Loss: 0.6695, Val: 0.9316,\n",
      "diffLevel:9,Epoch: 177, Loss: 0.6691, Val: 0.9317,\n",
      "diffLevel:9,Epoch: 178, Loss: 0.6692, Val: 0.9317,\n",
      "diffLevel:9,Epoch: 179, Loss: 0.6690, Val: 0.9317,\n",
      "diffLevel:9,Epoch: 180, Loss: 0.6694, Val: 0.9318,\n",
      "diffLevel:9,Epoch: 181, Loss: 0.6689, Val: 0.9318,\n",
      "diffLevel:9,Epoch: 182, Loss: 0.6692, Val: 0.9319,\n",
      "diffLevel:9,Epoch: 183, Loss: 0.6696, Val: 0.9319,\n",
      "diffLevel:9,Epoch: 184, Loss: 0.6684, Val: 0.9319,\n",
      "diffLevel:9,Epoch: 185, Loss: 0.6697, Val: 0.9320,\n",
      "diffLevel:9,Epoch: 186, Loss: 0.6691, Val: 0.9320,\n",
      "diffLevel:9,Epoch: 187, Loss: 0.6692, Val: 0.9321,\n",
      "diffLevel:9,Epoch: 188, Loss: 0.6695, Val: 0.9321,\n",
      "diffLevel:9,Epoch: 189, Loss: 0.6693, Val: 0.9321,\n",
      "diffLevel:9,Epoch: 190, Loss: 0.6695, Val: 0.9322,\n",
      "diffLevel:9,Epoch: 191, Loss: 0.6695, Val: 0.9322,\n",
      "diffLevel:9,Epoch: 192, Loss: 0.6694, Val: 0.9323,\n",
      "diffLevel:9,Epoch: 193, Loss: 0.6690, Val: 0.9323,\n",
      "diffLevel:9,Epoch: 194, Loss: 0.6685, Val: 0.9324,\n",
      "diffLevel:9,Epoch: 195, Loss: 0.6689, Val: 0.9324,\n",
      "diffLevel:9,Epoch: 196, Loss: 0.6684, Val: 0.9325,\n",
      "diffLevel:9,Epoch: 197, Loss: 0.6696, Val: 0.9325,\n",
      "diffLevel:9,Epoch: 198, Loss: 0.6692, Val: 0.9326,\n",
      "diffLevel:9,Epoch: 199, Loss: 0.6694, Val: 0.9326,\n",
      "diffLevel:9,Epoch: 200, Loss: 0.6695, Val: 0.9326,\n",
      "diffLevel:9,Epoch: 201, Loss: 0.6685, Val: 0.9327,\n",
      "diffLevel:9,Epoch: 202, Loss: 0.6691, Val: 0.9327,\n",
      "diffLevel:9,Epoch: 203, Loss: 0.6690, Val: 0.9328,\n",
      "diffLevel:9,Epoch: 204, Loss: 0.6692, Val: 0.9328,\n",
      "diffLevel:9,Epoch: 205, Loss: 0.6687, Val: 0.9329,\n",
      "diffLevel:9,Epoch: 206, Loss: 0.6685, Val: 0.9329,\n",
      "diffLevel:9,Epoch: 207, Loss: 0.6684, Val: 0.9330,\n",
      "diffLevel:9,Epoch: 208, Loss: 0.6688, Val: 0.9330,\n",
      "diffLevel:9,Epoch: 209, Loss: 0.6691, Val: 0.9330,\n",
      "diffLevel:9,Epoch: 210, Loss: 0.6688, Val: 0.9330,\n",
      "diffLevel:9,Epoch: 211, Loss: 0.6691, Val: 0.9331,\n",
      "diffLevel:9,Epoch: 212, Loss: 0.6687, Val: 0.9331,\n",
      "diffLevel:9,Epoch: 213, Loss: 0.6692, Val: 0.9332,\n",
      "diffLevel:9,Epoch: 214, Loss: 0.6686, Val: 0.9332,\n",
      "diffLevel:9,Epoch: 215, Loss: 0.6687, Val: 0.9332,\n",
      "diffLevel:9,Epoch: 216, Loss: 0.6692, Val: 0.9332,\n",
      "diffLevel:9,Epoch: 217, Loss: 0.6688, Val: 0.9333,\n",
      "diffLevel:9,Epoch: 218, Loss: 0.6688, Val: 0.9333,\n",
      "diffLevel:9,Epoch: 219, Loss: 0.6686, Val: 0.9334,\n",
      "diffLevel:9,Epoch: 220, Loss: 0.6686, Val: 0.9334,\n",
      "diffLevel:9,Epoch: 221, Loss: 0.6687, Val: 0.9335,\n",
      "diffLevel:9,Epoch: 222, Loss: 0.6690, Val: 0.9335,\n",
      "diffLevel:9,Epoch: 223, Loss: 0.6690, Val: 0.9335,\n",
      "diffLevel:9,Epoch: 224, Loss: 0.6682, Val: 0.9336,\n",
      "diffLevel:9,Epoch: 225, Loss: 0.6688, Val: 0.9336,\n",
      "diffLevel:9,Epoch: 226, Loss: 0.6683, Val: 0.9337,\n",
      "diffLevel:9,Epoch: 227, Loss: 0.6686, Val: 0.9337,\n",
      "diffLevel:9,Epoch: 228, Loss: 0.6695, Val: 0.9337,\n",
      "diffLevel:9,Epoch: 229, Loss: 0.6687, Val: 0.9338,\n",
      "diffLevel:9,Epoch: 230, Loss: 0.6686, Val: 0.9338,\n",
      "diffLevel:9,Epoch: 231, Loss: 0.6696, Val: 0.9338,\n",
      "diffLevel:9,Epoch: 232, Loss: 0.6691, Val: 0.9339,\n",
      "diffLevel:9,Epoch: 233, Loss: 0.6687, Val: 0.9339,\n",
      "diffLevel:9,Epoch: 234, Loss: 0.6686, Val: 0.9340,\n",
      "diffLevel:9,Epoch: 235, Loss: 0.6687, Val: 0.9340,\n",
      "diffLevel:9,Epoch: 236, Loss: 0.6684, Val: 0.9341,\n",
      "diffLevel:9,Epoch: 237, Loss: 0.6684, Val: 0.9341,\n",
      "diffLevel:9,Epoch: 238, Loss: 0.6680, Val: 0.9341,\n",
      "diffLevel:9,Epoch: 239, Loss: 0.6685, Val: 0.9342,\n",
      "diffLevel:9,Epoch: 240, Loss: 0.6685, Val: 0.9342,\n",
      "diffLevel:9,Epoch: 241, Loss: 0.6680, Val: 0.9343,\n",
      "diffLevel:9,Epoch: 242, Loss: 0.6692, Val: 0.9343,\n",
      "diffLevel:9,Epoch: 243, Loss: 0.6683, Val: 0.9343,\n",
      "diffLevel:9,Epoch: 244, Loss: 0.6684, Val: 0.9344,\n",
      "diffLevel:9,Epoch: 245, Loss: 0.6689, Val: 0.9344,\n",
      "diffLevel:9,Epoch: 246, Loss: 0.6687, Val: 0.9344,\n",
      "diffLevel:9,Epoch: 247, Loss: 0.6684, Val: 0.9344,\n",
      "diffLevel:9,Epoch: 248, Loss: 0.6687, Val: 0.9345,\n",
      "diffLevel:9,Epoch: 249, Loss: 0.6683, Val: 0.9345,\n",
      "diffLevel:9,Epoch: 250, Loss: 0.6685, Val: 0.9345,\n",
      "diffLevel:9,Epoch: 251, Loss: 0.6683, Val: 0.9346,\n",
      "diffLevel:9,Epoch: 252, Loss: 0.6682, Val: 0.9346,\n",
      "diffLevel:9,Epoch: 253, Loss: 0.6686, Val: 0.9347,\n",
      "diffLevel:9,Epoch: 254, Loss: 0.6683, Val: 0.9347,\n",
      "diffLevel:9,Epoch: 255, Loss: 0.6679, Val: 0.9347,\n",
      "diffLevel:9,Epoch: 256, Loss: 0.6681, Val: 0.9348,\n",
      "diffLevel:9,Epoch: 257, Loss: 0.6688, Val: 0.9348,\n",
      "diffLevel:9,Epoch: 258, Loss: 0.6679, Val: 0.9348,\n",
      "diffLevel:9,Epoch: 259, Loss: 0.6675, Val: 0.9349,\n",
      "diffLevel:9,Epoch: 260, Loss: 0.6682, Val: 0.9349,\n",
      "diffLevel:9,Epoch: 261, Loss: 0.6681, Val: 0.9350,\n",
      "diffLevel:9,Epoch: 262, Loss: 0.6685, Val: 0.9350,\n",
      "diffLevel:9,Epoch: 263, Loss: 0.6676, Val: 0.9350,\n",
      "diffLevel:9,Epoch: 264, Loss: 0.6679, Val: 0.9351,\n",
      "diffLevel:9,Epoch: 265, Loss: 0.6682, Val: 0.9351,\n",
      "diffLevel:9,Epoch: 266, Loss: 0.6675, Val: 0.9351,\n",
      "diffLevel:9,Epoch: 267, Loss: 0.6686, Val: 0.9352,\n",
      "diffLevel:9,Epoch: 268, Loss: 0.6672, Val: 0.9352,\n",
      "diffLevel:9,Epoch: 269, Loss: 0.6676, Val: 0.9352,\n",
      "diffLevel:9,Epoch: 270, Loss: 0.6689, Val: 0.9353,\n",
      "diffLevel:9,Epoch: 271, Loss: 0.6685, Val: 0.9353,\n",
      "diffLevel:9,Epoch: 272, Loss: 0.6683, Val: 0.9353,\n",
      "diffLevel:9,Epoch: 273, Loss: 0.6685, Val: 0.9354,\n",
      "diffLevel:9,Epoch: 274, Loss: 0.6682, Val: 0.9354,\n",
      "diffLevel:9,Epoch: 275, Loss: 0.6681, Val: 0.9355,\n",
      "diffLevel:9,Epoch: 276, Loss: 0.6685, Val: 0.9355,\n",
      "diffLevel:9,Epoch: 277, Loss: 0.6682, Val: 0.9355,\n",
      "diffLevel:9,Epoch: 278, Loss: 0.6681, Val: 0.9356,\n",
      "diffLevel:9,Epoch: 279, Loss: 0.6677, Val: 0.9356,\n",
      "diffLevel:9,Epoch: 280, Loss: 0.6670, Val: 0.9357,\n",
      "diffLevel:9,Epoch: 281, Loss: 0.6682, Val: 0.9357,\n",
      "diffLevel:9,Epoch: 282, Loss: 0.6677, Val: 0.9357,\n",
      "diffLevel:9,Epoch: 283, Loss: 0.6684, Val: 0.9357,\n",
      "diffLevel:9,Epoch: 284, Loss: 0.6680, Val: 0.9358,\n",
      "diffLevel:9,Epoch: 285, Loss: 0.6677, Val: 0.9358,\n",
      "diffLevel:9,Epoch: 286, Loss: 0.6685, Val: 0.9358,\n",
      "diffLevel:9,Epoch: 287, Loss: 0.6680, Val: 0.9359,\n",
      "diffLevel:9,Epoch: 288, Loss: 0.6673, Val: 0.9359,\n",
      "diffLevel:9,Epoch: 289, Loss: 0.6681, Val: 0.9360,\n",
      "diffLevel:9,Epoch: 290, Loss: 0.6675, Val: 0.9360,\n",
      "diffLevel:9,Epoch: 291, Loss: 0.6671, Val: 0.9361,\n",
      "diffLevel:9,Epoch: 292, Loss: 0.6677, Val: 0.9361,\n",
      "diffLevel:9,Epoch: 293, Loss: 0.6674, Val: 0.9361,\n",
      "diffLevel:9,Epoch: 294, Loss: 0.6679, Val: 0.9362,\n",
      "diffLevel:9,Epoch: 295, Loss: 0.6683, Val: 0.9362,\n",
      "diffLevel:9,Epoch: 296, Loss: 0.6678, Val: 0.9362,\n",
      "diffLevel:9,Epoch: 297, Loss: 0.6680, Val: 0.9363,\n",
      "diffLevel:9,Epoch: 298, Loss: 0.6678, Val: 0.9363,\n",
      "diffLevel:9,Epoch: 299, Loss: 0.6683, Val: 0.9364,\n",
      "diffLevel:9,Epoch: 300, Loss: 0.6678, Val: 0.9364,\n",
      "diffLevel:9,Epoch: 301, Loss: 0.6675, Val: 0.9364,\n",
      "diffLevel:9,Epoch: 302, Loss: 0.6676, Val: 0.9365,\n",
      "diffLevel:9,Epoch: 303, Loss: 0.6680, Val: 0.9365,\n",
      "diffLevel:9,Epoch: 304, Loss: 0.6680, Val: 0.9366,\n",
      "diffLevel:9,Epoch: 305, Loss: 0.6668, Val: 0.9366,\n",
      "diffLevel:9,Epoch: 306, Loss: 0.6678, Val: 0.9366,\n",
      "diffLevel:9,Epoch: 307, Loss: 0.6668, Val: 0.9367,\n",
      "diffLevel:9,Epoch: 308, Loss: 0.6678, Val: 0.9367,\n",
      "diffLevel:9,Epoch: 309, Loss: 0.6676, Val: 0.9367,\n",
      "diffLevel:9,Epoch: 310, Loss: 0.6677, Val: 0.9368,\n",
      "diffLevel:9,Epoch: 311, Loss: 0.6671, Val: 0.9368,\n",
      "diffLevel:9,Epoch: 312, Loss: 0.6673, Val: 0.9368,\n",
      "diffLevel:9,Epoch: 313, Loss: 0.6682, Val: 0.9369,\n",
      "diffLevel:9,Epoch: 314, Loss: 0.6678, Val: 0.9369,\n",
      "diffLevel:9,Epoch: 315, Loss: 0.6674, Val: 0.9369,\n",
      "diffLevel:9,Epoch: 316, Loss: 0.6677, Val: 0.9370,\n",
      "diffLevel:9,Epoch: 317, Loss: 0.6674, Val: 0.9370,\n",
      "diffLevel:9,Epoch: 318, Loss: 0.6673, Val: 0.9371,\n",
      "diffLevel:9,Epoch: 319, Loss: 0.6673, Val: 0.9371,\n",
      "diffLevel:9,Epoch: 320, Loss: 0.6677, Val: 0.9371,\n",
      "diffLevel:9,Epoch: 321, Loss: 0.6676, Val: 0.9371,\n",
      "diffLevel:9,Epoch: 322, Loss: 0.6670, Val: 0.9372,\n",
      "diffLevel:9,Epoch: 323, Loss: 0.6670, Val: 0.9372,\n",
      "diffLevel:9,Epoch: 324, Loss: 0.6671, Val: 0.9372,\n",
      "diffLevel:9,Epoch: 325, Loss: 0.6673, Val: 0.9372,\n",
      "diffLevel:9,Epoch: 326, Loss: 0.6670, Val: 0.9372,\n",
      "diffLevel:9,Epoch: 327, Loss: 0.6673, Val: 0.9373,\n",
      "diffLevel:9,Epoch: 328, Loss: 0.6675, Val: 0.9373,\n",
      "diffLevel:9,Epoch: 329, Loss: 0.6675, Val: 0.9373,\n",
      "diffLevel:9,Epoch: 330, Loss: 0.6680, Val: 0.9373,\n",
      "diffLevel:9,Epoch: 331, Loss: 0.6676, Val: 0.9374,\n",
      "diffLevel:9,Epoch: 332, Loss: 0.6666, Val: 0.9374,\n",
      "diffLevel:9,Epoch: 333, Loss: 0.6673, Val: 0.9374,\n",
      "diffLevel:9,Epoch: 334, Loss: 0.6674, Val: 0.9375,\n",
      "diffLevel:9,Epoch: 335, Loss: 0.6667, Val: 0.9375,\n",
      "diffLevel:9,Epoch: 336, Loss: 0.6670, Val: 0.9375,\n",
      "diffLevel:9,Epoch: 337, Loss: 0.6664, Val: 0.9375,\n",
      "diffLevel:9,Epoch: 338, Loss: 0.6673, Val: 0.9376,\n",
      "diffLevel:9,Epoch: 339, Loss: 0.6673, Val: 0.9376,\n",
      "diffLevel:9,Epoch: 340, Loss: 0.6666, Val: 0.9376,\n",
      "diffLevel:9,Epoch: 341, Loss: 0.6672, Val: 0.9376,\n",
      "diffLevel:9,Epoch: 342, Loss: 0.6672, Val: 0.9376,\n",
      "diffLevel:9,Epoch: 343, Loss: 0.6676, Val: 0.9377,\n",
      "diffLevel:9,Epoch: 344, Loss: 0.6663, Val: 0.9377,\n",
      "diffLevel:9,Epoch: 345, Loss: 0.6670, Val: 0.9377,\n",
      "diffLevel:9,Epoch: 346, Loss: 0.6675, Val: 0.9377,\n",
      "diffLevel:9,Epoch: 347, Loss: 0.6667, Val: 0.9378,\n",
      "diffLevel:9,Epoch: 348, Loss: 0.6674, Val: 0.9378,\n",
      "diffLevel:9,Epoch: 349, Loss: 0.6670, Val: 0.9378,\n",
      "diffLevel:9,Epoch: 350, Loss: 0.6666, Val: 0.9379,\n",
      "diffLevel:9,Epoch: 351, Loss: 0.6668, Val: 0.9379,\n",
      "diffLevel:9,Epoch: 352, Loss: 0.6673, Val: 0.9379,\n",
      "diffLevel:9,Epoch: 353, Loss: 0.6668, Val: 0.9379,\n",
      "diffLevel:9,Epoch: 354, Loss: 0.6664, Val: 0.9380,\n",
      "diffLevel:9,Epoch: 355, Loss: 0.6669, Val: 0.9380,\n",
      "diffLevel:9,Epoch: 356, Loss: 0.6667, Val: 0.9380,\n",
      "diffLevel:9,Epoch: 357, Loss: 0.6662, Val: 0.9380,\n",
      "diffLevel:9,Epoch: 358, Loss: 0.6666, Val: 0.9381,\n",
      "diffLevel:9,Epoch: 359, Loss: 0.6674, Val: 0.9381,\n",
      "diffLevel:9,Epoch: 360, Loss: 0.6679, Val: 0.9381,\n",
      "diffLevel:9,Epoch: 361, Loss: 0.6669, Val: 0.9382,\n",
      "diffLevel:9,Epoch: 362, Loss: 0.6667, Val: 0.9382,\n",
      "diffLevel:9,Epoch: 363, Loss: 0.6668, Val: 0.9382,\n",
      "diffLevel:9,Epoch: 364, Loss: 0.6665, Val: 0.9383,\n",
      "diffLevel:9,Epoch: 365, Loss: 0.6670, Val: 0.9383,\n",
      "diffLevel:9,Epoch: 366, Loss: 0.6670, Val: 0.9383,\n",
      "diffLevel:9,Epoch: 367, Loss: 0.6669, Val: 0.9384,\n",
      "diffLevel:9,Epoch: 368, Loss: 0.6671, Val: 0.9384,\n",
      "diffLevel:9,Epoch: 369, Loss: 0.6667, Val: 0.9384,\n",
      "diffLevel:9,Epoch: 370, Loss: 0.6672, Val: 0.9385,\n",
      "diffLevel:9,Epoch: 371, Loss: 0.6666, Val: 0.9385,\n",
      "diffLevel:9,Epoch: 372, Loss: 0.6667, Val: 0.9385,\n",
      "diffLevel:9,Epoch: 373, Loss: 0.6671, Val: 0.9386,\n",
      "diffLevel:9,Epoch: 374, Loss: 0.6661, Val: 0.9386,\n",
      "diffLevel:9,Epoch: 375, Loss: 0.6673, Val: 0.9387,\n",
      "diffLevel:9,Epoch: 376, Loss: 0.6671, Val: 0.9387,\n",
      "diffLevel:9,Epoch: 377, Loss: 0.6673, Val: 0.9387,\n",
      "diffLevel:9,Epoch: 378, Loss: 0.6662, Val: 0.9388,\n",
      "diffLevel:9,Epoch: 379, Loss: 0.6665, Val: 0.9388,\n",
      "diffLevel:9,Epoch: 380, Loss: 0.6665, Val: 0.9388,\n",
      "diffLevel:9,Epoch: 381, Loss: 0.6662, Val: 0.9388,\n",
      "diffLevel:9,Epoch: 382, Loss: 0.6661, Val: 0.9389,\n",
      "diffLevel:9,Epoch: 383, Loss: 0.6671, Val: 0.9389,\n",
      "diffLevel:9,Epoch: 384, Loss: 0.6663, Val: 0.9389,\n",
      "diffLevel:9,Epoch: 385, Loss: 0.6664, Val: 0.9389,\n",
      "diffLevel:9,Epoch: 386, Loss: 0.6662, Val: 0.9390,\n",
      "diffLevel:9,Epoch: 387, Loss: 0.6664, Val: 0.9390,\n",
      "diffLevel:9,Epoch: 388, Loss: 0.6660, Val: 0.9390,\n",
      "diffLevel:9,Epoch: 389, Loss: 0.6672, Val: 0.9391,\n",
      "diffLevel:9,Epoch: 390, Loss: 0.6667, Val: 0.9391,\n",
      "diffLevel:9,Epoch: 391, Loss: 0.6666, Val: 0.9391,\n",
      "diffLevel:9,Epoch: 392, Loss: 0.6667, Val: 0.9392,\n",
      "diffLevel:9,Epoch: 393, Loss: 0.6667, Val: 0.9392,\n",
      "diffLevel:9,Epoch: 394, Loss: 0.6663, Val: 0.9392,\n",
      "diffLevel:9,Epoch: 395, Loss: 0.6668, Val: 0.9392,\n",
      "diffLevel:9,Epoch: 396, Loss: 0.6665, Val: 0.9393,\n",
      "diffLevel:9,Epoch: 397, Loss: 0.6668, Val: 0.9393,\n",
      "diffLevel:9,Epoch: 398, Loss: 0.6664, Val: 0.9393,\n",
      "diffLevel:9,Epoch: 399, Loss: 0.6666, Val: 0.9394,\n",
      "diffLevel:9,Epoch: 400, Loss: 0.6664, Val: 0.9394,\n",
      "diffLevel:9,Epoch: 401, Loss: 0.6669, Val: 0.9394,\n",
      "diffLevel:9,Epoch: 402, Loss: 0.6669, Val: 0.9395,\n",
      "diffLevel:9,Epoch: 403, Loss: 0.6667, Val: 0.9395,\n",
      "diffLevel:9,Epoch: 404, Loss: 0.6661, Val: 0.9395,\n",
      "diffLevel:9,Epoch: 405, Loss: 0.6657, Val: 0.9396,\n",
      "diffLevel:9,Epoch: 406, Loss: 0.6663, Val: 0.9396,\n",
      "diffLevel:9,Epoch: 407, Loss: 0.6670, Val: 0.9396,\n",
      "diffLevel:9,Epoch: 408, Loss: 0.6667, Val: 0.9396,\n",
      "diffLevel:9,Epoch: 409, Loss: 0.6661, Val: 0.9397,\n",
      "diffLevel:9,Epoch: 410, Loss: 0.6665, Val: 0.9397,\n",
      "diffLevel:9,Epoch: 411, Loss: 0.6659, Val: 0.9397,\n",
      "diffLevel:9,Epoch: 412, Loss: 0.6662, Val: 0.9398,\n",
      "diffLevel:9,Epoch: 413, Loss: 0.6660, Val: 0.9398,\n",
      "diffLevel:9,Epoch: 414, Loss: 0.6666, Val: 0.9398,\n",
      "diffLevel:9,Epoch: 415, Loss: 0.6663, Val: 0.9399,\n",
      "diffLevel:9,Epoch: 416, Loss: 0.6657, Val: 0.9399,\n",
      "diffLevel:9,Epoch: 417, Loss: 0.6663, Val: 0.9399,\n",
      "diffLevel:9,Epoch: 418, Loss: 0.6656, Val: 0.9400,\n",
      "diffLevel:9,Epoch: 419, Loss: 0.6661, Val: 0.9400,\n",
      "diffLevel:9,Epoch: 420, Loss: 0.6662, Val: 0.9400,\n",
      "diffLevel:9,Epoch: 421, Loss: 0.6666, Val: 0.9400,\n",
      "diffLevel:9,Epoch: 422, Loss: 0.6663, Val: 0.9401,\n",
      "diffLevel:9,Epoch: 423, Loss: 0.6662, Val: 0.9401,\n",
      "diffLevel:9,Epoch: 424, Loss: 0.6662, Val: 0.9401,\n",
      "diffLevel:9,Epoch: 425, Loss: 0.6668, Val: 0.9402,\n",
      "diffLevel:9,Epoch: 426, Loss: 0.6665, Val: 0.9402,\n",
      "diffLevel:9,Epoch: 427, Loss: 0.6658, Val: 0.9402,\n",
      "diffLevel:9,Epoch: 428, Loss: 0.6666, Val: 0.9403,\n",
      "diffLevel:9,Epoch: 429, Loss: 0.6653, Val: 0.9403,\n",
      "diffLevel:9,Epoch: 430, Loss: 0.6671, Val: 0.9403,\n",
      "diffLevel:9,Epoch: 431, Loss: 0.6667, Val: 0.9404,\n",
      "diffLevel:9,Epoch: 432, Loss: 0.6665, Val: 0.9404,\n",
      "diffLevel:9,Epoch: 433, Loss: 0.6656, Val: 0.9404,\n",
      "diffLevel:9,Epoch: 434, Loss: 0.6660, Val: 0.9404,\n",
      "diffLevel:9,Epoch: 435, Loss: 0.6660, Val: 0.9405,\n",
      "diffLevel:9,Epoch: 436, Loss: 0.6662, Val: 0.9405,\n",
      "diffLevel:9,Epoch: 437, Loss: 0.6667, Val: 0.9405,\n",
      "diffLevel:9,Epoch: 438, Loss: 0.6661, Val: 0.9406,\n",
      "diffLevel:9,Epoch: 439, Loss: 0.6654, Val: 0.9406,\n",
      "diffLevel:9,Epoch: 440, Loss: 0.6661, Val: 0.9406,\n",
      "diffLevel:9,Epoch: 441, Loss: 0.6660, Val: 0.9406,\n",
      "diffLevel:9,Epoch: 442, Loss: 0.6663, Val: 0.9407,\n",
      "diffLevel:9,Epoch: 443, Loss: 0.6662, Val: 0.9407,\n",
      "diffLevel:9,Epoch: 444, Loss: 0.6664, Val: 0.9407,\n",
      "diffLevel:9,Epoch: 445, Loss: 0.6665, Val: 0.9407,\n",
      "diffLevel:9,Epoch: 446, Loss: 0.6660, Val: 0.9407,\n",
      "diffLevel:9,Epoch: 447, Loss: 0.6667, Val: 0.9408,\n",
      "diffLevel:9,Epoch: 448, Loss: 0.6658, Val: 0.9408,\n",
      "diffLevel:9,Epoch: 449, Loss: 0.6657, Val: 0.9408,\n",
      "diffLevel:9,Epoch: 450, Loss: 0.6661, Val: 0.9408,\n",
      "diffLevel:9,Epoch: 451, Loss: 0.6661, Val: 0.9408,\n",
      "diffLevel:9,Epoch: 452, Loss: 0.6654, Val: 0.9409,\n",
      "diffLevel:9,Epoch: 453, Loss: 0.6658, Val: 0.9409,\n",
      "diffLevel:9,Epoch: 454, Loss: 0.6664, Val: 0.9409,\n",
      "diffLevel:9,Epoch: 455, Loss: 0.6657, Val: 0.9410,\n",
      "diffLevel:9,Epoch: 456, Loss: 0.6658, Val: 0.9410,\n",
      "diffLevel:9,Epoch: 457, Loss: 0.6656, Val: 0.9410,\n",
      "diffLevel:9,Epoch: 458, Loss: 0.6655, Val: 0.9410,\n",
      "diffLevel:9,Epoch: 459, Loss: 0.6656, Val: 0.9410,\n",
      "diffLevel:9,Epoch: 460, Loss: 0.6662, Val: 0.9411,\n",
      "diffLevel:9,Epoch: 461, Loss: 0.6662, Val: 0.9411,\n",
      "diffLevel:9,Epoch: 462, Loss: 0.6658, Val: 0.9411,\n",
      "diffLevel:9,Epoch: 463, Loss: 0.6659, Val: 0.9411,\n",
      "diffLevel:9,Epoch: 464, Loss: 0.6658, Val: 0.9412,\n",
      "diffLevel:9,Epoch: 465, Loss: 0.6657, Val: 0.9412,\n",
      "diffLevel:9,Epoch: 466, Loss: 0.6661, Val: 0.9412,\n",
      "diffLevel:9,Epoch: 467, Loss: 0.6660, Val: 0.9412,\n",
      "diffLevel:9,Epoch: 468, Loss: 0.6659, Val: 0.9413,\n",
      "diffLevel:9,Epoch: 469, Loss: 0.6653, Val: 0.9413,\n",
      "diffLevel:9,Epoch: 470, Loss: 0.6661, Val: 0.9413,\n",
      "diffLevel:9,Epoch: 471, Loss: 0.6658, Val: 0.9413,\n",
      "diffLevel:9,Epoch: 472, Loss: 0.6659, Val: 0.9414,\n",
      "diffLevel:9,Epoch: 473, Loss: 0.6662, Val: 0.9414,\n",
      "diffLevel:9,Epoch: 474, Loss: 0.6658, Val: 0.9414,\n",
      "diffLevel:9,Epoch: 475, Loss: 0.6651, Val: 0.9414,\n",
      "diffLevel:9,Epoch: 476, Loss: 0.6654, Val: 0.9415,\n",
      "diffLevel:9,Epoch: 477, Loss: 0.6658, Val: 0.9415,\n",
      "diffLevel:9,Epoch: 478, Loss: 0.6661, Val: 0.9415,\n",
      "diffLevel:9,Epoch: 479, Loss: 0.6661, Val: 0.9416,\n",
      "diffLevel:9,Epoch: 480, Loss: 0.6648, Val: 0.9416,\n",
      "diffLevel:9,Epoch: 481, Loss: 0.6654, Val: 0.9416,\n",
      "diffLevel:9,Epoch: 482, Loss: 0.6656, Val: 0.9416,\n",
      "diffLevel:9,Epoch: 483, Loss: 0.6646, Val: 0.9417,\n",
      "diffLevel:9,Epoch: 484, Loss: 0.6655, Val: 0.9417,\n",
      "diffLevel:9,Epoch: 485, Loss: 0.6656, Val: 0.9417,\n",
      "diffLevel:9,Epoch: 486, Loss: 0.6655, Val: 0.9417,\n",
      "diffLevel:9,Epoch: 487, Loss: 0.6653, Val: 0.9417,\n",
      "diffLevel:9,Epoch: 488, Loss: 0.6657, Val: 0.9417,\n",
      "diffLevel:9,Epoch: 489, Loss: 0.6657, Val: 0.9418,\n",
      "diffLevel:9,Epoch: 490, Loss: 0.6659, Val: 0.9418,\n",
      "diffLevel:9,Epoch: 491, Loss: 0.6651, Val: 0.9418,\n",
      "diffLevel:9,Epoch: 492, Loss: 0.6653, Val: 0.9418,\n",
      "diffLevel:9,Epoch: 493, Loss: 0.6656, Val: 0.9418,\n",
      "diffLevel:9,Epoch: 494, Loss: 0.6655, Val: 0.9419,\n",
      "diffLevel:9,Epoch: 495, Loss: 0.6650, Val: 0.9419,\n",
      "diffLevel:9,Epoch: 496, Loss: 0.6654, Val: 0.9419,\n",
      "diffLevel:9,Epoch: 497, Loss: 0.6660, Val: 0.9419,\n",
      "diffLevel:9,Epoch: 498, Loss: 0.6655, Val: 0.9420,\n",
      "diffLevel:9,Epoch: 499, Loss: 0.6655, Val: 0.9420,\n",
      "diffLevel:9,Epoch: 500, Loss: 0.6647, Val: 0.9420,\n",
      "diffLevel:9,Epoch: 501, Loss: 0.6648, Val: 0.9420,\n",
      "diffLevel:9,Epoch: 502, Loss: 0.6654, Val: 0.9421,\n",
      "diffLevel:9,Epoch: 503, Loss: 0.6649, Val: 0.9421,\n",
      "diffLevel:9,Epoch: 504, Loss: 0.6658, Val: 0.9421,\n",
      "diffLevel:9,Epoch: 505, Loss: 0.6656, Val: 0.9421,\n",
      "diffLevel:9,Epoch: 506, Loss: 0.6658, Val: 0.9422,\n",
      "diffLevel:9,Epoch: 507, Loss: 0.6658, Val: 0.9422,\n",
      "diffLevel:9,Epoch: 508, Loss: 0.6657, Val: 0.9422,\n",
      "diffLevel:9,Epoch: 509, Loss: 0.6661, Val: 0.9423,\n",
      "diffLevel:9,Epoch: 510, Loss: 0.6654, Val: 0.9423,\n",
      "diffLevel:9,Epoch: 511, Loss: 0.6653, Val: 0.9424,\n",
      "diffLevel:9,Epoch: 512, Loss: 0.6654, Val: 0.9424,\n",
      "diffLevel:9,Epoch: 513, Loss: 0.6657, Val: 0.9425,\n",
      "diffLevel:9,Epoch: 514, Loss: 0.6653, Val: 0.9425,\n",
      "diffLevel:9,Epoch: 515, Loss: 0.6650, Val: 0.9425,\n",
      "diffLevel:9,Epoch: 516, Loss: 0.6662, Val: 0.9426,\n",
      "diffLevel:9,Epoch: 517, Loss: 0.6653, Val: 0.9426,\n",
      "diffLevel:9,Epoch: 518, Loss: 0.6653, Val: 0.9427,\n",
      "diffLevel:9,Epoch: 519, Loss: 0.6652, Val: 0.9427,\n",
      "diffLevel:9,Epoch: 520, Loss: 0.6663, Val: 0.9427,\n",
      "diffLevel:9,Epoch: 521, Loss: 0.6653, Val: 0.9428,\n",
      "diffLevel:9,Epoch: 522, Loss: 0.6654, Val: 0.9428,\n",
      "diffLevel:9,Epoch: 523, Loss: 0.6653, Val: 0.9428,\n",
      "diffLevel:9,Epoch: 524, Loss: 0.6650, Val: 0.9429,\n",
      "diffLevel:9,Epoch: 525, Loss: 0.6659, Val: 0.9429,\n",
      "diffLevel:9,Epoch: 526, Loss: 0.6648, Val: 0.9429,\n",
      "diffLevel:9,Epoch: 527, Loss: 0.6649, Val: 0.9430,\n",
      "diffLevel:9,Epoch: 528, Loss: 0.6660, Val: 0.9430,\n",
      "diffLevel:9,Epoch: 529, Loss: 0.6650, Val: 0.9431,\n",
      "diffLevel:9,Epoch: 530, Loss: 0.6658, Val: 0.9431,\n",
      "diffLevel:9,Epoch: 531, Loss: 0.6651, Val: 0.9431,\n",
      "diffLevel:9,Epoch: 532, Loss: 0.6661, Val: 0.9432,\n",
      "diffLevel:9,Epoch: 533, Loss: 0.6651, Val: 0.9432,\n",
      "diffLevel:9,Epoch: 534, Loss: 0.6648, Val: 0.9432,\n",
      "diffLevel:9,Epoch: 535, Loss: 0.6655, Val: 0.9433,\n",
      "diffLevel:9,Epoch: 536, Loss: 0.6648, Val: 0.9433,\n",
      "diffLevel:9,Epoch: 537, Loss: 0.6655, Val: 0.9433,\n",
      "diffLevel:9,Epoch: 538, Loss: 0.6650, Val: 0.9434,\n",
      "diffLevel:9,Epoch: 539, Loss: 0.6655, Val: 0.9434,\n",
      "diffLevel:9,Epoch: 540, Loss: 0.6651, Val: 0.9434,\n",
      "diffLevel:9,Epoch: 541, Loss: 0.6653, Val: 0.9435,\n",
      "diffLevel:9,Epoch: 542, Loss: 0.6648, Val: 0.9435,\n",
      "diffLevel:9,Epoch: 543, Loss: 0.6660, Val: 0.9435,\n",
      "diffLevel:9,Epoch: 544, Loss: 0.6657, Val: 0.9435,\n",
      "diffLevel:9,Epoch: 545, Loss: 0.6650, Val: 0.9436,\n",
      "diffLevel:9,Epoch: 546, Loss: 0.6652, Val: 0.9436,\n",
      "diffLevel:9,Epoch: 547, Loss: 0.6654, Val: 0.9436,\n",
      "diffLevel:9,Epoch: 548, Loss: 0.6651, Val: 0.9437,\n",
      "diffLevel:9,Epoch: 549, Loss: 0.6652, Val: 0.9437,\n",
      "diffLevel:9,Epoch: 550, Loss: 0.6646, Val: 0.9437,\n",
      "diffLevel:9,Epoch: 551, Loss: 0.6647, Val: 0.9437,\n",
      "diffLevel:9,Epoch: 552, Loss: 0.6645, Val: 0.9437,\n",
      "diffLevel:9,Epoch: 553, Loss: 0.6656, Val: 0.9438,\n",
      "diffLevel:9,Epoch: 554, Loss: 0.6651, Val: 0.9438,\n",
      "diffLevel:9,Epoch: 555, Loss: 0.6651, Val: 0.9438,\n",
      "diffLevel:9,Epoch: 556, Loss: 0.6650, Val: 0.9438,\n",
      "diffLevel:9,Epoch: 557, Loss: 0.6650, Val: 0.9438,\n",
      "diffLevel:9,Epoch: 558, Loss: 0.6652, Val: 0.9439,\n",
      "diffLevel:9,Epoch: 559, Loss: 0.6645, Val: 0.9439,\n",
      "diffLevel:9,Epoch: 560, Loss: 0.6647, Val: 0.9439,\n",
      "diffLevel:9,Epoch: 561, Loss: 0.6643, Val: 0.9439,\n",
      "diffLevel:9,Epoch: 562, Loss: 0.6652, Val: 0.9439,\n",
      "diffLevel:9,Epoch: 563, Loss: 0.6646, Val: 0.9439,\n",
      "diffLevel:9,Epoch: 564, Loss: 0.6656, Val: 0.9439,\n",
      "diffLevel:9,Epoch: 565, Loss: 0.6652, Val: 0.9439,\n",
      "diffLevel:9,Epoch: 566, Loss: 0.6649, Val: 0.9440,\n",
      "diffLevel:9,Epoch: 567, Loss: 0.6650, Val: 0.9440,\n",
      "diffLevel:9,Epoch: 568, Loss: 0.6644, Val: 0.9440,\n",
      "diffLevel:9,Epoch: 569, Loss: 0.6648, Val: 0.9440,\n",
      "diffLevel:9,Epoch: 570, Loss: 0.6651, Val: 0.9441,\n",
      "diffLevel:9,Epoch: 571, Loss: 0.6650, Val: 0.9441,\n",
      "diffLevel:9,Epoch: 572, Loss: 0.6653, Val: 0.9441,\n",
      "diffLevel:9,Epoch: 573, Loss: 0.6645, Val: 0.9441,\n",
      "diffLevel:9,Epoch: 574, Loss: 0.6658, Val: 0.9441,\n",
      "diffLevel:9,Epoch: 575, Loss: 0.6650, Val: 0.9442,\n",
      "diffLevel:9,Epoch: 576, Loss: 0.6651, Val: 0.9442,\n",
      "diffLevel:9,Epoch: 577, Loss: 0.6650, Val: 0.9442,\n",
      "diffLevel:9,Epoch: 578, Loss: 0.6642, Val: 0.9443,\n",
      "diffLevel:9,Epoch: 579, Loss: 0.6649, Val: 0.9443,\n",
      "diffLevel:9,Epoch: 580, Loss: 0.6642, Val: 0.9443,\n",
      "diffLevel:9,Epoch: 581, Loss: 0.6641, Val: 0.9443,\n",
      "diffLevel:9,Epoch: 582, Loss: 0.6649, Val: 0.9444,\n",
      "diffLevel:9,Epoch: 583, Loss: 0.6647, Val: 0.9444,\n",
      "diffLevel:9,Epoch: 584, Loss: 0.6653, Val: 0.9444,\n",
      "diffLevel:9,Epoch: 585, Loss: 0.6653, Val: 0.9445,\n",
      "diffLevel:9,Epoch: 586, Loss: 0.6654, Val: 0.9445,\n",
      "diffLevel:9,Epoch: 587, Loss: 0.6643, Val: 0.9445,\n",
      "diffLevel:9,Epoch: 588, Loss: 0.6644, Val: 0.9445,\n",
      "diffLevel:9,Epoch: 589, Loss: 0.6643, Val: 0.9445,\n",
      "diffLevel:9,Epoch: 590, Loss: 0.6647, Val: 0.9445,\n",
      "diffLevel:9,Epoch: 591, Loss: 0.6647, Val: 0.9446,\n",
      "diffLevel:9,Epoch: 592, Loss: 0.6649, Val: 0.9446,\n",
      "diffLevel:9,Epoch: 593, Loss: 0.6648, Val: 0.9446,\n",
      "diffLevel:9,Epoch: 594, Loss: 0.6654, Val: 0.9446,\n",
      "diffLevel:9,Epoch: 595, Loss: 0.6648, Val: 0.9447,\n",
      "diffLevel:9,Epoch: 596, Loss: 0.6647, Val: 0.9447,\n",
      "diffLevel:9,Epoch: 597, Loss: 0.6639, Val: 0.9447,\n",
      "diffLevel:9,Epoch: 598, Loss: 0.6647, Val: 0.9447,\n",
      "diffLevel:9,Epoch: 599, Loss: 0.6651, Val: 0.9448,\n",
      "diffLevel:9,Epoch: 600, Loss: 0.6638, Val: 0.9448,\n",
      "diffLevel:9,Epoch: 601, Loss: 0.6645, Val: 0.9448,\n",
      "diffLevel:9,Epoch: 602, Loss: 0.6642, Val: 0.9448,\n",
      "diffLevel:9,Epoch: 603, Loss: 0.6647, Val: 0.9449,\n",
      "diffLevel:9,Epoch: 604, Loss: 0.6646, Val: 0.9449,\n",
      "diffLevel:9,Epoch: 605, Loss: 0.6647, Val: 0.9449,\n",
      "diffLevel:9,Epoch: 606, Loss: 0.6644, Val: 0.9449,\n",
      "diffLevel:9,Epoch: 607, Loss: 0.6639, Val: 0.9450,\n",
      "diffLevel:9,Epoch: 608, Loss: 0.6651, Val: 0.9450,\n",
      "diffLevel:9,Epoch: 609, Loss: 0.6650, Val: 0.9450,\n",
      "diffLevel:9,Epoch: 610, Loss: 0.6641, Val: 0.9450,\n",
      "diffLevel:9,Epoch: 611, Loss: 0.6648, Val: 0.9451,\n",
      "diffLevel:9,Epoch: 612, Loss: 0.6646, Val: 0.9451,\n",
      "diffLevel:9,Epoch: 613, Loss: 0.6643, Val: 0.9451,\n",
      "diffLevel:9,Epoch: 614, Loss: 0.6649, Val: 0.9451,\n",
      "diffLevel:9,Epoch: 615, Loss: 0.6648, Val: 0.9451,\n",
      "diffLevel:9,Epoch: 616, Loss: 0.6645, Val: 0.9451,\n",
      "diffLevel:9,Epoch: 617, Loss: 0.6643, Val: 0.9452,\n",
      "diffLevel:9,Epoch: 618, Loss: 0.6644, Val: 0.9452,\n",
      "diffLevel:9,Epoch: 619, Loss: 0.6643, Val: 0.9452,\n",
      "diffLevel:9,Epoch: 620, Loss: 0.6650, Val: 0.9452,\n",
      "diffLevel:9,Epoch: 621, Loss: 0.6643, Val: 0.9452,\n",
      "diffLevel:9,Epoch: 622, Loss: 0.6643, Val: 0.9452,\n",
      "diffLevel:9,Epoch: 623, Loss: 0.6648, Val: 0.9452,\n",
      "diffLevel:9,Epoch: 624, Loss: 0.6649, Val: 0.9452,\n",
      "diffLevel:9,Epoch: 625, Loss: 0.6646, Val: 0.9453,\n",
      "diffLevel:9,Epoch: 626, Loss: 0.6644, Val: 0.9453,\n",
      "diffLevel:9,Epoch: 627, Loss: 0.6640, Val: 0.9453,\n",
      "diffLevel:9,Epoch: 628, Loss: 0.6646, Val: 0.9453,\n",
      "diffLevel:9,Epoch: 629, Loss: 0.6648, Val: 0.9454,\n",
      "diffLevel:9,Epoch: 630, Loss: 0.6642, Val: 0.9454,\n",
      "diffLevel:9,Epoch: 631, Loss: 0.6641, Val: 0.9454,\n",
      "diffLevel:9,Epoch: 632, Loss: 0.6644, Val: 0.9454,\n",
      "diffLevel:9,Epoch: 633, Loss: 0.6642, Val: 0.9455,\n",
      "diffLevel:9,Epoch: 634, Loss: 0.6641, Val: 0.9455,\n",
      "diffLevel:9,Epoch: 635, Loss: 0.6639, Val: 0.9455,\n",
      "diffLevel:9,Epoch: 636, Loss: 0.6644, Val: 0.9455,\n",
      "diffLevel:9,Epoch: 637, Loss: 0.6640, Val: 0.9455,\n",
      "diffLevel:9,Epoch: 638, Loss: 0.6643, Val: 0.9456,\n",
      "diffLevel:9,Epoch: 639, Loss: 0.6648, Val: 0.9456,\n",
      "diffLevel:9,Epoch: 640, Loss: 0.6635, Val: 0.9456,\n",
      "diffLevel:9,Epoch: 641, Loss: 0.6637, Val: 0.9456,\n",
      "diffLevel:9,Epoch: 642, Loss: 0.6643, Val: 0.9456,\n",
      "diffLevel:9,Epoch: 643, Loss: 0.6652, Val: 0.9457,\n",
      "diffLevel:9,Epoch: 644, Loss: 0.6649, Val: 0.9457,\n",
      "diffLevel:9,Epoch: 645, Loss: 0.6648, Val: 0.9457,\n",
      "diffLevel:9,Epoch: 646, Loss: 0.6647, Val: 0.9458,\n",
      "diffLevel:9,Epoch: 647, Loss: 0.6643, Val: 0.9458,\n",
      "diffLevel:9,Epoch: 648, Loss: 0.6644, Val: 0.9458,\n",
      "diffLevel:9,Epoch: 649, Loss: 0.6649, Val: 0.9458,\n",
      "diffLevel:9,Epoch: 650, Loss: 0.6638, Val: 0.9459,\n",
      "diffLevel:9,Epoch: 651, Loss: 0.6647, Val: 0.9459,\n",
      "diffLevel:9,Epoch: 652, Loss: 0.6643, Val: 0.9459,\n",
      "diffLevel:9,Epoch: 653, Loss: 0.6641, Val: 0.9459,\n",
      "diffLevel:9,Epoch: 654, Loss: 0.6638, Val: 0.9460,\n",
      "diffLevel:9,Epoch: 655, Loss: 0.6644, Val: 0.9460,\n",
      "diffLevel:9,Epoch: 656, Loss: 0.6639, Val: 0.9460,\n",
      "diffLevel:9,Epoch: 657, Loss: 0.6638, Val: 0.9460,\n",
      "diffLevel:9,Epoch: 658, Loss: 0.6645, Val: 0.9461,\n",
      "diffLevel:9,Epoch: 659, Loss: 0.6643, Val: 0.9461,\n",
      "diffLevel:9,Epoch: 660, Loss: 0.6644, Val: 0.9461,\n",
      "diffLevel:9,Epoch: 661, Loss: 0.6635, Val: 0.9461,\n",
      "diffLevel:9,Epoch: 662, Loss: 0.6637, Val: 0.9461,\n",
      "diffLevel:9,Epoch: 663, Loss: 0.6642, Val: 0.9462,\n",
      "diffLevel:9,Epoch: 664, Loss: 0.6641, Val: 0.9462,\n",
      "diffLevel:9,Epoch: 665, Loss: 0.6645, Val: 0.9462,\n",
      "diffLevel:9,Epoch: 666, Loss: 0.6638, Val: 0.9462,\n",
      "diffLevel:9,Epoch: 667, Loss: 0.6643, Val: 0.9462,\n",
      "diffLevel:9,Epoch: 668, Loss: 0.6643, Val: 0.9463,\n",
      "diffLevel:9,Epoch: 669, Loss: 0.6645, Val: 0.9463,\n",
      "diffLevel:9,Epoch: 670, Loss: 0.6640, Val: 0.9463,\n",
      "diffLevel:9,Epoch: 671, Loss: 0.6643, Val: 0.9463,\n",
      "diffLevel:9,Epoch: 672, Loss: 0.6639, Val: 0.9463,\n",
      "diffLevel:9,Epoch: 673, Loss: 0.6651, Val: 0.9464,\n",
      "diffLevel:9,Epoch: 674, Loss: 0.6638, Val: 0.9464,\n",
      "diffLevel:9,Epoch: 675, Loss: 0.6648, Val: 0.9464,\n",
      "diffLevel:9,Epoch: 676, Loss: 0.6644, Val: 0.9464,\n",
      "diffLevel:9,Epoch: 677, Loss: 0.6639, Val: 0.9464,\n",
      "diffLevel:9,Epoch: 678, Loss: 0.6633, Val: 0.9464,\n",
      "diffLevel:9,Epoch: 679, Loss: 0.6640, Val: 0.9465,\n",
      "diffLevel:9,Epoch: 680, Loss: 0.6643, Val: 0.9465,\n",
      "diffLevel:9,Epoch: 681, Loss: 0.6643, Val: 0.9465,\n",
      "diffLevel:9,Epoch: 682, Loss: 0.6636, Val: 0.9465,\n",
      "diffLevel:9,Epoch: 683, Loss: 0.6638, Val: 0.9465,\n",
      "diffLevel:9,Epoch: 684, Loss: 0.6631, Val: 0.9466,\n",
      "diffLevel:9,Epoch: 685, Loss: 0.6641, Val: 0.9466,\n",
      "diffLevel:9,Epoch: 686, Loss: 0.6646, Val: 0.9466,\n",
      "diffLevel:9,Epoch: 687, Loss: 0.6632, Val: 0.9466,\n",
      "diffLevel:9,Epoch: 688, Loss: 0.6640, Val: 0.9466,\n",
      "diffLevel:9,Epoch: 689, Loss: 0.6646, Val: 0.9466,\n",
      "diffLevel:9,Epoch: 690, Loss: 0.6637, Val: 0.9466,\n",
      "diffLevel:9,Epoch: 691, Loss: 0.6643, Val: 0.9467,\n",
      "diffLevel:9,Epoch: 692, Loss: 0.6638, Val: 0.9467,\n",
      "diffLevel:9,Epoch: 693, Loss: 0.6642, Val: 0.9467,\n",
      "diffLevel:9,Epoch: 694, Loss: 0.6634, Val: 0.9467,\n",
      "diffLevel:9,Epoch: 695, Loss: 0.6642, Val: 0.9467,\n",
      "diffLevel:9,Epoch: 696, Loss: 0.6642, Val: 0.9468,\n",
      "diffLevel:9,Epoch: 697, Loss: 0.6632, Val: 0.9468,\n",
      "diffLevel:9,Epoch: 698, Loss: 0.6641, Val: 0.9469,\n",
      "diffLevel:9,Epoch: 699, Loss: 0.6628, Val: 0.9469,\n",
      "diffLevel:9,Epoch: 700, Loss: 0.6634, Val: 0.9469,\n",
      "diffLevel:9,Epoch: 701, Loss: 0.6647, Val: 0.9469,\n",
      "diffLevel:9,Epoch: 702, Loss: 0.6644, Val: 0.9469,\n",
      "diffLevel:9,Epoch: 703, Loss: 0.6636, Val: 0.9469,\n",
      "diffLevel:9,Epoch: 704, Loss: 0.6637, Val: 0.9469,\n",
      "diffLevel:9,Epoch: 705, Loss: 0.6637, Val: 0.9470,\n",
      "diffLevel:9,Epoch: 706, Loss: 0.6633, Val: 0.9470,\n",
      "diffLevel:9,Epoch: 707, Loss: 0.6635, Val: 0.9470,\n",
      "diffLevel:9,Epoch: 708, Loss: 0.6639, Val: 0.9470,\n",
      "diffLevel:9,Epoch: 709, Loss: 0.6635, Val: 0.9470,\n",
      "diffLevel:9,Epoch: 710, Loss: 0.6642, Val: 0.9470,\n",
      "diffLevel:9,Epoch: 711, Loss: 0.6641, Val: 0.9471,\n",
      "diffLevel:9,Epoch: 712, Loss: 0.6641, Val: 0.9471,\n",
      "diffLevel:9,Epoch: 713, Loss: 0.6637, Val: 0.9471,\n",
      "diffLevel:9,Epoch: 714, Loss: 0.6639, Val: 0.9471,\n",
      "diffLevel:9,Epoch: 715, Loss: 0.6637, Val: 0.9471,\n",
      "diffLevel:9,Epoch: 716, Loss: 0.6635, Val: 0.9471,\n",
      "diffLevel:9,Epoch: 717, Loss: 0.6636, Val: 0.9472,\n",
      "diffLevel:9,Epoch: 718, Loss: 0.6637, Val: 0.9472,\n",
      "diffLevel:9,Epoch: 719, Loss: 0.6637, Val: 0.9472,\n",
      "diffLevel:9,Epoch: 720, Loss: 0.6641, Val: 0.9472,\n",
      "diffLevel:9,Epoch: 721, Loss: 0.6640, Val: 0.9472,\n",
      "diffLevel:9,Epoch: 722, Loss: 0.6639, Val: 0.9473,\n",
      "diffLevel:9,Epoch: 723, Loss: 0.6638, Val: 0.9473,\n",
      "diffLevel:9,Epoch: 724, Loss: 0.6636, Val: 0.9473,\n",
      "diffLevel:9,Epoch: 725, Loss: 0.6637, Val: 0.9473,\n",
      "diffLevel:9,Epoch: 726, Loss: 0.6630, Val: 0.9473,\n",
      "diffLevel:9,Epoch: 727, Loss: 0.6638, Val: 0.9474,\n",
      "diffLevel:9,Epoch: 728, Loss: 0.6633, Val: 0.9474,\n",
      "diffLevel:9,Epoch: 729, Loss: 0.6642, Val: 0.9474,\n",
      "diffLevel:9,Epoch: 730, Loss: 0.6640, Val: 0.9474,\n",
      "diffLevel:9,Epoch: 731, Loss: 0.6637, Val: 0.9475,\n",
      "diffLevel:9,Epoch: 732, Loss: 0.6642, Val: 0.9475,\n",
      "diffLevel:9,Epoch: 733, Loss: 0.6639, Val: 0.9475,\n",
      "diffLevel:9,Epoch: 734, Loss: 0.6641, Val: 0.9475,\n",
      "diffLevel:9,Epoch: 735, Loss: 0.6633, Val: 0.9476,\n",
      "diffLevel:9,Epoch: 736, Loss: 0.6631, Val: 0.9476,\n",
      "diffLevel:9,Epoch: 737, Loss: 0.6629, Val: 0.9476,\n",
      "diffLevel:9,Epoch: 738, Loss: 0.6641, Val: 0.9476,\n",
      "diffLevel:9,Epoch: 739, Loss: 0.6637, Val: 0.9477,\n",
      "diffLevel:9,Epoch: 740, Loss: 0.6636, Val: 0.9477,\n",
      "diffLevel:9,Epoch: 741, Loss: 0.6634, Val: 0.9477,\n",
      "diffLevel:9,Epoch: 742, Loss: 0.6642, Val: 0.9478,\n",
      "diffLevel:9,Epoch: 743, Loss: 0.6632, Val: 0.9478,\n",
      "diffLevel:9,Epoch: 744, Loss: 0.6643, Val: 0.9478,\n",
      "diffLevel:9,Epoch: 745, Loss: 0.6634, Val: 0.9478,\n",
      "diffLevel:9,Epoch: 746, Loss: 0.6639, Val: 0.9479,\n",
      "diffLevel:9,Epoch: 747, Loss: 0.6635, Val: 0.9479,\n",
      "diffLevel:9,Epoch: 748, Loss: 0.6632, Val: 0.9479,\n",
      "diffLevel:9,Epoch: 749, Loss: 0.6631, Val: 0.9479,\n",
      "diffLevel:9,Epoch: 750, Loss: 0.6631, Val: 0.9479,\n",
      "diffLevel:9,Epoch: 751, Loss: 0.6641, Val: 0.9479,\n",
      "diffLevel:9,Epoch: 752, Loss: 0.6627, Val: 0.9479,\n",
      "diffLevel:9,Epoch: 753, Loss: 0.6641, Val: 0.9480,\n",
      "diffLevel:9,Epoch: 754, Loss: 0.6636, Val: 0.9480,\n",
      "diffLevel:9,Epoch: 755, Loss: 0.6629, Val: 0.9480,\n",
      "diffLevel:9,Epoch: 756, Loss: 0.6640, Val: 0.9480,\n",
      "diffLevel:9,Epoch: 757, Loss: 0.6636, Val: 0.9480,\n",
      "diffLevel:9,Epoch: 758, Loss: 0.6639, Val: 0.9481,\n",
      "diffLevel:9,Epoch: 759, Loss: 0.6637, Val: 0.9481,\n",
      "diffLevel:9,Epoch: 760, Loss: 0.6633, Val: 0.9481,\n",
      "diffLevel:9,Epoch: 761, Loss: 0.6629, Val: 0.9481,\n",
      "diffLevel:9,Epoch: 762, Loss: 0.6636, Val: 0.9482,\n",
      "diffLevel:9,Epoch: 763, Loss: 0.6635, Val: 0.9482,\n",
      "diffLevel:9,Epoch: 764, Loss: 0.6634, Val: 0.9482,\n",
      "diffLevel:9,Epoch: 765, Loss: 0.6637, Val: 0.9482,\n",
      "diffLevel:9,Epoch: 766, Loss: 0.6637, Val: 0.9482,\n",
      "diffLevel:9,Epoch: 767, Loss: 0.6638, Val: 0.9483,\n",
      "diffLevel:9,Epoch: 768, Loss: 0.6633, Val: 0.9483,\n",
      "diffLevel:9,Epoch: 769, Loss: 0.6631, Val: 0.9483,\n",
      "diffLevel:9,Epoch: 770, Loss: 0.6634, Val: 0.9483,\n",
      "diffLevel:9,Epoch: 771, Loss: 0.6640, Val: 0.9483,\n",
      "diffLevel:9,Epoch: 772, Loss: 0.6638, Val: 0.9484,\n",
      "diffLevel:9,Epoch: 773, Loss: 0.6638, Val: 0.9484,\n",
      "diffLevel:9,Epoch: 774, Loss: 0.6633, Val: 0.9484,\n",
      "diffLevel:9,Epoch: 775, Loss: 0.6630, Val: 0.9484,\n",
      "diffLevel:9,Epoch: 776, Loss: 0.6632, Val: 0.9484,\n",
      "diffLevel:9,Epoch: 777, Loss: 0.6639, Val: 0.9484,\n",
      "diffLevel:9,Epoch: 778, Loss: 0.6630, Val: 0.9485,\n",
      "diffLevel:9,Epoch: 779, Loss: 0.6636, Val: 0.9485,\n",
      "diffLevel:9,Epoch: 780, Loss: 0.6629, Val: 0.9485,\n",
      "diffLevel:9,Epoch: 781, Loss: 0.6636, Val: 0.9485,\n",
      "diffLevel:9,Epoch: 782, Loss: 0.6633, Val: 0.9485,\n",
      "diffLevel:9,Epoch: 783, Loss: 0.6627, Val: 0.9485,\n",
      "diffLevel:9,Epoch: 784, Loss: 0.6630, Val: 0.9485,\n",
      "diffLevel:9,Epoch: 785, Loss: 0.6631, Val: 0.9486,\n",
      "diffLevel:9,Epoch: 786, Loss: 0.6630, Val: 0.9486,\n",
      "diffLevel:9,Epoch: 787, Loss: 0.6634, Val: 0.9486,\n",
      "diffLevel:9,Epoch: 788, Loss: 0.6630, Val: 0.9486,\n",
      "diffLevel:9,Epoch: 789, Loss: 0.6636, Val: 0.9487,\n",
      "diffLevel:9,Epoch: 790, Loss: 0.6635, Val: 0.9487,\n",
      "diffLevel:9,Epoch: 791, Loss: 0.6632, Val: 0.9487,\n",
      "diffLevel:9,Epoch: 792, Loss: 0.6631, Val: 0.9487,\n",
      "diffLevel:9,Epoch: 793, Loss: 0.6634, Val: 0.9487,\n",
      "diffLevel:9,Epoch: 794, Loss: 0.6631, Val: 0.9488,\n",
      "diffLevel:9,Epoch: 795, Loss: 0.6627, Val: 0.9488,\n",
      "diffLevel:9,Epoch: 796, Loss: 0.6625, Val: 0.9488,\n",
      "diffLevel:9,Epoch: 797, Loss: 0.6633, Val: 0.9488,\n",
      "diffLevel:9,Epoch: 798, Loss: 0.6636, Val: 0.9488,\n",
      "diffLevel:9,Epoch: 799, Loss: 0.6631, Val: 0.9489,\n",
      "diffLevel:9,Epoch: 800, Loss: 0.6638, Val: 0.9489,\n",
      "diffLevel:9,Epoch: 801, Loss: 0.6631, Val: 0.9489,\n",
      "diffLevel:9,Epoch: 802, Loss: 0.6634, Val: 0.9489,\n",
      "diffLevel:9,Epoch: 803, Loss: 0.6632, Val: 0.9489,\n",
      "diffLevel:9,Epoch: 804, Loss: 0.6624, Val: 0.9490,\n",
      "diffLevel:9,Epoch: 805, Loss: 0.6629, Val: 0.9490,\n",
      "diffLevel:9,Epoch: 806, Loss: 0.6632, Val: 0.9490,\n",
      "diffLevel:9,Epoch: 807, Loss: 0.6635, Val: 0.9490,\n",
      "diffLevel:9,Epoch: 808, Loss: 0.6633, Val: 0.9490,\n",
      "diffLevel:9,Epoch: 809, Loss: 0.6637, Val: 0.9490,\n",
      "diffLevel:9,Epoch: 810, Loss: 0.6628, Val: 0.9491,\n",
      "diffLevel:9,Epoch: 811, Loss: 0.6629, Val: 0.9491,\n",
      "diffLevel:9,Epoch: 812, Loss: 0.6630, Val: 0.9491,\n",
      "diffLevel:9,Epoch: 813, Loss: 0.6632, Val: 0.9491,\n",
      "diffLevel:9,Epoch: 814, Loss: 0.6631, Val: 0.9491,\n",
      "diffLevel:9,Epoch: 815, Loss: 0.6632, Val: 0.9491,\n",
      "diffLevel:9,Epoch: 816, Loss: 0.6640, Val: 0.9491,\n",
      "diffLevel:9,Epoch: 817, Loss: 0.6630, Val: 0.9491,\n",
      "diffLevel:9,Epoch: 818, Loss: 0.6629, Val: 0.9491,\n",
      "diffLevel:9,Epoch: 819, Loss: 0.6631, Val: 0.9491,\n",
      "diffLevel:9,Epoch: 820, Loss: 0.6633, Val: 0.9492,\n",
      "diffLevel:9,Epoch: 821, Loss: 0.6632, Val: 0.9492,\n",
      "diffLevel:9,Epoch: 822, Loss: 0.6629, Val: 0.9492,\n",
      "diffLevel:9,Epoch: 823, Loss: 0.6632, Val: 0.9492,\n",
      "diffLevel:9,Epoch: 824, Loss: 0.6632, Val: 0.9492,\n",
      "diffLevel:9,Epoch: 825, Loss: 0.6632, Val: 0.9492,\n",
      "diffLevel:9,Epoch: 826, Loss: 0.6626, Val: 0.9492,\n",
      "diffLevel:9,Epoch: 827, Loss: 0.6633, Val: 0.9492,\n",
      "diffLevel:9,Epoch: 828, Loss: 0.6628, Val: 0.9492,\n",
      "diffLevel:9,Epoch: 829, Loss: 0.6632, Val: 0.9492,\n",
      "diffLevel:9,Epoch: 830, Loss: 0.6634, Val: 0.9492,\n",
      "diffLevel:9,Epoch: 831, Loss: 0.6629, Val: 0.9492,\n",
      "diffLevel:9,Epoch: 832, Loss: 0.6629, Val: 0.9493,\n",
      "diffLevel:9,Epoch: 833, Loss: 0.6629, Val: 0.9493,\n",
      "diffLevel:9,Epoch: 834, Loss: 0.6630, Val: 0.9493,\n",
      "diffLevel:9,Epoch: 835, Loss: 0.6628, Val: 0.9493,\n",
      "diffLevel:9,Epoch: 836, Loss: 0.6627, Val: 0.9493,\n",
      "diffLevel:9,Epoch: 837, Loss: 0.6629, Val: 0.9494,\n",
      "diffLevel:9,Epoch: 838, Loss: 0.6628, Val: 0.9494,\n",
      "diffLevel:9,Epoch: 839, Loss: 0.6632, Val: 0.9494,\n",
      "diffLevel:9,Epoch: 840, Loss: 0.6637, Val: 0.9494,\n",
      "diffLevel:9,Epoch: 841, Loss: 0.6635, Val: 0.9494,\n",
      "diffLevel:9,Epoch: 842, Loss: 0.6623, Val: 0.9494,\n",
      "diffLevel:9,Epoch: 843, Loss: 0.6630, Val: 0.9495,\n",
      "diffLevel:9,Epoch: 844, Loss: 0.6633, Val: 0.9495,\n",
      "diffLevel:9,Epoch: 845, Loss: 0.6627, Val: 0.9495,\n",
      "diffLevel:9,Epoch: 846, Loss: 0.6630, Val: 0.9495,\n",
      "diffLevel:9,Epoch: 847, Loss: 0.6627, Val: 0.9495,\n",
      "diffLevel:9,Epoch: 848, Loss: 0.6631, Val: 0.9495,\n",
      "diffLevel:9,Epoch: 849, Loss: 0.6626, Val: 0.9495,\n",
      "diffLevel:9,Epoch: 850, Loss: 0.6629, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 851, Loss: 0.6633, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 852, Loss: 0.6619, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 853, Loss: 0.6629, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 854, Loss: 0.6622, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 855, Loss: 0.6631, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 856, Loss: 0.6626, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 857, Loss: 0.6631, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 858, Loss: 0.6629, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 859, Loss: 0.6630, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 860, Loss: 0.6633, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 861, Loss: 0.6629, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 862, Loss: 0.6622, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 863, Loss: 0.6624, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 864, Loss: 0.6624, Val: 0.9496,\n",
      "diffLevel:9,Epoch: 865, Loss: 0.6626, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 866, Loss: 0.6627, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 867, Loss: 0.6625, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 868, Loss: 0.6627, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 869, Loss: 0.6635, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 870, Loss: 0.6632, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 871, Loss: 0.6613, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 872, Loss: 0.6629, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 873, Loss: 0.6624, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 874, Loss: 0.6622, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 875, Loss: 0.6624, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 876, Loss: 0.6632, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 877, Loss: 0.6628, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 878, Loss: 0.6626, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 879, Loss: 0.6632, Val: 0.9497,\n",
      "diffLevel:9,Epoch: 880, Loss: 0.6632, Val: 0.9498,\n",
      "diffLevel:9,Epoch: 881, Loss: 0.6628, Val: 0.9498,\n",
      "diffLevel:9,Epoch: 882, Loss: 0.6631, Val: 0.9498,\n",
      "diffLevel:9,Epoch: 883, Loss: 0.6629, Val: 0.9498,\n",
      "diffLevel:9,Epoch: 884, Loss: 0.6622, Val: 0.9498,\n",
      "diffLevel:9,Epoch: 885, Loss: 0.6629, Val: 0.9498,\n",
      "diffLevel:9,Epoch: 886, Loss: 0.6627, Val: 0.9498,\n",
      "diffLevel:9,Epoch: 887, Loss: 0.6626, Val: 0.9498,\n",
      "diffLevel:9,Epoch: 888, Loss: 0.6623, Val: 0.9499,\n",
      "diffLevel:9,Epoch: 889, Loss: 0.6623, Val: 0.9499,\n",
      "diffLevel:9,Epoch: 890, Loss: 0.6628, Val: 0.9499,\n",
      "diffLevel:9,Epoch: 891, Loss: 0.6623, Val: 0.9499,\n",
      "diffLevel:9,Epoch: 892, Loss: 0.6629, Val: 0.9499,\n",
      "diffLevel:9,Epoch: 893, Loss: 0.6638, Val: 0.9499,\n",
      "diffLevel:9,Epoch: 894, Loss: 0.6624, Val: 0.9499,\n",
      "diffLevel:9,Epoch: 895, Loss: 0.6628, Val: 0.9500,\n",
      "diffLevel:9,Epoch: 896, Loss: 0.6630, Val: 0.9500,\n",
      "diffLevel:9,Epoch: 897, Loss: 0.6621, Val: 0.9500,\n",
      "diffLevel:9,Epoch: 898, Loss: 0.6628, Val: 0.9500,\n",
      "diffLevel:9,Epoch: 899, Loss: 0.6628, Val: 0.9500,\n",
      "diffLevel:9,Epoch: 900, Loss: 0.6626, Val: 0.9500,\n",
      "diffLevel:9,Epoch: 901, Loss: 0.6627, Val: 0.9501,\n",
      "diffLevel:9,Epoch: 902, Loss: 0.6620, Val: 0.9501,\n",
      "diffLevel:9,Epoch: 903, Loss: 0.6628, Val: 0.9501,\n",
      "diffLevel:9,Epoch: 904, Loss: 0.6620, Val: 0.9501,\n",
      "diffLevel:9,Epoch: 905, Loss: 0.6625, Val: 0.9502,\n",
      "diffLevel:9,Epoch: 906, Loss: 0.6625, Val: 0.9502,\n",
      "diffLevel:9,Epoch: 907, Loss: 0.6625, Val: 0.9502,\n",
      "diffLevel:9,Epoch: 908, Loss: 0.6628, Val: 0.9502,\n",
      "diffLevel:9,Epoch: 909, Loss: 0.6622, Val: 0.9503,\n",
      "diffLevel:9,Epoch: 910, Loss: 0.6629, Val: 0.9503,\n",
      "diffLevel:9,Epoch: 911, Loss: 0.6629, Val: 0.9503,\n",
      "diffLevel:9,Epoch: 912, Loss: 0.6626, Val: 0.9503,\n",
      "diffLevel:9,Epoch: 913, Loss: 0.6623, Val: 0.9503,\n",
      "diffLevel:9,Epoch: 914, Loss: 0.6620, Val: 0.9504,\n",
      "diffLevel:9,Epoch: 915, Loss: 0.6619, Val: 0.9504,\n",
      "diffLevel:9,Epoch: 916, Loss: 0.6622, Val: 0.9504,\n",
      "diffLevel:9,Epoch: 917, Loss: 0.6630, Val: 0.9504,\n",
      "diffLevel:9,Epoch: 918, Loss: 0.6632, Val: 0.9505,\n",
      "diffLevel:9,Epoch: 919, Loss: 0.6627, Val: 0.9505,\n",
      "diffLevel:9,Epoch: 920, Loss: 0.6630, Val: 0.9505,\n",
      "diffLevel:9,Epoch: 921, Loss: 0.6625, Val: 0.9505,\n",
      "diffLevel:9,Epoch: 922, Loss: 0.6626, Val: 0.9506,\n",
      "diffLevel:9,Epoch: 923, Loss: 0.6622, Val: 0.9506,\n",
      "diffLevel:9,Epoch: 924, Loss: 0.6628, Val: 0.9506,\n",
      "diffLevel:9,Epoch: 925, Loss: 0.6622, Val: 0.9506,\n",
      "diffLevel:9,Epoch: 926, Loss: 0.6637, Val: 0.9507,\n",
      "diffLevel:9,Epoch: 927, Loss: 0.6629, Val: 0.9507,\n",
      "diffLevel:9,Epoch: 928, Loss: 0.6627, Val: 0.9507,\n",
      "diffLevel:9,Epoch: 929, Loss: 0.6627, Val: 0.9508,\n",
      "diffLevel:9,Epoch: 930, Loss: 0.6617, Val: 0.9508,\n",
      "diffLevel:9,Epoch: 931, Loss: 0.6625, Val: 0.9508,\n",
      "diffLevel:9,Epoch: 932, Loss: 0.6626, Val: 0.9508,\n",
      "diffLevel:9,Epoch: 933, Loss: 0.6625, Val: 0.9508,\n",
      "diffLevel:9,Epoch: 934, Loss: 0.6633, Val: 0.9508,\n",
      "diffLevel:9,Epoch: 935, Loss: 0.6627, Val: 0.9509,\n",
      "diffLevel:9,Epoch: 936, Loss: 0.6623, Val: 0.9509,\n",
      "diffLevel:9,Epoch: 937, Loss: 0.6627, Val: 0.9509,\n",
      "diffLevel:9,Epoch: 938, Loss: 0.6625, Val: 0.9509,\n",
      "diffLevel:9,Epoch: 939, Loss: 0.6617, Val: 0.9509,\n",
      "diffLevel:9,Epoch: 940, Loss: 0.6624, Val: 0.9509,\n",
      "diffLevel:9,Epoch: 941, Loss: 0.6616, Val: 0.9509,\n",
      "diffLevel:9,Epoch: 942, Loss: 0.6621, Val: 0.9509,\n",
      "diffLevel:9,Epoch: 943, Loss: 0.6631, Val: 0.9510,\n",
      "diffLevel:9,Epoch: 944, Loss: 0.6628, Val: 0.9510,\n",
      "diffLevel:9,Epoch: 945, Loss: 0.6621, Val: 0.9510,\n",
      "diffLevel:9,Epoch: 946, Loss: 0.6625, Val: 0.9510,\n",
      "diffLevel:9,Epoch: 947, Loss: 0.6619, Val: 0.9510,\n",
      "diffLevel:9,Epoch: 948, Loss: 0.6624, Val: 0.9510,\n",
      "diffLevel:9,Epoch: 949, Loss: 0.6621, Val: 0.9510,\n",
      "diffLevel:9,Epoch: 950, Loss: 0.6615, Val: 0.9510,\n",
      "diffLevel:9,Epoch: 951, Loss: 0.6624, Val: 0.9510,\n",
      "diffLevel:9,Epoch: 952, Loss: 0.6622, Val: 0.9510,\n",
      "diffLevel:9,Epoch: 953, Loss: 0.6626, Val: 0.9510,\n",
      "diffLevel:9,Epoch: 954, Loss: 0.6622, Val: 0.9510,\n",
      "diffLevel:9,Epoch: 955, Loss: 0.6630, Val: 0.9510,\n",
      "diffLevel:9,Epoch: 956, Loss: 0.6617, Val: 0.9510,\n",
      "diffLevel:9,Epoch: 957, Loss: 0.6624, Val: 0.9511,\n",
      "diffLevel:9,Epoch: 958, Loss: 0.6631, Val: 0.9511,\n",
      "diffLevel:9,Epoch: 959, Loss: 0.6627, Val: 0.9511,\n",
      "diffLevel:9,Epoch: 960, Loss: 0.6626, Val: 0.9511,\n",
      "diffLevel:9,Epoch: 961, Loss: 0.6621, Val: 0.9511,\n",
      "diffLevel:9,Epoch: 962, Loss: 0.6625, Val: 0.9511,\n",
      "diffLevel:9,Epoch: 963, Loss: 0.6617, Val: 0.9511,\n",
      "diffLevel:9,Epoch: 964, Loss: 0.6627, Val: 0.9511,\n",
      "diffLevel:9,Epoch: 965, Loss: 0.6623, Val: 0.9512,\n",
      "diffLevel:9,Epoch: 966, Loss: 0.6632, Val: 0.9512,\n",
      "diffLevel:9,Epoch: 967, Loss: 0.6627, Val: 0.9512,\n",
      "diffLevel:9,Epoch: 968, Loss: 0.6619, Val: 0.9512,\n",
      "diffLevel:9,Epoch: 969, Loss: 0.6624, Val: 0.9512,\n",
      "diffLevel:9,Epoch: 970, Loss: 0.6620, Val: 0.9513,\n",
      "diffLevel:9,Epoch: 971, Loss: 0.6619, Val: 0.9513,\n",
      "diffLevel:9,Epoch: 972, Loss: 0.6618, Val: 0.9513,\n",
      "diffLevel:9,Epoch: 973, Loss: 0.6617, Val: 0.9513,\n",
      "diffLevel:9,Epoch: 974, Loss: 0.6623, Val: 0.9513,\n",
      "diffLevel:9,Epoch: 975, Loss: 0.6625, Val: 0.9513,\n",
      "diffLevel:9,Epoch: 976, Loss: 0.6626, Val: 0.9513,\n",
      "diffLevel:9,Epoch: 977, Loss: 0.6623, Val: 0.9513,\n",
      "diffLevel:9,Epoch: 978, Loss: 0.6625, Val: 0.9513,\n",
      "diffLevel:9,Epoch: 979, Loss: 0.6621, Val: 0.9513,\n",
      "diffLevel:9,Epoch: 980, Loss: 0.6624, Val: 0.9514,\n",
      "diffLevel:9,Epoch: 981, Loss: 0.6625, Val: 0.9514,\n",
      "diffLevel:9,Epoch: 982, Loss: 0.6619, Val: 0.9514,\n",
      "diffLevel:9,Epoch: 983, Loss: 0.6623, Val: 0.9514,\n",
      "diffLevel:9,Epoch: 984, Loss: 0.6620, Val: 0.9514,\n",
      "diffLevel:9,Epoch: 985, Loss: 0.6622, Val: 0.9515,\n",
      "diffLevel:9,Epoch: 986, Loss: 0.6621, Val: 0.9515,\n",
      "diffLevel:9,Epoch: 987, Loss: 0.6630, Val: 0.9515,\n",
      "diffLevel:9,Epoch: 988, Loss: 0.6626, Val: 0.9515,\n",
      "diffLevel:9,Epoch: 989, Loss: 0.6618, Val: 0.9515,\n",
      "diffLevel:9,Epoch: 990, Loss: 0.6619, Val: 0.9515,\n",
      "diffLevel:9,Epoch: 991, Loss: 0.6619, Val: 0.9516,\n",
      "diffLevel:9,Epoch: 992, Loss: 0.6627, Val: 0.9516,\n",
      "diffLevel:9,Epoch: 993, Loss: 0.6621, Val: 0.9516,\n",
      "diffLevel:9,Epoch: 994, Loss: 0.6617, Val: 0.9517,\n",
      "diffLevel:9,Epoch: 995, Loss: 0.6624, Val: 0.9517,\n",
      "diffLevel:9,Epoch: 996, Loss: 0.6624, Val: 0.9517,\n",
      "diffLevel:9,Epoch: 997, Loss: 0.6617, Val: 0.9517,\n",
      "diffLevel:9,Epoch: 998, Loss: 0.6619, Val: 0.9517,\n",
      "diffLevel:9,Epoch: 999, Loss: 0.6626, Val: 0.9517,\n",
      "diffLevel:9,Epoch: 1000, Loss: 0.6623, Val: 0.9518,\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:10,Epoch: 001, Loss: 0.6620, Val: 0.9518,\n",
      "diffLevel:10,Epoch: 002, Loss: 0.6617, Val: 0.9518,\n",
      "diffLevel:10,Epoch: 003, Loss: 0.6631, Val: 0.9518,\n",
      "diffLevel:10,Epoch: 004, Loss: 0.6620, Val: 0.9519,\n",
      "diffLevel:10,Epoch: 005, Loss: 0.6615, Val: 0.9519,\n",
      "diffLevel:10,Epoch: 006, Loss: 0.6621, Val: 0.9519,\n",
      "diffLevel:10,Epoch: 007, Loss: 0.6621, Val: 0.9519,\n",
      "diffLevel:10,Epoch: 008, Loss: 0.6624, Val: 0.9520,\n",
      "diffLevel:10,Epoch: 009, Loss: 0.6614, Val: 0.9520,\n",
      "diffLevel:10,Epoch: 010, Loss: 0.6624, Val: 0.9520,\n",
      "diffLevel:10,Epoch: 011, Loss: 0.6615, Val: 0.9521,\n",
      "diffLevel:10,Epoch: 012, Loss: 0.6622, Val: 0.9521,\n",
      "diffLevel:10,Epoch: 013, Loss: 0.6622, Val: 0.9521,\n",
      "diffLevel:10,Epoch: 014, Loss: 0.6619, Val: 0.9521,\n",
      "diffLevel:10,Epoch: 015, Loss: 0.6615, Val: 0.9522,\n",
      "diffLevel:10,Epoch: 016, Loss: 0.6619, Val: 0.9522,\n",
      "diffLevel:10,Epoch: 017, Loss: 0.6619, Val: 0.9522,\n",
      "diffLevel:10,Epoch: 018, Loss: 0.6619, Val: 0.9522,\n",
      "diffLevel:10,Epoch: 019, Loss: 0.6616, Val: 0.9523,\n",
      "diffLevel:10,Epoch: 020, Loss: 0.6619, Val: 0.9523,\n",
      "diffLevel:10,Epoch: 021, Loss: 0.6618, Val: 0.9523,\n",
      "diffLevel:10,Epoch: 022, Loss: 0.6620, Val: 0.9523,\n",
      "diffLevel:10,Epoch: 023, Loss: 0.6619, Val: 0.9524,\n",
      "diffLevel:10,Epoch: 024, Loss: 0.6625, Val: 0.9524,\n",
      "diffLevel:10,Epoch: 025, Loss: 0.6619, Val: 0.9524,\n",
      "diffLevel:10,Epoch: 026, Loss: 0.6613, Val: 0.9524,\n",
      "diffLevel:10,Epoch: 027, Loss: 0.6622, Val: 0.9525,\n",
      "diffLevel:10,Epoch: 028, Loss: 0.6619, Val: 0.9525,\n",
      "diffLevel:10,Epoch: 029, Loss: 0.6616, Val: 0.9525,\n",
      "diffLevel:10,Epoch: 030, Loss: 0.6618, Val: 0.9526,\n",
      "diffLevel:10,Epoch: 031, Loss: 0.6625, Val: 0.9526,\n",
      "diffLevel:10,Epoch: 032, Loss: 0.6611, Val: 0.9526,\n",
      "diffLevel:10,Epoch: 033, Loss: 0.6613, Val: 0.9526,\n",
      "diffLevel:10,Epoch: 034, Loss: 0.6617, Val: 0.9526,\n",
      "diffLevel:10,Epoch: 035, Loss: 0.6612, Val: 0.9526,\n",
      "diffLevel:10,Epoch: 036, Loss: 0.6621, Val: 0.9526,\n",
      "diffLevel:10,Epoch: 037, Loss: 0.6622, Val: 0.9527,\n",
      "diffLevel:10,Epoch: 038, Loss: 0.6620, Val: 0.9527,\n",
      "diffLevel:10,Epoch: 039, Loss: 0.6622, Val: 0.9527,\n",
      "diffLevel:10,Epoch: 040, Loss: 0.6630, Val: 0.9527,\n",
      "diffLevel:10,Epoch: 041, Loss: 0.6624, Val: 0.9527,\n",
      "diffLevel:10,Epoch: 042, Loss: 0.6617, Val: 0.9527,\n",
      "diffLevel:10,Epoch: 043, Loss: 0.6615, Val: 0.9528,\n",
      "diffLevel:10,Epoch: 044, Loss: 0.6614, Val: 0.9528,\n",
      "diffLevel:10,Epoch: 045, Loss: 0.6621, Val: 0.9528,\n",
      "diffLevel:10,Epoch: 046, Loss: 0.6618, Val: 0.9528,\n",
      "diffLevel:10,Epoch: 047, Loss: 0.6620, Val: 0.9529,\n",
      "diffLevel:10,Epoch: 048, Loss: 0.6614, Val: 0.9529,\n",
      "diffLevel:10,Epoch: 049, Loss: 0.6617, Val: 0.9529,\n",
      "diffLevel:10,Epoch: 050, Loss: 0.6612, Val: 0.9529,\n",
      "diffLevel:10,Epoch: 051, Loss: 0.6615, Val: 0.9529,\n",
      "diffLevel:10,Epoch: 052, Loss: 0.6620, Val: 0.9529,\n",
      "diffLevel:10,Epoch: 053, Loss: 0.6618, Val: 0.9529,\n",
      "diffLevel:10,Epoch: 054, Loss: 0.6619, Val: 0.9529,\n",
      "diffLevel:10,Epoch: 055, Loss: 0.6615, Val: 0.9529,\n",
      "diffLevel:10,Epoch: 056, Loss: 0.6612, Val: 0.9529,\n",
      "diffLevel:10,Epoch: 057, Loss: 0.6629, Val: 0.9530,\n",
      "diffLevel:10,Epoch: 058, Loss: 0.6612, Val: 0.9530,\n",
      "diffLevel:10,Epoch: 059, Loss: 0.6606, Val: 0.9530,\n",
      "diffLevel:10,Epoch: 060, Loss: 0.6617, Val: 0.9530,\n",
      "diffLevel:10,Epoch: 061, Loss: 0.6617, Val: 0.9530,\n",
      "diffLevel:10,Epoch: 062, Loss: 0.6620, Val: 0.9530,\n",
      "diffLevel:10,Epoch: 063, Loss: 0.6615, Val: 0.9530,\n",
      "diffLevel:10,Epoch: 064, Loss: 0.6615, Val: 0.9530,\n",
      "diffLevel:10,Epoch: 065, Loss: 0.6616, Val: 0.9531,\n",
      "diffLevel:10,Epoch: 066, Loss: 0.6621, Val: 0.9531,\n",
      "diffLevel:10,Epoch: 067, Loss: 0.6617, Val: 0.9531,\n",
      "diffLevel:10,Epoch: 068, Loss: 0.6623, Val: 0.9531,\n",
      "diffLevel:10,Epoch: 069, Loss: 0.6620, Val: 0.9531,\n",
      "diffLevel:10,Epoch: 070, Loss: 0.6619, Val: 0.9531,\n",
      "diffLevel:10,Epoch: 071, Loss: 0.6614, Val: 0.9531,\n",
      "diffLevel:10,Epoch: 072, Loss: 0.6611, Val: 0.9531,\n",
      "diffLevel:10,Epoch: 073, Loss: 0.6613, Val: 0.9532,\n",
      "diffLevel:10,Epoch: 074, Loss: 0.6618, Val: 0.9532,\n",
      "diffLevel:10,Epoch: 075, Loss: 0.6617, Val: 0.9532,\n",
      "diffLevel:10,Epoch: 076, Loss: 0.6619, Val: 0.9532,\n",
      "diffLevel:10,Epoch: 077, Loss: 0.6618, Val: 0.9532,\n",
      "diffLevel:10,Epoch: 078, Loss: 0.6613, Val: 0.9533,\n",
      "diffLevel:10,Epoch: 079, Loss: 0.6613, Val: 0.9533,\n",
      "diffLevel:10,Epoch: 080, Loss: 0.6607, Val: 0.9533,\n",
      "diffLevel:10,Epoch: 081, Loss: 0.6620, Val: 0.9533,\n",
      "diffLevel:10,Epoch: 082, Loss: 0.6607, Val: 0.9533,\n",
      "diffLevel:10,Epoch: 083, Loss: 0.6610, Val: 0.9533,\n",
      "diffLevel:10,Epoch: 084, Loss: 0.6612, Val: 0.9533,\n",
      "diffLevel:10,Epoch: 085, Loss: 0.6614, Val: 0.9533,\n",
      "diffLevel:10,Epoch: 086, Loss: 0.6616, Val: 0.9534,\n",
      "diffLevel:10,Epoch: 087, Loss: 0.6613, Val: 0.9534,\n",
      "diffLevel:10,Epoch: 088, Loss: 0.6610, Val: 0.9534,\n",
      "diffLevel:10,Epoch: 089, Loss: 0.6616, Val: 0.9534,\n",
      "diffLevel:10,Epoch: 090, Loss: 0.6618, Val: 0.9534,\n",
      "diffLevel:10,Epoch: 091, Loss: 0.6605, Val: 0.9534,\n",
      "diffLevel:10,Epoch: 092, Loss: 0.6617, Val: 0.9534,\n",
      "diffLevel:10,Epoch: 093, Loss: 0.6608, Val: 0.9534,\n",
      "diffLevel:10,Epoch: 094, Loss: 0.6616, Val: 0.9535,\n",
      "diffLevel:10,Epoch: 095, Loss: 0.6616, Val: 0.9535,\n",
      "diffLevel:10,Epoch: 096, Loss: 0.6613, Val: 0.9535,\n",
      "diffLevel:10,Epoch: 097, Loss: 0.6611, Val: 0.9535,\n",
      "diffLevel:10,Epoch: 098, Loss: 0.6608, Val: 0.9535,\n",
      "diffLevel:10,Epoch: 099, Loss: 0.6620, Val: 0.9535,\n",
      "diffLevel:10,Epoch: 100, Loss: 0.6616, Val: 0.9535,\n",
      "diffLevel:10,Epoch: 101, Loss: 0.6613, Val: 0.9535,\n",
      "diffLevel:10,Epoch: 102, Loss: 0.6612, Val: 0.9535,\n",
      "diffLevel:10,Epoch: 103, Loss: 0.6619, Val: 0.9536,\n",
      "diffLevel:10,Epoch: 104, Loss: 0.6614, Val: 0.9536,\n",
      "diffLevel:10,Epoch: 105, Loss: 0.6612, Val: 0.9536,\n",
      "diffLevel:10,Epoch: 106, Loss: 0.6605, Val: 0.9536,\n",
      "diffLevel:10,Epoch: 107, Loss: 0.6609, Val: 0.9536,\n",
      "diffLevel:10,Epoch: 108, Loss: 0.6617, Val: 0.9536,\n",
      "diffLevel:10,Epoch: 109, Loss: 0.6613, Val: 0.9536,\n",
      "diffLevel:10,Epoch: 110, Loss: 0.6608, Val: 0.9536,\n",
      "diffLevel:10,Epoch: 111, Loss: 0.6613, Val: 0.9536,\n",
      "diffLevel:10,Epoch: 112, Loss: 0.6614, Val: 0.9536,\n",
      "diffLevel:10,Epoch: 113, Loss: 0.6614, Val: 0.9536,\n",
      "diffLevel:10,Epoch: 114, Loss: 0.6611, Val: 0.9536,\n",
      "diffLevel:10,Epoch: 115, Loss: 0.6612, Val: 0.9536,\n",
      "diffLevel:10,Epoch: 116, Loss: 0.6614, Val: 0.9537,\n",
      "diffLevel:10,Epoch: 117, Loss: 0.6618, Val: 0.9537,\n",
      "diffLevel:10,Epoch: 118, Loss: 0.6610, Val: 0.9537,\n",
      "diffLevel:10,Epoch: 119, Loss: 0.6612, Val: 0.9537,\n",
      "diffLevel:10,Epoch: 120, Loss: 0.6614, Val: 0.9537,\n",
      "diffLevel:10,Epoch: 121, Loss: 0.6614, Val: 0.9537,\n",
      "diffLevel:10,Epoch: 122, Loss: 0.6612, Val: 0.9537,\n",
      "diffLevel:10,Epoch: 123, Loss: 0.6614, Val: 0.9537,\n",
      "diffLevel:10,Epoch: 124, Loss: 0.6608, Val: 0.9537,\n",
      "diffLevel:10,Epoch: 125, Loss: 0.6608, Val: 0.9538,\n",
      "diffLevel:10,Epoch: 126, Loss: 0.6623, Val: 0.9538,\n",
      "diffLevel:10,Epoch: 127, Loss: 0.6607, Val: 0.9538,\n",
      "diffLevel:10,Epoch: 128, Loss: 0.6611, Val: 0.9538,\n",
      "diffLevel:10,Epoch: 129, Loss: 0.6616, Val: 0.9538,\n",
      "diffLevel:10,Epoch: 130, Loss: 0.6611, Val: 0.9538,\n",
      "diffLevel:10,Epoch: 131, Loss: 0.6617, Val: 0.9538,\n",
      "diffLevel:10,Epoch: 132, Loss: 0.6614, Val: 0.9539,\n",
      "diffLevel:10,Epoch: 133, Loss: 0.6623, Val: 0.9539,\n",
      "diffLevel:10,Epoch: 134, Loss: 0.6607, Val: 0.9539,\n",
      "diffLevel:10,Epoch: 135, Loss: 0.6609, Val: 0.9540,\n",
      "diffLevel:10,Epoch: 136, Loss: 0.6612, Val: 0.9540,\n",
      "diffLevel:10,Epoch: 137, Loss: 0.6610, Val: 0.9540,\n",
      "diffLevel:10,Epoch: 138, Loss: 0.6618, Val: 0.9540,\n",
      "diffLevel:10,Epoch: 139, Loss: 0.6619, Val: 0.9540,\n",
      "diffLevel:10,Epoch: 140, Loss: 0.6612, Val: 0.9540,\n",
      "diffLevel:10,Epoch: 141, Loss: 0.6609, Val: 0.9540,\n",
      "diffLevel:10,Epoch: 142, Loss: 0.6614, Val: 0.9540,\n",
      "diffLevel:10,Epoch: 143, Loss: 0.6617, Val: 0.9541,\n",
      "diffLevel:10,Epoch: 144, Loss: 0.6613, Val: 0.9541,\n",
      "diffLevel:10,Epoch: 145, Loss: 0.6617, Val: 0.9541,\n",
      "diffLevel:10,Epoch: 146, Loss: 0.6608, Val: 0.9541,\n",
      "diffLevel:10,Epoch: 147, Loss: 0.6614, Val: 0.9541,\n",
      "diffLevel:10,Epoch: 148, Loss: 0.6610, Val: 0.9541,\n",
      "diffLevel:10,Epoch: 149, Loss: 0.6612, Val: 0.9541,\n",
      "diffLevel:10,Epoch: 150, Loss: 0.6614, Val: 0.9541,\n",
      "diffLevel:10,Epoch: 151, Loss: 0.6613, Val: 0.9541,\n",
      "diffLevel:10,Epoch: 152, Loss: 0.6614, Val: 0.9541,\n",
      "diffLevel:10,Epoch: 153, Loss: 0.6608, Val: 0.9541,\n",
      "diffLevel:10,Epoch: 154, Loss: 0.6611, Val: 0.9542,\n",
      "diffLevel:10,Epoch: 155, Loss: 0.6617, Val: 0.9542,\n",
      "diffLevel:10,Epoch: 156, Loss: 0.6610, Val: 0.9542,\n",
      "diffLevel:10,Epoch: 157, Loss: 0.6618, Val: 0.9542,\n",
      "diffLevel:10,Epoch: 158, Loss: 0.6608, Val: 0.9542,\n",
      "diffLevel:10,Epoch: 159, Loss: 0.6605, Val: 0.9542,\n",
      "diffLevel:10,Epoch: 160, Loss: 0.6605, Val: 0.9542,\n",
      "diffLevel:10,Epoch: 161, Loss: 0.6607, Val: 0.9542,\n",
      "diffLevel:10,Epoch: 162, Loss: 0.6608, Val: 0.9542,\n",
      "diffLevel:10,Epoch: 163, Loss: 0.6618, Val: 0.9542,\n",
      "diffLevel:10,Epoch: 164, Loss: 0.6615, Val: 0.9542,\n",
      "diffLevel:10,Epoch: 165, Loss: 0.6610, Val: 0.9542,\n",
      "diffLevel:10,Epoch: 166, Loss: 0.6613, Val: 0.9542,\n",
      "diffLevel:10,Epoch: 167, Loss: 0.6607, Val: 0.9543,\n",
      "diffLevel:10,Epoch: 168, Loss: 0.6612, Val: 0.9543,\n",
      "diffLevel:10,Epoch: 169, Loss: 0.6613, Val: 0.9543,\n",
      "diffLevel:10,Epoch: 170, Loss: 0.6614, Val: 0.9543,\n",
      "diffLevel:10,Epoch: 171, Loss: 0.6611, Val: 0.9543,\n",
      "diffLevel:10,Epoch: 172, Loss: 0.6609, Val: 0.9543,\n",
      "diffLevel:10,Epoch: 173, Loss: 0.6616, Val: 0.9543,\n",
      "diffLevel:10,Epoch: 174, Loss: 0.6619, Val: 0.9544,\n",
      "diffLevel:10,Epoch: 175, Loss: 0.6608, Val: 0.9544,\n",
      "diffLevel:10,Epoch: 176, Loss: 0.6610, Val: 0.9544,\n",
      "diffLevel:10,Epoch: 177, Loss: 0.6611, Val: 0.9544,\n",
      "diffLevel:10,Epoch: 178, Loss: 0.6608, Val: 0.9544,\n",
      "diffLevel:10,Epoch: 179, Loss: 0.6617, Val: 0.9544,\n",
      "diffLevel:10,Epoch: 180, Loss: 0.6607, Val: 0.9544,\n",
      "diffLevel:10,Epoch: 181, Loss: 0.6613, Val: 0.9544,\n",
      "diffLevel:10,Epoch: 182, Loss: 0.6610, Val: 0.9544,\n",
      "diffLevel:10,Epoch: 183, Loss: 0.6611, Val: 0.9544,\n",
      "diffLevel:10,Epoch: 184, Loss: 0.6602, Val: 0.9544,\n",
      "diffLevel:10,Epoch: 184, Loss: 0.6602, Val: 0.9544,\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:11,Epoch: 001, Loss: 0.6615, Val: 0.9544,\n",
      "diffLevel:11,Epoch: 002, Loss: 0.6615, Val: 0.9544,\n",
      "diffLevel:11,Epoch: 003, Loss: 0.6613, Val: 0.9544,\n",
      "diffLevel:11,Epoch: 004, Loss: 0.6612, Val: 0.9544,\n",
      "diffLevel:11,Epoch: 005, Loss: 0.6618, Val: 0.9544,\n",
      "diffLevel:11,Epoch: 006, Loss: 0.6614, Val: 0.9545,\n",
      "diffLevel:11,Epoch: 007, Loss: 0.6611, Val: 0.9545,\n",
      "diffLevel:11,Epoch: 008, Loss: 0.6608, Val: 0.9545,\n",
      "diffLevel:11,Epoch: 009, Loss: 0.6608, Val: 0.9545,\n",
      "diffLevel:11,Epoch: 010, Loss: 0.6609, Val: 0.9546,\n",
      "diffLevel:11,Epoch: 011, Loss: 0.6605, Val: 0.9546,\n",
      "diffLevel:11,Epoch: 012, Loss: 0.6613, Val: 0.9546,\n",
      "diffLevel:11,Epoch: 013, Loss: 0.6608, Val: 0.9547,\n",
      "diffLevel:11,Epoch: 014, Loss: 0.6616, Val: 0.9547,\n",
      "diffLevel:11,Epoch: 015, Loss: 0.6613, Val: 0.9548,\n",
      "diffLevel:11,Epoch: 016, Loss: 0.6613, Val: 0.9548,\n",
      "diffLevel:11,Epoch: 017, Loss: 0.6610, Val: 0.9549,\n",
      "diffLevel:11,Epoch: 018, Loss: 0.6608, Val: 0.9549,\n",
      "diffLevel:11,Epoch: 019, Loss: 0.6613, Val: 0.9549,\n",
      "diffLevel:11,Epoch: 020, Loss: 0.6606, Val: 0.9550,\n",
      "diffLevel:11,Epoch: 021, Loss: 0.6613, Val: 0.9551,\n",
      "diffLevel:11,Epoch: 022, Loss: 0.6608, Val: 0.9551,\n",
      "diffLevel:11,Epoch: 023, Loss: 0.6607, Val: 0.9551,\n",
      "diffLevel:11,Epoch: 024, Loss: 0.6603, Val: 0.9552,\n",
      "diffLevel:11,Epoch: 025, Loss: 0.6604, Val: 0.9552,\n",
      "diffLevel:11,Epoch: 026, Loss: 0.6612, Val: 0.9552,\n",
      "diffLevel:11,Epoch: 027, Loss: 0.6606, Val: 0.9553,\n",
      "diffLevel:11,Epoch: 028, Loss: 0.6603, Val: 0.9553,\n",
      "diffLevel:11,Epoch: 029, Loss: 0.6614, Val: 0.9554,\n",
      "diffLevel:11,Epoch: 030, Loss: 0.6605, Val: 0.9554,\n",
      "diffLevel:11,Epoch: 031, Loss: 0.6616, Val: 0.9554,\n",
      "diffLevel:11,Epoch: 032, Loss: 0.6606, Val: 0.9555,\n",
      "diffLevel:11,Epoch: 033, Loss: 0.6610, Val: 0.9555,\n",
      "diffLevel:11,Epoch: 034, Loss: 0.6622, Val: 0.9555,\n",
      "diffLevel:11,Epoch: 035, Loss: 0.6613, Val: 0.9555,\n",
      "diffLevel:11,Epoch: 036, Loss: 0.6616, Val: 0.9555,\n",
      "diffLevel:11,Epoch: 037, Loss: 0.6608, Val: 0.9555,\n",
      "diffLevel:11,Epoch: 038, Loss: 0.6606, Val: 0.9556,\n",
      "diffLevel:11,Epoch: 039, Loss: 0.6609, Val: 0.9556,\n",
      "diffLevel:11,Epoch: 040, Loss: 0.6609, Val: 0.9556,\n",
      "diffLevel:11,Epoch: 041, Loss: 0.6608, Val: 0.9556,\n",
      "diffLevel:11,Epoch: 042, Loss: 0.6606, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 043, Loss: 0.6610, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 044, Loss: 0.6612, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 045, Loss: 0.6597, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 046, Loss: 0.6606, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 047, Loss: 0.6617, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 048, Loss: 0.6607, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 049, Loss: 0.6607, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 050, Loss: 0.6607, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 051, Loss: 0.6603, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 052, Loss: 0.6607, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 053, Loss: 0.6612, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 054, Loss: 0.6609, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 055, Loss: 0.6610, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 056, Loss: 0.6607, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 057, Loss: 0.6614, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 058, Loss: 0.6612, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 059, Loss: 0.6600, Val: 0.9557,\n",
      "diffLevel:11,Epoch: 060, Loss: 0.6612, Val: 0.9558,\n",
      "diffLevel:11,Epoch: 061, Loss: 0.6608, Val: 0.9558,\n",
      "diffLevel:11,Epoch: 062, Loss: 0.6605, Val: 0.9558,\n",
      "diffLevel:11,Epoch: 063, Loss: 0.6609, Val: 0.9558,\n",
      "diffLevel:11,Epoch: 064, Loss: 0.6614, Val: 0.9558,\n",
      "diffLevel:11,Epoch: 065, Loss: 0.6609, Val: 0.9558,\n",
      "diffLevel:11,Epoch: 066, Loss: 0.6602, Val: 0.9558,\n",
      "diffLevel:11,Epoch: 067, Loss: 0.6611, Val: 0.9559,\n",
      "diffLevel:11,Epoch: 068, Loss: 0.6613, Val: 0.9559,\n",
      "diffLevel:11,Epoch: 069, Loss: 0.6610, Val: 0.9559,\n",
      "diffLevel:11,Epoch: 070, Loss: 0.6611, Val: 0.9559,\n",
      "diffLevel:11,Epoch: 071, Loss: 0.6608, Val: 0.9559,\n",
      "diffLevel:11,Epoch: 072, Loss: 0.6607, Val: 0.9560,\n",
      "diffLevel:11,Epoch: 073, Loss: 0.6602, Val: 0.9560,\n",
      "diffLevel:11,Epoch: 074, Loss: 0.6604, Val: 0.9560,\n",
      "diffLevel:11,Epoch: 075, Loss: 0.6609, Val: 0.9560,\n",
      "diffLevel:11,Epoch: 076, Loss: 0.6605, Val: 0.9560,\n",
      "diffLevel:11,Epoch: 077, Loss: 0.6602, Val: 0.9560,\n",
      "diffLevel:11,Epoch: 078, Loss: 0.6607, Val: 0.9560,\n",
      "diffLevel:11,Epoch: 079, Loss: 0.6600, Val: 0.9560,\n",
      "diffLevel:11,Epoch: 080, Loss: 0.6612, Val: 0.9560,\n",
      "diffLevel:11,Epoch: 081, Loss: 0.6613, Val: 0.9560,\n",
      "diffLevel:11,Epoch: 082, Loss: 0.6606, Val: 0.9560,\n",
      "diffLevel:11,Epoch: 083, Loss: 0.6606, Val: 0.9561,\n",
      "diffLevel:11,Epoch: 084, Loss: 0.6607, Val: 0.9561,\n",
      "diffLevel:11,Epoch: 085, Loss: 0.6610, Val: 0.9561,\n",
      "diffLevel:11,Epoch: 086, Loss: 0.6601, Val: 0.9561,\n",
      "diffLevel:11,Epoch: 087, Loss: 0.6608, Val: 0.9561,\n",
      "diffLevel:11,Epoch: 088, Loss: 0.6598, Val: 0.9561,\n",
      "diffLevel:11,Epoch: 089, Loss: 0.6609, Val: 0.9562,\n",
      "diffLevel:11,Epoch: 090, Loss: 0.6608, Val: 0.9562,\n",
      "diffLevel:11,Epoch: 091, Loss: 0.6608, Val: 0.9562,\n",
      "diffLevel:11,Epoch: 092, Loss: 0.6608, Val: 0.9562,\n",
      "diffLevel:11,Epoch: 093, Loss: 0.6609, Val: 0.9562,\n",
      "diffLevel:11,Epoch: 094, Loss: 0.6613, Val: 0.9562,\n",
      "diffLevel:11,Epoch: 095, Loss: 0.6598, Val: 0.9562,\n",
      "diffLevel:11,Epoch: 096, Loss: 0.6603, Val: 0.9562,\n",
      "diffLevel:11,Epoch: 097, Loss: 0.6609, Val: 0.9562,\n",
      "diffLevel:11,Epoch: 098, Loss: 0.6615, Val: 0.9563,\n",
      "diffLevel:11,Epoch: 099, Loss: 0.6605, Val: 0.9563,\n",
      "diffLevel:11,Epoch: 100, Loss: 0.6614, Val: 0.9564,\n",
      "diffLevel:11,Epoch: 101, Loss: 0.6611, Val: 0.9564,\n",
      "diffLevel:11,Epoch: 102, Loss: 0.6604, Val: 0.9564,\n",
      "diffLevel:11,Epoch: 103, Loss: 0.6607, Val: 0.9564,\n",
      "diffLevel:11,Epoch: 104, Loss: 0.6607, Val: 0.9564,\n",
      "diffLevel:11,Epoch: 105, Loss: 0.6605, Val: 0.9564,\n",
      "diffLevel:11,Epoch: 106, Loss: 0.6616, Val: 0.9565,\n",
      "diffLevel:11,Epoch: 107, Loss: 0.6609, Val: 0.9565,\n",
      "diffLevel:11,Epoch: 108, Loss: 0.6598, Val: 0.9565,\n",
      "diffLevel:11,Epoch: 109, Loss: 0.6604, Val: 0.9565,\n",
      "diffLevel:11,Epoch: 110, Loss: 0.6612, Val: 0.9565,\n",
      "diffLevel:11,Epoch: 111, Loss: 0.6607, Val: 0.9566,\n",
      "diffLevel:11,Epoch: 112, Loss: 0.6610, Val: 0.9566,\n",
      "diffLevel:11,Epoch: 113, Loss: 0.6604, Val: 0.9566,\n",
      "diffLevel:11,Epoch: 114, Loss: 0.6605, Val: 0.9566,\n",
      "diffLevel:11,Epoch: 115, Loss: 0.6602, Val: 0.9566,\n",
      "diffLevel:11,Epoch: 116, Loss: 0.6597, Val: 0.9566,\n",
      "diffLevel:11,Epoch: 117, Loss: 0.6609, Val: 0.9566,\n",
      "diffLevel:11,Epoch: 118, Loss: 0.6605, Val: 0.9566,\n",
      "diffLevel:11,Epoch: 119, Loss: 0.6606, Val: 0.9566,\n",
      "diffLevel:11,Epoch: 120, Loss: 0.6606, Val: 0.9566,\n",
      "diffLevel:11,Epoch: 121, Loss: 0.6612, Val: 0.9567,\n",
      "diffLevel:11,Epoch: 122, Loss: 0.6607, Val: 0.9567,\n",
      "diffLevel:11,Epoch: 123, Loss: 0.6602, Val: 0.9567,\n",
      "diffLevel:11,Epoch: 124, Loss: 0.6605, Val: 0.9567,\n",
      "diffLevel:11,Epoch: 125, Loss: 0.6606, Val: 0.9567,\n",
      "diffLevel:11,Epoch: 126, Loss: 0.6598, Val: 0.9567,\n",
      "diffLevel:11,Epoch: 127, Loss: 0.6610, Val: 0.9567,\n",
      "diffLevel:11,Epoch: 128, Loss: 0.6609, Val: 0.9567,\n",
      "diffLevel:11,Epoch: 129, Loss: 0.6604, Val: 0.9568,\n",
      "diffLevel:11,Epoch: 130, Loss: 0.6604, Val: 0.9568,\n",
      "diffLevel:11,Epoch: 131, Loss: 0.6607, Val: 0.9568,\n",
      "diffLevel:11,Epoch: 132, Loss: 0.6606, Val: 0.9568,\n",
      "diffLevel:11,Epoch: 133, Loss: 0.6607, Val: 0.9568,\n",
      "diffLevel:11,Epoch: 134, Loss: 0.6606, Val: 0.9568,\n",
      "diffLevel:11,Epoch: 135, Loss: 0.6602, Val: 0.9568,\n",
      "diffLevel:11,Epoch: 136, Loss: 0.6611, Val: 0.9569,\n",
      "diffLevel:11,Epoch: 137, Loss: 0.6608, Val: 0.9569,\n",
      "diffLevel:11,Epoch: 138, Loss: 0.6600, Val: 0.9569,\n",
      "diffLevel:11,Epoch: 139, Loss: 0.6610, Val: 0.9569,\n",
      "diffLevel:11,Epoch: 140, Loss: 0.6608, Val: 0.9569,\n",
      "diffLevel:11,Epoch: 141, Loss: 0.6610, Val: 0.9569,\n",
      "diffLevel:11,Epoch: 142, Loss: 0.6605, Val: 0.9569,\n",
      "diffLevel:11,Epoch: 143, Loss: 0.6599, Val: 0.9569,\n",
      "diffLevel:11,Epoch: 144, Loss: 0.6607, Val: 0.9569,\n",
      "diffLevel:11,Epoch: 145, Loss: 0.6614, Val: 0.9570,\n",
      "diffLevel:11,Epoch: 146, Loss: 0.6605, Val: 0.9570,\n",
      "diffLevel:11,Epoch: 147, Loss: 0.6609, Val: 0.9570,\n",
      "diffLevel:11,Epoch: 148, Loss: 0.6604, Val: 0.9570,\n",
      "diffLevel:11,Epoch: 149, Loss: 0.6605, Val: 0.9570,\n",
      "diffLevel:11,Epoch: 150, Loss: 0.6610, Val: 0.9570,\n",
      "diffLevel:11,Epoch: 151, Loss: 0.6608, Val: 0.9571,\n",
      "diffLevel:11,Epoch: 152, Loss: 0.6607, Val: 0.9571,\n",
      "diffLevel:11,Epoch: 153, Loss: 0.6603, Val: 0.9571,\n",
      "diffLevel:11,Epoch: 154, Loss: 0.6604, Val: 0.9571,\n",
      "diffLevel:11,Epoch: 155, Loss: 0.6604, Val: 0.9571,\n",
      "diffLevel:11,Epoch: 156, Loss: 0.6607, Val: 0.9571,\n",
      "diffLevel:11,Epoch: 157, Loss: 0.6603, Val: 0.9571,\n",
      "diffLevel:11,Epoch: 158, Loss: 0.6598, Val: 0.9572,\n",
      "diffLevel:11,Epoch: 159, Loss: 0.6605, Val: 0.9572,\n",
      "diffLevel:11,Epoch: 160, Loss: 0.6600, Val: 0.9572,\n",
      "diffLevel:11,Epoch: 161, Loss: 0.6599, Val: 0.9572,\n",
      "diffLevel:11,Epoch: 162, Loss: 0.6606, Val: 0.9571,\n",
      "diffLevel:11,Epoch: 163, Loss: 0.6607, Val: 0.9571,\n",
      "diffLevel:11,Epoch: 164, Loss: 0.6600, Val: 0.9571,\n",
      "diffLevel:11,Epoch: 165, Loss: 0.6601, Val: 0.9571,\n",
      "diffLevel:11,Epoch: 165, Loss: 0.6601, Val: 0.9571,\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:12,Epoch: 001, Loss: 0.6599, Val: 0.9571,\n",
      "diffLevel:12,Epoch: 002, Loss: 0.6610, Val: 0.9570,\n",
      "diffLevel:12,Epoch: 003, Loss: 0.6601, Val: 0.9569,\n",
      "diffLevel:12,Epoch: 004, Loss: 0.6598, Val: 0.9569,\n",
      "diffLevel:12,Epoch: 005, Loss: 0.6600, Val: 0.9569,\n",
      "diffLevel:12,Epoch: 006, Loss: 0.6598, Val: 0.9570,\n",
      "diffLevel:12,Epoch: 007, Loss: 0.6602, Val: 0.9571,\n",
      "diffLevel:12,Epoch: 008, Loss: 0.6601, Val: 0.9571,\n",
      "diffLevel:12,Epoch: 009, Loss: 0.6602, Val: 0.9570,\n",
      "diffLevel:12,Epoch: 010, Loss: 0.6604, Val: 0.9570,\n",
      "diffLevel:12,Epoch: 011, Loss: 0.6597, Val: 0.9570,\n",
      "diffLevel:12,Epoch: 012, Loss: 0.6600, Val: 0.9570,\n",
      "diffLevel:12,Epoch: 013, Loss: 0.6601, Val: 0.9571,\n",
      "diffLevel:12,Epoch: 014, Loss: 0.6608, Val: 0.9571,\n",
      "diffLevel:12,Epoch: 015, Loss: 0.6602, Val: 0.9572,\n",
      "diffLevel:12,Epoch: 016, Loss: 0.6612, Val: 0.9572,\n",
      "diffLevel:12,Epoch: 017, Loss: 0.6605, Val: 0.9572,\n",
      "diffLevel:12,Epoch: 018, Loss: 0.6606, Val: 0.9572,\n",
      "diffLevel:12,Epoch: 019, Loss: 0.6600, Val: 0.9572,\n",
      "diffLevel:12,Epoch: 020, Loss: 0.6603, Val: 0.9573,\n",
      "diffLevel:12,Epoch: 021, Loss: 0.6596, Val: 0.9573,\n",
      "diffLevel:12,Epoch: 022, Loss: 0.6602, Val: 0.9574,\n",
      "diffLevel:12,Epoch: 023, Loss: 0.6592, Val: 0.9574,\n",
      "diffLevel:12,Epoch: 024, Loss: 0.6603, Val: 0.9574,\n",
      "diffLevel:12,Epoch: 025, Loss: 0.6601, Val: 0.9574,\n",
      "diffLevel:12,Epoch: 026, Loss: 0.6607, Val: 0.9575,\n",
      "diffLevel:12,Epoch: 027, Loss: 0.6596, Val: 0.9575,\n",
      "diffLevel:12,Epoch: 028, Loss: 0.6603, Val: 0.9575,\n",
      "diffLevel:12,Epoch: 029, Loss: 0.6605, Val: 0.9575,\n",
      "diffLevel:12,Epoch: 030, Loss: 0.6608, Val: 0.9576,\n",
      "diffLevel:12,Epoch: 031, Loss: 0.6600, Val: 0.9576,\n",
      "diffLevel:12,Epoch: 032, Loss: 0.6604, Val: 0.9576,\n",
      "diffLevel:12,Epoch: 033, Loss: 0.6596, Val: 0.9576,\n",
      "diffLevel:12,Epoch: 034, Loss: 0.6608, Val: 0.9576,\n",
      "diffLevel:12,Epoch: 035, Loss: 0.6603, Val: 0.9577,\n",
      "diffLevel:12,Epoch: 036, Loss: 0.6599, Val: 0.9577,\n",
      "diffLevel:12,Epoch: 037, Loss: 0.6601, Val: 0.9578,\n",
      "diffLevel:12,Epoch: 038, Loss: 0.6599, Val: 0.9578,\n",
      "diffLevel:12,Epoch: 039, Loss: 0.6597, Val: 0.9578,\n",
      "diffLevel:12,Epoch: 040, Loss: 0.6603, Val: 0.9578,\n",
      "diffLevel:12,Epoch: 041, Loss: 0.6601, Val: 0.9578,\n",
      "diffLevel:12,Epoch: 042, Loss: 0.6603, Val: 0.9578,\n",
      "diffLevel:12,Epoch: 043, Loss: 0.6605, Val: 0.9579,\n",
      "diffLevel:12,Epoch: 044, Loss: 0.6604, Val: 0.9579,\n",
      "diffLevel:12,Epoch: 045, Loss: 0.6608, Val: 0.9580,\n",
      "diffLevel:12,Epoch: 046, Loss: 0.6607, Val: 0.9580,\n",
      "diffLevel:12,Epoch: 047, Loss: 0.6604, Val: 0.9580,\n",
      "diffLevel:12,Epoch: 048, Loss: 0.6600, Val: 0.9580,\n",
      "diffLevel:12,Epoch: 049, Loss: 0.6604, Val: 0.9580,\n",
      "diffLevel:12,Epoch: 050, Loss: 0.6606, Val: 0.9580,\n",
      "diffLevel:12,Epoch: 051, Loss: 0.6597, Val: 0.9580,\n",
      "diffLevel:12,Epoch: 052, Loss: 0.6602, Val: 0.9581,\n",
      "diffLevel:12,Epoch: 053, Loss: 0.6600, Val: 0.9581,\n",
      "diffLevel:12,Epoch: 054, Loss: 0.6593, Val: 0.9581,\n",
      "diffLevel:12,Epoch: 055, Loss: 0.6600, Val: 0.9581,\n",
      "diffLevel:12,Epoch: 056, Loss: 0.6601, Val: 0.9581,\n",
      "diffLevel:12,Epoch: 057, Loss: 0.6601, Val: 0.9581,\n",
      "diffLevel:12,Epoch: 058, Loss: 0.6597, Val: 0.9581,\n",
      "diffLevel:12,Epoch: 059, Loss: 0.6602, Val: 0.9581,\n",
      "diffLevel:12,Epoch: 060, Loss: 0.6598, Val: 0.9581,\n",
      "diffLevel:12,Epoch: 061, Loss: 0.6597, Val: 0.9581,\n",
      "diffLevel:12,Epoch: 062, Loss: 0.6598, Val: 0.9581,\n",
      "diffLevel:12,Epoch: 063, Loss: 0.6598, Val: 0.9581,\n",
      "diffLevel:12,Epoch: 064, Loss: 0.6593, Val: 0.9581,\n",
      "diffLevel:12,Epoch: 065, Loss: 0.6601, Val: 0.9582,\n",
      "diffLevel:12,Epoch: 066, Loss: 0.6600, Val: 0.9582,\n",
      "diffLevel:12,Epoch: 067, Loss: 0.6604, Val: 0.9582,\n",
      "diffLevel:12,Epoch: 068, Loss: 0.6598, Val: 0.9582,\n",
      "diffLevel:12,Epoch: 069, Loss: 0.6601, Val: 0.9582,\n",
      "diffLevel:12,Epoch: 070, Loss: 0.6604, Val: 0.9582,\n",
      "diffLevel:12,Epoch: 071, Loss: 0.6597, Val: 0.9582,\n",
      "diffLevel:12,Epoch: 072, Loss: 0.6603, Val: 0.9582,\n",
      "diffLevel:12,Epoch: 073, Loss: 0.6592, Val: 0.9583,\n",
      "diffLevel:12,Epoch: 074, Loss: 0.6601, Val: 0.9583,\n",
      "diffLevel:12,Epoch: 075, Loss: 0.6602, Val: 0.9583,\n",
      "diffLevel:12,Epoch: 076, Loss: 0.6598, Val: 0.9584,\n",
      "diffLevel:12,Epoch: 077, Loss: 0.6595, Val: 0.9584,\n",
      "diffLevel:12,Epoch: 078, Loss: 0.6597, Val: 0.9584,\n",
      "diffLevel:12,Epoch: 079, Loss: 0.6606, Val: 0.9584,\n",
      "diffLevel:12,Epoch: 080, Loss: 0.6597, Val: 0.9584,\n",
      "diffLevel:12,Epoch: 081, Loss: 0.6599, Val: 0.9585,\n",
      "diffLevel:12,Epoch: 082, Loss: 0.6594, Val: 0.9585,\n",
      "diffLevel:12,Epoch: 083, Loss: 0.6603, Val: 0.9585,\n",
      "diffLevel:12,Epoch: 084, Loss: 0.6603, Val: 0.9585,\n",
      "diffLevel:12,Epoch: 085, Loss: 0.6601, Val: 0.9585,\n",
      "diffLevel:12,Epoch: 086, Loss: 0.6609, Val: 0.9586,\n",
      "diffLevel:12,Epoch: 087, Loss: 0.6604, Val: 0.9586,\n",
      "diffLevel:12,Epoch: 088, Loss: 0.6597, Val: 0.9586,\n",
      "diffLevel:12,Epoch: 089, Loss: 0.6597, Val: 0.9586,\n",
      "diffLevel:12,Epoch: 090, Loss: 0.6595, Val: 0.9586,\n",
      "diffLevel:12,Epoch: 091, Loss: 0.6601, Val: 0.9586,\n",
      "diffLevel:12,Epoch: 092, Loss: 0.6605, Val: 0.9586,\n",
      "diffLevel:12,Epoch: 093, Loss: 0.6601, Val: 0.9586,\n",
      "diffLevel:12,Epoch: 094, Loss: 0.6599, Val: 0.9586,\n",
      "diffLevel:12,Epoch: 095, Loss: 0.6600, Val: 0.9586,\n",
      "diffLevel:12,Epoch: 096, Loss: 0.6600, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 097, Loss: 0.6600, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 098, Loss: 0.6598, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 099, Loss: 0.6598, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 100, Loss: 0.6600, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 101, Loss: 0.6588, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 102, Loss: 0.6592, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 103, Loss: 0.6610, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 104, Loss: 0.6591, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 105, Loss: 0.6599, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 106, Loss: 0.6600, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 107, Loss: 0.6594, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 108, Loss: 0.6597, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 109, Loss: 0.6600, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 110, Loss: 0.6601, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 111, Loss: 0.6597, Val: 0.9587,\n",
      "diffLevel:12,Epoch: 112, Loss: 0.6603, Val: 0.9588,\n",
      "diffLevel:12,Epoch: 113, Loss: 0.6602, Val: 0.9588,\n",
      "diffLevel:12,Epoch: 114, Loss: 0.6603, Val: 0.9588,\n",
      "diffLevel:12,Epoch: 115, Loss: 0.6596, Val: 0.9588,\n",
      "diffLevel:12,Epoch: 116, Loss: 0.6595, Val: 0.9588,\n",
      "diffLevel:12,Epoch: 117, Loss: 0.6593, Val: 0.9588,\n",
      "diffLevel:12,Epoch: 118, Loss: 0.6600, Val: 0.9588,\n",
      "diffLevel:12,Epoch: 119, Loss: 0.6594, Val: 0.9588,\n",
      "diffLevel:12,Epoch: 120, Loss: 0.6600, Val: 0.9589,\n",
      "diffLevel:12,Epoch: 121, Loss: 0.6599, Val: 0.9589,\n",
      "diffLevel:12,Epoch: 122, Loss: 0.6600, Val: 0.9589,\n",
      "diffLevel:12,Epoch: 123, Loss: 0.6594, Val: 0.9589,\n",
      "diffLevel:12,Epoch: 124, Loss: 0.6595, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 125, Loss: 0.6592, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 126, Loss: 0.6602, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 127, Loss: 0.6600, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 128, Loss: 0.6591, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 129, Loss: 0.6592, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 130, Loss: 0.6592, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 131, Loss: 0.6597, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 132, Loss: 0.6591, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 133, Loss: 0.6597, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 134, Loss: 0.6597, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 135, Loss: 0.6600, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 136, Loss: 0.6600, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 137, Loss: 0.6600, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 138, Loss: 0.6595, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 139, Loss: 0.6587, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 140, Loss: 0.6601, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 141, Loss: 0.6597, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 142, Loss: 0.6597, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 143, Loss: 0.6600, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 144, Loss: 0.6597, Val: 0.9590,\n",
      "diffLevel:12,Epoch: 145, Loss: 0.6601, Val: 0.9591,\n",
      "diffLevel:12,Epoch: 146, Loss: 0.6602, Val: 0.9591,\n",
      "diffLevel:12,Epoch: 147, Loss: 0.6596, Val: 0.9591,\n",
      "diffLevel:12,Epoch: 148, Loss: 0.6592, Val: 0.9591,\n",
      "diffLevel:12,Epoch: 149, Loss: 0.6601, Val: 0.9591,\n",
      "diffLevel:12,Epoch: 150, Loss: 0.6593, Val: 0.9592,\n",
      "diffLevel:12,Epoch: 151, Loss: 0.6598, Val: 0.9592,\n",
      "diffLevel:12,Epoch: 152, Loss: 0.6601, Val: 0.9592,\n",
      "diffLevel:12,Epoch: 153, Loss: 0.6597, Val: 0.9592,\n",
      "diffLevel:12,Epoch: 154, Loss: 0.6591, Val: 0.9592,\n",
      "diffLevel:12,Epoch: 155, Loss: 0.6591, Val: 0.9592,\n",
      "diffLevel:12,Epoch: 156, Loss: 0.6595, Val: 0.9593,\n",
      "diffLevel:12,Epoch: 157, Loss: 0.6597, Val: 0.9593,\n",
      "diffLevel:12,Epoch: 158, Loss: 0.6595, Val: 0.9593,\n",
      "diffLevel:12,Epoch: 159, Loss: 0.6594, Val: 0.9593,\n",
      "diffLevel:12,Epoch: 160, Loss: 0.6598, Val: 0.9593,\n",
      "diffLevel:12,Epoch: 161, Loss: 0.6598, Val: 0.9593,\n",
      "diffLevel:12,Epoch: 162, Loss: 0.6599, Val: 0.9592,\n",
      "diffLevel:12,Epoch: 163, Loss: 0.6601, Val: 0.9592,\n",
      "diffLevel:12,Epoch: 164, Loss: 0.6587, Val: 0.9593,\n",
      "diffLevel:12,Epoch: 164, Loss: 0.6587, Val: 0.9593,\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:13,Epoch: 001, Loss: 0.6592, Val: 0.9592,\n",
      "diffLevel:13,Epoch: 002, Loss: 0.6596, Val: 0.9591,\n",
      "diffLevel:13,Epoch: 003, Loss: 0.6595, Val: 0.9590,\n",
      "diffLevel:13,Epoch: 004, Loss: 0.6602, Val: 0.9590,\n",
      "diffLevel:13,Epoch: 005, Loss: 0.6605, Val: 0.9591,\n",
      "diffLevel:13,Epoch: 006, Loss: 0.6600, Val: 0.9592,\n",
      "diffLevel:13,Epoch: 007, Loss: 0.6592, Val: 0.9593,\n",
      "diffLevel:13,Epoch: 008, Loss: 0.6599, Val: 0.9593,\n",
      "diffLevel:13,Epoch: 009, Loss: 0.6595, Val: 0.9593,\n",
      "diffLevel:13,Epoch: 010, Loss: 0.6596, Val: 0.9593,\n",
      "diffLevel:13,Epoch: 011, Loss: 0.6592, Val: 0.9593,\n",
      "diffLevel:13,Epoch: 012, Loss: 0.6591, Val: 0.9593,\n",
      "diffLevel:13,Epoch: 013, Loss: 0.6599, Val: 0.9594,\n",
      "diffLevel:13,Epoch: 014, Loss: 0.6598, Val: 0.9595,\n",
      "diffLevel:13,Epoch: 015, Loss: 0.6596, Val: 0.9595,\n",
      "diffLevel:13,Epoch: 016, Loss: 0.6588, Val: 0.9596,\n",
      "diffLevel:13,Epoch: 017, Loss: 0.6594, Val: 0.9596,\n",
      "diffLevel:13,Epoch: 018, Loss: 0.6605, Val: 0.9596,\n",
      "diffLevel:13,Epoch: 019, Loss: 0.6595, Val: 0.9596,\n",
      "diffLevel:13,Epoch: 020, Loss: 0.6598, Val: 0.9596,\n",
      "diffLevel:13,Epoch: 021, Loss: 0.6592, Val: 0.9597,\n",
      "diffLevel:13,Epoch: 022, Loss: 0.6601, Val: 0.9597,\n",
      "diffLevel:13,Epoch: 023, Loss: 0.6594, Val: 0.9598,\n",
      "diffLevel:13,Epoch: 024, Loss: 0.6596, Val: 0.9598,\n",
      "diffLevel:13,Epoch: 025, Loss: 0.6599, Val: 0.9598,\n",
      "diffLevel:13,Epoch: 026, Loss: 0.6596, Val: 0.9598,\n",
      "diffLevel:13,Epoch: 027, Loss: 0.6591, Val: 0.9598,\n",
      "diffLevel:13,Epoch: 028, Loss: 0.6595, Val: 0.9598,\n",
      "diffLevel:13,Epoch: 029, Loss: 0.6602, Val: 0.9598,\n",
      "diffLevel:13,Epoch: 030, Loss: 0.6588, Val: 0.9598,\n",
      "diffLevel:13,Epoch: 031, Loss: 0.6597, Val: 0.9599,\n",
      "diffLevel:13,Epoch: 032, Loss: 0.6591, Val: 0.9599,\n",
      "diffLevel:13,Epoch: 033, Loss: 0.6598, Val: 0.9599,\n",
      "diffLevel:13,Epoch: 034, Loss: 0.6593, Val: 0.9599,\n",
      "diffLevel:13,Epoch: 035, Loss: 0.6596, Val: 0.9599,\n",
      "diffLevel:13,Epoch: 036, Loss: 0.6599, Val: 0.9599,\n",
      "diffLevel:13,Epoch: 037, Loss: 0.6593, Val: 0.9599,\n",
      "diffLevel:13,Epoch: 038, Loss: 0.6592, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 039, Loss: 0.6592, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 040, Loss: 0.6596, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 041, Loss: 0.6594, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 042, Loss: 0.6598, Val: 0.9599,\n",
      "diffLevel:13,Epoch: 043, Loss: 0.6592, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 044, Loss: 0.6590, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 045, Loss: 0.6599, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 046, Loss: 0.6594, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 047, Loss: 0.6591, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 048, Loss: 0.6591, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 049, Loss: 0.6597, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 050, Loss: 0.6587, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 051, Loss: 0.6597, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 052, Loss: 0.6597, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 053, Loss: 0.6597, Val: 0.9601,\n",
      "diffLevel:13,Epoch: 054, Loss: 0.6594, Val: 0.9601,\n",
      "diffLevel:13,Epoch: 055, Loss: 0.6593, Val: 0.9601,\n",
      "diffLevel:13,Epoch: 056, Loss: 0.6598, Val: 0.9601,\n",
      "diffLevel:13,Epoch: 057, Loss: 0.6593, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 058, Loss: 0.6596, Val: 0.9600,\n",
      "diffLevel:13,Epoch: 059, Loss: 0.6591, Val: 0.9601,\n",
      "diffLevel:13,Epoch: 060, Loss: 0.6601, Val: 0.9601,\n",
      "diffLevel:13,Epoch: 061, Loss: 0.6596, Val: 0.9601,\n",
      "diffLevel:13,Epoch: 062, Loss: 0.6593, Val: 0.9601,\n",
      "diffLevel:13,Epoch: 063, Loss: 0.6598, Val: 0.9601,\n",
      "diffLevel:13,Epoch: 064, Loss: 0.6600, Val: 0.9601,\n",
      "diffLevel:13,Epoch: 065, Loss: 0.6594, Val: 0.9601,\n",
      "diffLevel:13,Epoch: 066, Loss: 0.6592, Val: 0.9601,\n",
      "diffLevel:13,Epoch: 067, Loss: 0.6597, Val: 0.9601,\n",
      "diffLevel:13,Epoch: 068, Loss: 0.6594, Val: 0.9602,\n",
      "diffLevel:13,Epoch: 069, Loss: 0.6592, Val: 0.9602,\n",
      "diffLevel:13,Epoch: 070, Loss: 0.6594, Val: 0.9602,\n",
      "diffLevel:13,Epoch: 071, Loss: 0.6601, Val: 0.9602,\n",
      "diffLevel:13,Epoch: 072, Loss: 0.6597, Val: 0.9602,\n",
      "diffLevel:13,Epoch: 073, Loss: 0.6599, Val: 0.9603,\n",
      "diffLevel:13,Epoch: 074, Loss: 0.6598, Val: 0.9603,\n",
      "diffLevel:13,Epoch: 075, Loss: 0.6597, Val: 0.9603,\n",
      "diffLevel:13,Epoch: 076, Loss: 0.6592, Val: 0.9603,\n",
      "diffLevel:13,Epoch: 077, Loss: 0.6594, Val: 0.9604,\n",
      "diffLevel:13,Epoch: 078, Loss: 0.6597, Val: 0.9604,\n",
      "diffLevel:13,Epoch: 079, Loss: 0.6594, Val: 0.9604,\n",
      "diffLevel:13,Epoch: 080, Loss: 0.6598, Val: 0.9604,\n",
      "diffLevel:13,Epoch: 081, Loss: 0.6583, Val: 0.9604,\n",
      "diffLevel:13,Epoch: 082, Loss: 0.6596, Val: 0.9604,\n",
      "diffLevel:13,Epoch: 083, Loss: 0.6596, Val: 0.9605,\n",
      "diffLevel:13,Epoch: 084, Loss: 0.6598, Val: 0.9604,\n",
      "diffLevel:13,Epoch: 085, Loss: 0.6591, Val: 0.9604,\n",
      "diffLevel:13,Epoch: 086, Loss: 0.6589, Val: 0.9604,\n",
      "diffLevel:13,Epoch: 087, Loss: 0.6597, Val: 0.9604,\n",
      "diffLevel:13,Epoch: 088, Loss: 0.6593, Val: 0.9605,\n",
      "diffLevel:13,Epoch: 089, Loss: 0.6600, Val: 0.9605,\n",
      "diffLevel:13,Epoch: 090, Loss: 0.6596, Val: 0.9605,\n",
      "diffLevel:13,Epoch: 091, Loss: 0.6593, Val: 0.9605,\n",
      "diffLevel:13,Epoch: 092, Loss: 0.6589, Val: 0.9605,\n",
      "diffLevel:13,Epoch: 093, Loss: 0.6591, Val: 0.9605,\n",
      "diffLevel:13,Epoch: 094, Loss: 0.6593, Val: 0.9605,\n",
      "diffLevel:13,Epoch: 095, Loss: 0.6593, Val: 0.9605,\n",
      "diffLevel:13,Epoch: 096, Loss: 0.6598, Val: 0.9605,\n",
      "diffLevel:13,Epoch: 097, Loss: 0.6588, Val: 0.9605,\n",
      "diffLevel:13,Epoch: 098, Loss: 0.6601, Val: 0.9606,\n",
      "diffLevel:13,Epoch: 099, Loss: 0.6596, Val: 0.9606,\n",
      "diffLevel:13,Epoch: 100, Loss: 0.6589, Val: 0.9606,\n",
      "diffLevel:13,Epoch: 101, Loss: 0.6592, Val: 0.9606,\n",
      "diffLevel:13,Epoch: 102, Loss: 0.6595, Val: 0.9606,\n",
      "diffLevel:13,Epoch: 103, Loss: 0.6591, Val: 0.9605,\n",
      "diffLevel:13,Epoch: 104, Loss: 0.6589, Val: 0.9605,\n",
      "diffLevel:13,Epoch: 105, Loss: 0.6589, Val: 0.9605,\n",
      "diffLevel:13,Epoch: 105, Loss: 0.6589, Val: 0.9605,\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:14,Epoch: 001, Loss: 0.6594, Val: 0.9604,\n",
      "diffLevel:14,Epoch: 002, Loss: 0.6595, Val: 0.9602,\n",
      "diffLevel:14,Epoch: 003, Loss: 0.6581, Val: 0.9601,\n",
      "diffLevel:14,Epoch: 004, Loss: 0.6595, Val: 0.9601,\n",
      "diffLevel:14,Epoch: 005, Loss: 0.6596, Val: 0.9602,\n",
      "diffLevel:14,Epoch: 006, Loss: 0.6595, Val: 0.9604,\n",
      "diffLevel:14,Epoch: 007, Loss: 0.6591, Val: 0.9604,\n",
      "diffLevel:14,Epoch: 008, Loss: 0.6591, Val: 0.9604,\n",
      "diffLevel:14,Epoch: 009, Loss: 0.6589, Val: 0.9604,\n",
      "diffLevel:14,Epoch: 010, Loss: 0.6594, Val: 0.9603,\n",
      "diffLevel:14,Epoch: 011, Loss: 0.6588, Val: 0.9603,\n",
      "diffLevel:14,Epoch: 012, Loss: 0.6589, Val: 0.9604,\n",
      "diffLevel:14,Epoch: 013, Loss: 0.6593, Val: 0.9605,\n",
      "diffLevel:14,Epoch: 014, Loss: 0.6592, Val: 0.9606,\n",
      "diffLevel:14,Epoch: 015, Loss: 0.6596, Val: 0.9606,\n",
      "diffLevel:14,Epoch: 016, Loss: 0.6589, Val: 0.9606,\n",
      "diffLevel:14,Epoch: 017, Loss: 0.6588, Val: 0.9606,\n",
      "diffLevel:14,Epoch: 018, Loss: 0.6580, Val: 0.9606,\n",
      "diffLevel:14,Epoch: 019, Loss: 0.6586, Val: 0.9606,\n",
      "diffLevel:14,Epoch: 020, Loss: 0.6593, Val: 0.9606,\n",
      "diffLevel:14,Epoch: 021, Loss: 0.6587, Val: 0.9607,\n",
      "diffLevel:14,Epoch: 022, Loss: 0.6595, Val: 0.9607,\n",
      "diffLevel:14,Epoch: 023, Loss: 0.6590, Val: 0.9608,\n",
      "diffLevel:14,Epoch: 024, Loss: 0.6590, Val: 0.9608,\n",
      "diffLevel:14,Epoch: 025, Loss: 0.6594, Val: 0.9608,\n",
      "diffLevel:14,Epoch: 026, Loss: 0.6594, Val: 0.9608,\n",
      "diffLevel:14,Epoch: 027, Loss: 0.6596, Val: 0.9609,\n",
      "diffLevel:14,Epoch: 028, Loss: 0.6594, Val: 0.9609,\n",
      "diffLevel:14,Epoch: 029, Loss: 0.6596, Val: 0.9609,\n",
      "diffLevel:14,Epoch: 030, Loss: 0.6589, Val: 0.9609,\n",
      "diffLevel:14,Epoch: 031, Loss: 0.6598, Val: 0.9609,\n",
      "diffLevel:14,Epoch: 032, Loss: 0.6592, Val: 0.9609,\n",
      "diffLevel:14,Epoch: 033, Loss: 0.6585, Val: 0.9610,\n",
      "diffLevel:14,Epoch: 034, Loss: 0.6583, Val: 0.9610,\n",
      "diffLevel:14,Epoch: 035, Loss: 0.6589, Val: 0.9610,\n",
      "diffLevel:14,Epoch: 036, Loss: 0.6587, Val: 0.9610,\n",
      "diffLevel:14,Epoch: 037, Loss: 0.6592, Val: 0.9610,\n",
      "diffLevel:14,Epoch: 038, Loss: 0.6598, Val: 0.9610,\n",
      "diffLevel:14,Epoch: 039, Loss: 0.6591, Val: 0.9610,\n",
      "diffLevel:14,Epoch: 040, Loss: 0.6595, Val: 0.9610,\n",
      "diffLevel:14,Epoch: 041, Loss: 0.6588, Val: 0.9611,\n",
      "diffLevel:14,Epoch: 042, Loss: 0.6595, Val: 0.9611,\n",
      "diffLevel:14,Epoch: 043, Loss: 0.6585, Val: 0.9611,\n",
      "diffLevel:14,Epoch: 044, Loss: 0.6587, Val: 0.9611,\n",
      "diffLevel:14,Epoch: 045, Loss: 0.6588, Val: 0.9611,\n",
      "diffLevel:14,Epoch: 046, Loss: 0.6591, Val: 0.9611,\n",
      "diffLevel:14,Epoch: 047, Loss: 0.6591, Val: 0.9611,\n",
      "diffLevel:14,Epoch: 048, Loss: 0.6588, Val: 0.9611,\n",
      "diffLevel:14,Epoch: 049, Loss: 0.6590, Val: 0.9611,\n",
      "diffLevel:14,Epoch: 050, Loss: 0.6589, Val: 0.9612,\n",
      "diffLevel:14,Epoch: 051, Loss: 0.6588, Val: 0.9612,\n",
      "diffLevel:14,Epoch: 052, Loss: 0.6586, Val: 0.9612,\n",
      "diffLevel:14,Epoch: 053, Loss: 0.6586, Val: 0.9612,\n",
      "diffLevel:14,Epoch: 054, Loss: 0.6588, Val: 0.9612,\n",
      "diffLevel:14,Epoch: 055, Loss: 0.6600, Val: 0.9612,\n",
      "diffLevel:14,Epoch: 056, Loss: 0.6593, Val: 0.9612,\n",
      "diffLevel:14,Epoch: 057, Loss: 0.6596, Val: 0.9612,\n",
      "diffLevel:14,Epoch: 058, Loss: 0.6593, Val: 0.9612,\n",
      "diffLevel:14,Epoch: 059, Loss: 0.6584, Val: 0.9612,\n",
      "diffLevel:14,Epoch: 060, Loss: 0.6589, Val: 0.9613,\n",
      "diffLevel:14,Epoch: 061, Loss: 0.6587, Val: 0.9613,\n",
      "diffLevel:14,Epoch: 062, Loss: 0.6588, Val: 0.9612,\n",
      "diffLevel:14,Epoch: 063, Loss: 0.6587, Val: 0.9612,\n",
      "diffLevel:14,Epoch: 064, Loss: 0.6591, Val: 0.9613,\n",
      "diffLevel:14,Epoch: 065, Loss: 0.6590, Val: 0.9613,\n",
      "diffLevel:14,Epoch: 066, Loss: 0.6592, Val: 0.9613,\n",
      "diffLevel:14,Epoch: 067, Loss: 0.6589, Val: 0.9613,\n",
      "diffLevel:14,Epoch: 068, Loss: 0.6588, Val: 0.9613,\n",
      "diffLevel:14,Epoch: 069, Loss: 0.6592, Val: 0.9613,\n",
      "diffLevel:14,Epoch: 070, Loss: 0.6585, Val: 0.9613,\n",
      "diffLevel:14,Epoch: 071, Loss: 0.6580, Val: 0.9613,\n",
      "diffLevel:14,Epoch: 072, Loss: 0.6591, Val: 0.9613,\n",
      "diffLevel:14,Epoch: 073, Loss: 0.6595, Val: 0.9614,\n",
      "diffLevel:14,Epoch: 074, Loss: 0.6587, Val: 0.9614,\n",
      "diffLevel:14,Epoch: 075, Loss: 0.6591, Val: 0.9614,\n",
      "diffLevel:14,Epoch: 076, Loss: 0.6582, Val: 0.9614,\n",
      "diffLevel:14,Epoch: 077, Loss: 0.6590, Val: 0.9614,\n",
      "diffLevel:14,Epoch: 078, Loss: 0.6592, Val: 0.9613,\n",
      "diffLevel:14,Epoch: 079, Loss: 0.6591, Val: 0.9613,\n",
      "diffLevel:14,Epoch: 080, Loss: 0.6586, Val: 0.9613,\n",
      "diffLevel:14,Epoch: 080, Loss: 0.6586, Val: 0.9613,\n",
      "*********\n",
      "训练新的难度等级\n",
      "*********\n",
      "diffLevel:15,Epoch: 001, Loss: 0.6592, Val: 0.9612,\n",
      "diffLevel:15,Epoch: 002, Loss: 0.6587, Val: 0.9610,\n",
      "diffLevel:15,Epoch: 003, Loss: 0.6590, Val: 0.9609,\n",
      "diffLevel:15,Epoch: 004, Loss: 0.6592, Val: 0.9609,\n",
      "diffLevel:15,Epoch: 005, Loss: 0.6589, Val: 0.9610,\n",
      "diffLevel:15,Epoch: 006, Loss: 0.6587, Val: 0.9611,\n",
      "diffLevel:15,Epoch: 007, Loss: 0.6585, Val: 0.9612,\n",
      "diffLevel:15,Epoch: 008, Loss: 0.6591, Val: 0.9613,\n",
      "diffLevel:15,Epoch: 009, Loss: 0.6591, Val: 0.9612,\n",
      "diffLevel:15,Epoch: 010, Loss: 0.6594, Val: 0.9611,\n",
      "diffLevel:15,Epoch: 011, Loss: 0.6586, Val: 0.9610,\n",
      "diffLevel:15,Epoch: 012, Loss: 0.6594, Val: 0.9611,\n",
      "diffLevel:15,Epoch: 013, Loss: 0.6596, Val: 0.9612,\n",
      "diffLevel:15,Epoch: 014, Loss: 0.6589, Val: 0.9613,\n",
      "diffLevel:15,Epoch: 015, Loss: 0.6588, Val: 0.9613,\n",
      "diffLevel:15,Epoch: 016, Loss: 0.6589, Val: 0.9614,\n",
      "diffLevel:15,Epoch: 017, Loss: 0.6589, Val: 0.9613,\n",
      "diffLevel:15,Epoch: 018, Loss: 0.6590, Val: 0.9613,\n",
      "diffLevel:15,Epoch: 019, Loss: 0.6586, Val: 0.9613,\n",
      "diffLevel:15,Epoch: 020, Loss: 0.6592, Val: 0.9613,\n",
      "diffLevel:15,Epoch: 021, Loss: 0.6591, Val: 0.9614,\n",
      "diffLevel:15,Epoch: 022, Loss: 0.6595, Val: 0.9615,\n",
      "diffLevel:15,Epoch: 023, Loss: 0.6589, Val: 0.9615,\n",
      "diffLevel:15,Epoch: 024, Loss: 0.6589, Val: 0.9615,\n",
      "diffLevel:15,Epoch: 025, Loss: 0.6591, Val: 0.9615,\n",
      "diffLevel:15,Epoch: 026, Loss: 0.6592, Val: 0.9615,\n",
      "diffLevel:15,Epoch: 027, Loss: 0.6587, Val: 0.9615,\n",
      "diffLevel:15,Epoch: 028, Loss: 0.6585, Val: 0.9616,\n",
      "diffLevel:15,Epoch: 029, Loss: 0.6582, Val: 0.9616,\n",
      "diffLevel:15,Epoch: 030, Loss: 0.6592, Val: 0.9616,\n",
      "diffLevel:15,Epoch: 031, Loss: 0.6591, Val: 0.9616,\n",
      "diffLevel:15,Epoch: 032, Loss: 0.6587, Val: 0.9615,\n",
      "diffLevel:15,Epoch: 033, Loss: 0.6581, Val: 0.9615,\n",
      "diffLevel:15,Epoch: 034, Loss: 0.6588, Val: 0.9615,\n",
      "diffLevel:15,Epoch: 035, Loss: 0.6589, Val: 0.9616,\n",
      "diffLevel:15,Epoch: 036, Loss: 0.6593, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 037, Loss: 0.6580, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 038, Loss: 0.6590, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 039, Loss: 0.6590, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 040, Loss: 0.6586, Val: 0.9616,\n",
      "diffLevel:15,Epoch: 041, Loss: 0.6582, Val: 0.9616,\n",
      "diffLevel:15,Epoch: 042, Loss: 0.6584, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 043, Loss: 0.6582, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 044, Loss: 0.6579, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 045, Loss: 0.6583, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 046, Loss: 0.6588, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 047, Loss: 0.6592, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 048, Loss: 0.6585, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 049, Loss: 0.6589, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 050, Loss: 0.6582, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 051, Loss: 0.6582, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 052, Loss: 0.6583, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 053, Loss: 0.6590, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 054, Loss: 0.6583, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 055, Loss: 0.6582, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 056, Loss: 0.6583, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 057, Loss: 0.6584, Val: 0.9618,\n",
      "diffLevel:15,Epoch: 058, Loss: 0.6582, Val: 0.9618,\n",
      "diffLevel:15,Epoch: 059, Loss: 0.6583, Val: 0.9618,\n",
      "diffLevel:15,Epoch: 060, Loss: 0.6590, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 061, Loss: 0.6587, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 062, Loss: 0.6590, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 063, Loss: 0.6583, Val: 0.9617,\n",
      "diffLevel:15,Epoch: 064, Loss: 0.6583, Val: 0.9618,\n",
      "diffLevel:15,Epoch: 065, Loss: 0.6594, Val: 0.9618,\n",
      "diffLevel:15,Epoch: 066, Loss: 0.6588, Val: 0.9618,\n",
      "diffLevel:15,Epoch: 067, Loss: 0.6591, Val: 0.9618,\n",
      "diffLevel:15,Epoch: 068, Loss: 0.6589, Val: 0.9618,\n",
      "diffLevel:15,Epoch: 069, Loss: 0.6585, Val: 0.9618,\n",
      "diffLevel:15,Epoch: 070, Loss: 0.6590, Val: 0.9618,\n",
      "diffLevel:15,Epoch: 071, Loss: 0.6583, Val: 0.9618,\n",
      "diffLevel:15,Epoch: 072, Loss: 0.6588, Val: 0.9618,\n",
      "diffLevel:15,Epoch: 073, Loss: 0.6583, Val: 0.9619,\n",
      "diffLevel:15,Epoch: 074, Loss: 0.6582, Val: 0.9619,\n",
      "diffLevel:15,Epoch: 075, Loss: 0.6580, Val: 0.9619,\n",
      "diffLevel:15,Epoch: 076, Loss: 0.6589, Val: 0.9619,\n",
      "diffLevel:15,Epoch: 077, Loss: 0.6585, Val: 0.9619,\n",
      "diffLevel:15,Epoch: 078, Loss: 0.6585, Val: 0.9619,\n",
      "diffLevel:15,Epoch: 079, Loss: 0.6580, Val: 0.9619,\n",
      "diffLevel:15,Epoch: 080, Loss: 0.6579, Val: 0.9620,\n",
      "diffLevel:15,Epoch: 081, Loss: 0.6588, Val: 0.9620,\n",
      "diffLevel:15,Epoch: 082, Loss: 0.6582, Val: 0.9620,\n",
      "diffLevel:15,Epoch: 083, Loss: 0.6582, Val: 0.9620,\n",
      "diffLevel:15,Epoch: 084, Loss: 0.6585, Val: 0.9620,\n",
      "diffLevel:15,Epoch: 085, Loss: 0.6585, Val: 0.9620,\n",
      "diffLevel:15,Epoch: 086, Loss: 0.6584, Val: 0.9620,\n",
      "diffLevel:15,Epoch: 087, Loss: 0.6581, Val: 0.9620,\n",
      "diffLevel:15,Epoch: 088, Loss: 0.6583, Val: 0.9620,\n",
      "diffLevel:15,Epoch: 089, Loss: 0.6590, Val: 0.9620,\n",
      "diffLevel:15,Epoch: 090, Loss: 0.6582, Val: 0.9621,\n",
      "diffLevel:15,Epoch: 091, Loss: 0.6579, Val: 0.9621,\n",
      "diffLevel:15,Epoch: 092, Loss: 0.6590, Val: 0.9621,\n",
      "diffLevel:15,Epoch: 093, Loss: 0.6581, Val: 0.9622,\n",
      "diffLevel:15,Epoch: 094, Loss: 0.6586, Val: 0.9622,\n",
      "diffLevel:15,Epoch: 095, Loss: 0.6586, Val: 0.9622,\n",
      "diffLevel:15,Epoch: 096, Loss: 0.6592, Val: 0.9622,\n",
      "diffLevel:15,Epoch: 097, Loss: 0.6583, Val: 0.9622,\n",
      "diffLevel:15,Epoch: 098, Loss: 0.6584, Val: 0.9622,\n",
      "diffLevel:15,Epoch: 099, Loss: 0.6590, Val: 0.9622,\n",
      "diffLevel:15,Epoch: 100, Loss: 0.6585, Val: 0.9622,\n",
      "diffLevel:15,Epoch: 101, Loss: 0.6597, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 102, Loss: 0.6581, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 103, Loss: 0.6579, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 104, Loss: 0.6593, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 105, Loss: 0.6581, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 106, Loss: 0.6588, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 107, Loss: 0.6585, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 108, Loss: 0.6590, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 109, Loss: 0.6584, Val: 0.9624,\n",
      "diffLevel:15,Epoch: 110, Loss: 0.6580, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 111, Loss: 0.6584, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 112, Loss: 0.6581, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 113, Loss: 0.6588, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 114, Loss: 0.6578, Val: 0.9624,\n",
      "diffLevel:15,Epoch: 115, Loss: 0.6583, Val: 0.9624,\n",
      "diffLevel:15,Epoch: 116, Loss: 0.6584, Val: 0.9624,\n",
      "diffLevel:15,Epoch: 117, Loss: 0.6585, Val: 0.9624,\n",
      "diffLevel:15,Epoch: 118, Loss: 0.6583, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 119, Loss: 0.6586, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 120, Loss: 0.6595, Val: 0.9623,\n",
      "diffLevel:15,Epoch: 120, Loss: 0.6595, Val: 0.9623,\n",
      "  \n",
      "result：\n",
      "loss: 0.6595374345779419\n",
      "val_auc: 0.9622930423592124\n",
      "精确度： 0.2561447811447843\n",
      "召回率： 0.5668106907117668\n",
      "F1： 0.35775418265036113\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"-\" * 10, \"CurLink(GAT)开始训练\", \"-\" * 10)\n",
    "\n",
    "# 构建网络开始训练\n",
    "# 构建网络\n",
    "num_node_features = len(data.x[0])\n",
    "model = GATNet(num_node_features, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "# 训练\n",
    "y_loss = []\n",
    "y_val_auc = []\n",
    "num_fit = 10\n",
    "fit_x = np.array([i + 1 for i in range(num_fit)])\n",
    "for nowDiff in range(NUM_diff_leve):\n",
    "    print(\"*********\\n训练新的难度等级\\n*********\")\n",
    "    y_tmp_val_auc = []\n",
    "    for epoch in range(1, num_epoch+1):\n",
    "        loss = train_diff(data, model, optimizer, nowDiff)\n",
    "        val_auc = val(data, model)\n",
    "        print(f'diffLevel:{nowDiff+1},Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f},')\n",
    "        y_loss.append(float(loss))\n",
    "        y_val_auc.append(float(val_auc))\n",
    "        y_tmp_val_auc.append(float(val_auc))\n",
    "\n",
    "        # 验证集用来控制何时结束训练,拟合直线斜率小于等于0则停止\n",
    "        if len(y_tmp_val_auc) > num_fit:\n",
    "            fit_y = np.array(y_val_auc[-num_fit:])\n",
    "            f1 = np.polyfit(fit_x, fit_y, 1)\n",
    "            if f1[0] <= 0: \n",
    "                print(f'diffLevel:{nowDiff+1},Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f},')\n",
    "                break\n",
    "\n",
    "print(\"  \")\n",
    "print(\"result：\")\n",
    "print(\"loss:\", y_loss[-1])\n",
    "print(\"val_auc:\", y_val_auc[-1])\n",
    "zzz = model.encode(data.x, data.train_pos_edge_index)\n",
    "prob_adj = zzz @ zzz.t()\n",
    "for i in range(len(prob_adj)):\n",
    "    prob_adj[i][i] = 0  # 自己和自己的距离小\n",
    "\n",
    "K = 10  # topk\n",
    "P_K, R_K, F1_ = count_o2n_Acc_Recall(K, prob_adj.cpu(), link_new_labels_M)\n",
    "print(\"精确度：\", P_K)\n",
    "print(\"召回率：\", R_K)\n",
    "print(\"F1：\", F1)\n",
    "\n",
    "x_epoch = [i + 1 for i in range(len(y_val_auc))]\n",
    "drawLossVal(x_epoch, y_loss, \"loss\", \"LOSS_Experiment\", \"epoch\", \"auc\")\n",
    "drawLossVal(x_epoch, y_val_auc, \"val\", \"val_Experiment\", \"epoch\", \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc24157-77de-41e2-978c-a7f10fbcbf93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 异构超图+GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9af3a94f-efbc-426f-b27e-b7afedc39f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 1.0886, Val: 0.6615\n",
      "Epoch: 002, Loss: 1.0440, Val: 0.6774\n",
      "Epoch: 003, Loss: 1.0027, Val: 0.6938\n",
      "Epoch: 004, Loss: 0.9675, Val: 0.7105\n",
      "Epoch: 005, Loss: 0.9335, Val: 0.7272\n",
      "Epoch: 006, Loss: 0.9048, Val: 0.7438\n",
      "Epoch: 007, Loss: 0.8777, Val: 0.7599\n",
      "Epoch: 008, Loss: 0.8532, Val: 0.7753\n",
      "Epoch: 009, Loss: 0.8316, Val: 0.7898\n",
      "Epoch: 010, Loss: 0.8131, Val: 0.8033\n",
      "Epoch: 011, Loss: 0.7957, Val: 0.8158\n",
      "Epoch: 012, Loss: 0.7801, Val: 0.8271\n",
      "Epoch: 013, Loss: 0.7672, Val: 0.8373\n",
      "Epoch: 014, Loss: 0.7553, Val: 0.8464\n",
      "Epoch: 015, Loss: 0.7442, Val: 0.8545\n",
      "Epoch: 016, Loss: 0.7352, Val: 0.8616\n",
      "Epoch: 017, Loss: 0.7271, Val: 0.8679\n",
      "Epoch: 018, Loss: 0.7202, Val: 0.8733\n",
      "Epoch: 019, Loss: 0.7137, Val: 0.8780\n",
      "Epoch: 020, Loss: 0.7082, Val: 0.8820\n",
      "Epoch: 021, Loss: 0.7038, Val: 0.8855\n",
      "Epoch: 022, Loss: 0.6993, Val: 0.8885\n",
      "Epoch: 023, Loss: 0.6962, Val: 0.8911\n",
      "Epoch: 024, Loss: 0.6929, Val: 0.8933\n",
      "Epoch: 025, Loss: 0.6906, Val: 0.8952\n",
      "Epoch: 026, Loss: 0.6883, Val: 0.8969\n",
      "Epoch: 027, Loss: 0.6864, Val: 0.8983\n",
      "Epoch: 028, Loss: 0.6845, Val: 0.8995\n",
      "Epoch: 029, Loss: 0.6833, Val: 0.9006\n",
      "Epoch: 030, Loss: 0.6824, Val: 0.9015\n",
      "Epoch: 031, Loss: 0.6815, Val: 0.9024\n",
      "Epoch: 032, Loss: 0.6805, Val: 0.9031\n",
      "Epoch: 033, Loss: 0.6799, Val: 0.9038\n",
      "Epoch: 034, Loss: 0.6796, Val: 0.9044\n",
      "Epoch: 035, Loss: 0.6793, Val: 0.9050\n",
      "Epoch: 036, Loss: 0.6788, Val: 0.9055\n",
      "Epoch: 037, Loss: 0.6782, Val: 0.9061\n",
      "Epoch: 038, Loss: 0.6782, Val: 0.9065\n",
      "Epoch: 039, Loss: 0.6781, Val: 0.9069\n",
      "Epoch: 040, Loss: 0.6775, Val: 0.9073\n",
      "Epoch: 041, Loss: 0.6778, Val: 0.9077\n",
      "Epoch: 042, Loss: 0.6774, Val: 0.9080\n",
      "Epoch: 043, Loss: 0.6778, Val: 0.9083\n",
      "Epoch: 044, Loss: 0.6774, Val: 0.9087\n",
      "Epoch: 045, Loss: 0.6768, Val: 0.9089\n",
      "Epoch: 046, Loss: 0.6775, Val: 0.9092\n",
      "Epoch: 047, Loss: 0.6775, Val: 0.9095\n",
      "Epoch: 048, Loss: 0.6769, Val: 0.9097\n",
      "Epoch: 049, Loss: 0.6772, Val: 0.9099\n",
      "Epoch: 050, Loss: 0.6766, Val: 0.9101\n",
      "Epoch: 051, Loss: 0.6770, Val: 0.9103\n",
      "Epoch: 052, Loss: 0.6769, Val: 0.9105\n",
      "Epoch: 053, Loss: 0.6767, Val: 0.9107\n",
      "Epoch: 054, Loss: 0.6768, Val: 0.9108\n",
      "Epoch: 055, Loss: 0.6767, Val: 0.9110\n",
      "Epoch: 056, Loss: 0.6766, Val: 0.9112\n",
      "Epoch: 057, Loss: 0.6767, Val: 0.9114\n",
      "Epoch: 058, Loss: 0.6767, Val: 0.9115\n",
      "Epoch: 059, Loss: 0.6767, Val: 0.9116\n",
      "Epoch: 060, Loss: 0.6763, Val: 0.9118\n",
      "Epoch: 061, Loss: 0.6766, Val: 0.9119\n",
      "Epoch: 062, Loss: 0.6761, Val: 0.9121\n",
      "Epoch: 063, Loss: 0.6763, Val: 0.9122\n",
      "Epoch: 064, Loss: 0.6760, Val: 0.9124\n",
      "Epoch: 065, Loss: 0.6763, Val: 0.9125\n",
      "Epoch: 066, Loss: 0.6761, Val: 0.9127\n",
      "Epoch: 067, Loss: 0.6758, Val: 0.9128\n",
      "Epoch: 068, Loss: 0.6759, Val: 0.9130\n",
      "Epoch: 069, Loss: 0.6756, Val: 0.9131\n",
      "Epoch: 070, Loss: 0.6754, Val: 0.9133\n",
      "Epoch: 071, Loss: 0.6761, Val: 0.9134\n",
      "Epoch: 072, Loss: 0.6753, Val: 0.9136\n",
      "Epoch: 073, Loss: 0.6752, Val: 0.9137\n",
      "Epoch: 074, Loss: 0.6756, Val: 0.9139\n",
      "Epoch: 075, Loss: 0.6754, Val: 0.9140\n",
      "Epoch: 076, Loss: 0.6756, Val: 0.9142\n",
      "Epoch: 077, Loss: 0.6754, Val: 0.9143\n",
      "Epoch: 078, Loss: 0.6760, Val: 0.9145\n",
      "Epoch: 079, Loss: 0.6750, Val: 0.9146\n",
      "Epoch: 080, Loss: 0.6749, Val: 0.9148\n",
      "Epoch: 081, Loss: 0.6751, Val: 0.9149\n",
      "Epoch: 082, Loss: 0.6749, Val: 0.9151\n",
      "Epoch: 083, Loss: 0.6750, Val: 0.9152\n",
      "Epoch: 084, Loss: 0.6746, Val: 0.9154\n",
      "Epoch: 085, Loss: 0.6752, Val: 0.9155\n",
      "Epoch: 086, Loss: 0.6751, Val: 0.9157\n",
      "Epoch: 087, Loss: 0.6748, Val: 0.9159\n",
      "Epoch: 088, Loss: 0.6749, Val: 0.9160\n",
      "Epoch: 089, Loss: 0.6745, Val: 0.9162\n",
      "Epoch: 090, Loss: 0.6751, Val: 0.9164\n",
      "Epoch: 091, Loss: 0.6750, Val: 0.9165\n",
      "Epoch: 092, Loss: 0.6748, Val: 0.9167\n",
      "Epoch: 093, Loss: 0.6743, Val: 0.9168\n",
      "Epoch: 094, Loss: 0.6744, Val: 0.9170\n",
      "Epoch: 095, Loss: 0.6747, Val: 0.9171\n",
      "Epoch: 096, Loss: 0.6745, Val: 0.9173\n",
      "Epoch: 097, Loss: 0.6747, Val: 0.9174\n",
      "Epoch: 098, Loss: 0.6743, Val: 0.9176\n",
      "Epoch: 099, Loss: 0.6744, Val: 0.9177\n",
      "Epoch: 100, Loss: 0.6744, Val: 0.9178\n",
      "Epoch: 101, Loss: 0.6742, Val: 0.9179\n",
      "Epoch: 102, Loss: 0.6743, Val: 0.9181\n",
      "Epoch: 103, Loss: 0.6743, Val: 0.9182\n",
      "Epoch: 104, Loss: 0.6745, Val: 0.9183\n",
      "Epoch: 105, Loss: 0.6746, Val: 0.9184\n",
      "Epoch: 106, Loss: 0.6743, Val: 0.9186\n",
      "Epoch: 107, Loss: 0.6739, Val: 0.9187\n",
      "Epoch: 108, Loss: 0.6738, Val: 0.9188\n",
      "Epoch: 109, Loss: 0.6739, Val: 0.9189\n",
      "Epoch: 110, Loss: 0.6740, Val: 0.9190\n",
      "Epoch: 111, Loss: 0.6737, Val: 0.9191\n",
      "Epoch: 112, Loss: 0.6739, Val: 0.9192\n",
      "Epoch: 113, Loss: 0.6734, Val: 0.9193\n",
      "Epoch: 114, Loss: 0.6737, Val: 0.9194\n",
      "Epoch: 115, Loss: 0.6737, Val: 0.9195\n",
      "Epoch: 116, Loss: 0.6740, Val: 0.9196\n",
      "Epoch: 117, Loss: 0.6736, Val: 0.9197\n",
      "Epoch: 118, Loss: 0.6737, Val: 0.9198\n",
      "Epoch: 119, Loss: 0.6731, Val: 0.9199\n",
      "Epoch: 120, Loss: 0.6734, Val: 0.9200\n",
      "Epoch: 121, Loss: 0.6731, Val: 0.9201\n",
      "Epoch: 122, Loss: 0.6731, Val: 0.9202\n",
      "Epoch: 123, Loss: 0.6730, Val: 0.9203\n",
      "Epoch: 124, Loss: 0.6728, Val: 0.9204\n",
      "Epoch: 125, Loss: 0.6731, Val: 0.9205\n",
      "Epoch: 126, Loss: 0.6728, Val: 0.9206\n",
      "Epoch: 127, Loss: 0.6734, Val: 0.9207\n",
      "Epoch: 128, Loss: 0.6727, Val: 0.9207\n",
      "Epoch: 129, Loss: 0.6732, Val: 0.9208\n",
      "Epoch: 130, Loss: 0.6733, Val: 0.9209\n",
      "Epoch: 131, Loss: 0.6727, Val: 0.9210\n",
      "Epoch: 132, Loss: 0.6729, Val: 0.9210\n",
      "Epoch: 133, Loss: 0.6730, Val: 0.9211\n",
      "Epoch: 134, Loss: 0.6732, Val: 0.9212\n",
      "Epoch: 135, Loss: 0.6730, Val: 0.9213\n",
      "Epoch: 136, Loss: 0.6723, Val: 0.9213\n",
      "Epoch: 137, Loss: 0.6724, Val: 0.9214\n",
      "Epoch: 138, Loss: 0.6731, Val: 0.9214\n",
      "Epoch: 139, Loss: 0.6726, Val: 0.9215\n",
      "Epoch: 140, Loss: 0.6730, Val: 0.9216\n",
      "Epoch: 141, Loss: 0.6728, Val: 0.9216\n",
      "Epoch: 142, Loss: 0.6725, Val: 0.9217\n",
      "Epoch: 143, Loss: 0.6725, Val: 0.9217\n",
      "Epoch: 144, Loss: 0.6722, Val: 0.9218\n",
      "Epoch: 145, Loss: 0.6723, Val: 0.9218\n",
      "Epoch: 146, Loss: 0.6723, Val: 0.9218\n",
      "Epoch: 147, Loss: 0.6725, Val: 0.9219\n",
      "Epoch: 148, Loss: 0.6720, Val: 0.9219\n",
      "Epoch: 149, Loss: 0.6721, Val: 0.9220\n",
      "Epoch: 150, Loss: 0.6719, Val: 0.9220\n",
      "Epoch: 151, Loss: 0.6721, Val: 0.9220\n",
      "Epoch: 152, Loss: 0.6722, Val: 0.9221\n",
      "Epoch: 153, Loss: 0.6728, Val: 0.9221\n",
      "Epoch: 154, Loss: 0.6720, Val: 0.9222\n",
      "Epoch: 155, Loss: 0.6718, Val: 0.9222\n",
      "Epoch: 156, Loss: 0.6720, Val: 0.9222\n",
      "Epoch: 157, Loss: 0.6717, Val: 0.9223\n",
      "Epoch: 158, Loss: 0.6724, Val: 0.9223\n",
      "Epoch: 159, Loss: 0.6711, Val: 0.9224\n",
      "Epoch: 160, Loss: 0.6716, Val: 0.9224\n",
      "Epoch: 161, Loss: 0.6713, Val: 0.9224\n",
      "Epoch: 162, Loss: 0.6719, Val: 0.9225\n",
      "Epoch: 163, Loss: 0.6712, Val: 0.9225\n",
      "Epoch: 164, Loss: 0.6716, Val: 0.9225\n",
      "Epoch: 165, Loss: 0.6715, Val: 0.9226\n",
      "Epoch: 166, Loss: 0.6715, Val: 0.9226\n",
      "Epoch: 167, Loss: 0.6713, Val: 0.9226\n",
      "Epoch: 168, Loss: 0.6714, Val: 0.9227\n",
      "Epoch: 169, Loss: 0.6714, Val: 0.9227\n",
      "Epoch: 170, Loss: 0.6715, Val: 0.9228\n",
      "Epoch: 171, Loss: 0.6717, Val: 0.9228\n",
      "Epoch: 172, Loss: 0.6712, Val: 0.9229\n",
      "Epoch: 173, Loss: 0.6709, Val: 0.9229\n",
      "Epoch: 174, Loss: 0.6712, Val: 0.9229\n",
      "Epoch: 175, Loss: 0.6715, Val: 0.9230\n",
      "Epoch: 176, Loss: 0.6709, Val: 0.9230\n",
      "Epoch: 177, Loss: 0.6714, Val: 0.9230\n",
      "Epoch: 178, Loss: 0.6709, Val: 0.9231\n",
      "Epoch: 179, Loss: 0.6708, Val: 0.9231\n",
      "Epoch: 180, Loss: 0.6712, Val: 0.9232\n",
      "Epoch: 181, Loss: 0.6707, Val: 0.9232\n",
      "Epoch: 182, Loss: 0.6710, Val: 0.9232\n",
      "Epoch: 183, Loss: 0.6708, Val: 0.9233\n",
      "Epoch: 184, Loss: 0.6708, Val: 0.9233\n",
      "Epoch: 185, Loss: 0.6706, Val: 0.9234\n",
      "Epoch: 186, Loss: 0.6710, Val: 0.9234\n",
      "Epoch: 187, Loss: 0.6707, Val: 0.9235\n",
      "Epoch: 188, Loss: 0.6708, Val: 0.9235\n",
      "Epoch: 189, Loss: 0.6710, Val: 0.9236\n",
      "Epoch: 190, Loss: 0.6704, Val: 0.9236\n",
      "Epoch: 191, Loss: 0.6702, Val: 0.9236\n",
      "Epoch: 192, Loss: 0.6704, Val: 0.9237\n",
      "Epoch: 193, Loss: 0.6704, Val: 0.9237\n",
      "Epoch: 194, Loss: 0.6700, Val: 0.9238\n",
      "Epoch: 195, Loss: 0.6705, Val: 0.9239\n",
      "Epoch: 196, Loss: 0.6699, Val: 0.9239\n",
      "Epoch: 197, Loss: 0.6702, Val: 0.9240\n",
      "Epoch: 198, Loss: 0.6705, Val: 0.9240\n",
      "Epoch: 199, Loss: 0.6707, Val: 0.9241\n",
      "Epoch: 200, Loss: 0.6702, Val: 0.9241\n",
      "Epoch: 201, Loss: 0.6705, Val: 0.9242\n",
      "Epoch: 202, Loss: 0.6704, Val: 0.9242\n",
      "Epoch: 203, Loss: 0.6708, Val: 0.9243\n",
      "Epoch: 204, Loss: 0.6696, Val: 0.9244\n",
      "Epoch: 205, Loss: 0.6700, Val: 0.9244\n",
      "Epoch: 206, Loss: 0.6703, Val: 0.9245\n",
      "Epoch: 207, Loss: 0.6698, Val: 0.9245\n",
      "Epoch: 208, Loss: 0.6705, Val: 0.9246\n",
      "Epoch: 209, Loss: 0.6700, Val: 0.9247\n",
      "Epoch: 210, Loss: 0.6708, Val: 0.9248\n",
      "Epoch: 211, Loss: 0.6700, Val: 0.9249\n",
      "Epoch: 212, Loss: 0.6698, Val: 0.9249\n",
      "Epoch: 213, Loss: 0.6700, Val: 0.9250\n",
      "Epoch: 214, Loss: 0.6698, Val: 0.9251\n",
      "Epoch: 215, Loss: 0.6700, Val: 0.9252\n",
      "Epoch: 216, Loss: 0.6699, Val: 0.9252\n",
      "Epoch: 217, Loss: 0.6705, Val: 0.9253\n",
      "Epoch: 218, Loss: 0.6698, Val: 0.9254\n",
      "Epoch: 219, Loss: 0.6701, Val: 0.9254\n",
      "Epoch: 220, Loss: 0.6699, Val: 0.9255\n",
      "Epoch: 221, Loss: 0.6698, Val: 0.9256\n",
      "Epoch: 222, Loss: 0.6696, Val: 0.9257\n",
      "Epoch: 223, Loss: 0.6699, Val: 0.9258\n",
      "Epoch: 224, Loss: 0.6699, Val: 0.9259\n",
      "Epoch: 225, Loss: 0.6699, Val: 0.9260\n",
      "Epoch: 226, Loss: 0.6697, Val: 0.9261\n",
      "Epoch: 227, Loss: 0.6702, Val: 0.9261\n",
      "Epoch: 228, Loss: 0.6695, Val: 0.9262\n",
      "Epoch: 229, Loss: 0.6696, Val: 0.9263\n",
      "Epoch: 230, Loss: 0.6695, Val: 0.9264\n",
      "Epoch: 231, Loss: 0.6697, Val: 0.9265\n",
      "Epoch: 232, Loss: 0.6694, Val: 0.9265\n",
      "Epoch: 233, Loss: 0.6696, Val: 0.9266\n",
      "Epoch: 234, Loss: 0.6692, Val: 0.9267\n",
      "Epoch: 235, Loss: 0.6696, Val: 0.9268\n",
      "Epoch: 236, Loss: 0.6698, Val: 0.9269\n",
      "Epoch: 237, Loss: 0.6696, Val: 0.9270\n",
      "Epoch: 238, Loss: 0.6698, Val: 0.9271\n",
      "Epoch: 239, Loss: 0.6692, Val: 0.9272\n",
      "Epoch: 240, Loss: 0.6694, Val: 0.9273\n",
      "Epoch: 241, Loss: 0.6691, Val: 0.9274\n",
      "Epoch: 242, Loss: 0.6692, Val: 0.9274\n",
      "Epoch: 243, Loss: 0.6693, Val: 0.9275\n",
      "Epoch: 244, Loss: 0.6694, Val: 0.9276\n",
      "Epoch: 245, Loss: 0.6692, Val: 0.9277\n",
      "Epoch: 246, Loss: 0.6683, Val: 0.9278\n",
      "Epoch: 247, Loss: 0.6695, Val: 0.9278\n",
      "Epoch: 248, Loss: 0.6698, Val: 0.9280\n",
      "Epoch: 249, Loss: 0.6691, Val: 0.9281\n",
      "Epoch: 250, Loss: 0.6690, Val: 0.9282\n",
      "Epoch: 251, Loss: 0.6690, Val: 0.9283\n",
      "Epoch: 252, Loss: 0.6685, Val: 0.9283\n",
      "Epoch: 253, Loss: 0.6693, Val: 0.9284\n",
      "Epoch: 254, Loss: 0.6694, Val: 0.9285\n",
      "Epoch: 255, Loss: 0.6693, Val: 0.9286\n",
      "Epoch: 256, Loss: 0.6684, Val: 0.9287\n",
      "Epoch: 257, Loss: 0.6688, Val: 0.9288\n",
      "Epoch: 258, Loss: 0.6690, Val: 0.9289\n",
      "Epoch: 259, Loss: 0.6689, Val: 0.9290\n",
      "Epoch: 260, Loss: 0.6687, Val: 0.9291\n",
      "Epoch: 261, Loss: 0.6693, Val: 0.9291\n",
      "Epoch: 262, Loss: 0.6693, Val: 0.9292\n",
      "Epoch: 263, Loss: 0.6690, Val: 0.9293\n",
      "Epoch: 264, Loss: 0.6689, Val: 0.9294\n",
      "Epoch: 265, Loss: 0.6684, Val: 0.9295\n",
      "Epoch: 266, Loss: 0.6690, Val: 0.9296\n",
      "Epoch: 267, Loss: 0.6687, Val: 0.9297\n",
      "Epoch: 268, Loss: 0.6688, Val: 0.9297\n",
      "Epoch: 269, Loss: 0.6685, Val: 0.9298\n",
      "Epoch: 270, Loss: 0.6688, Val: 0.9299\n",
      "Epoch: 271, Loss: 0.6687, Val: 0.9300\n",
      "Epoch: 272, Loss: 0.6689, Val: 0.9301\n",
      "Epoch: 273, Loss: 0.6688, Val: 0.9302\n",
      "Epoch: 274, Loss: 0.6686, Val: 0.9303\n",
      "Epoch: 275, Loss: 0.6684, Val: 0.9304\n",
      "Epoch: 276, Loss: 0.6687, Val: 0.9305\n",
      "Epoch: 277, Loss: 0.6679, Val: 0.9306\n",
      "Epoch: 278, Loss: 0.6688, Val: 0.9306\n",
      "Epoch: 279, Loss: 0.6688, Val: 0.9307\n",
      "Epoch: 280, Loss: 0.6685, Val: 0.9308\n",
      "Epoch: 281, Loss: 0.6685, Val: 0.9309\n",
      "Epoch: 282, Loss: 0.6687, Val: 0.9309\n",
      "Epoch: 283, Loss: 0.6684, Val: 0.9310\n",
      "Epoch: 284, Loss: 0.6682, Val: 0.9311\n",
      "Epoch: 285, Loss: 0.6686, Val: 0.9312\n",
      "Epoch: 286, Loss: 0.6680, Val: 0.9313\n",
      "Epoch: 287, Loss: 0.6684, Val: 0.9314\n",
      "Epoch: 288, Loss: 0.6682, Val: 0.9314\n",
      "Epoch: 289, Loss: 0.6686, Val: 0.9315\n",
      "Epoch: 290, Loss: 0.6688, Val: 0.9316\n",
      "Epoch: 291, Loss: 0.6682, Val: 0.9317\n",
      "Epoch: 292, Loss: 0.6679, Val: 0.9318\n",
      "Epoch: 293, Loss: 0.6679, Val: 0.9319\n",
      "Epoch: 294, Loss: 0.6683, Val: 0.9320\n",
      "Epoch: 295, Loss: 0.6682, Val: 0.9321\n",
      "Epoch: 296, Loss: 0.6681, Val: 0.9322\n",
      "Epoch: 297, Loss: 0.6686, Val: 0.9322\n",
      "Epoch: 298, Loss: 0.6677, Val: 0.9323\n",
      "Epoch: 299, Loss: 0.6684, Val: 0.9324\n",
      "Epoch: 300, Loss: 0.6684, Val: 0.9325\n",
      "Epoch: 301, Loss: 0.6674, Val: 0.9326\n",
      "Epoch: 302, Loss: 0.6679, Val: 0.9327\n",
      "Epoch: 303, Loss: 0.6678, Val: 0.9328\n",
      "Epoch: 304, Loss: 0.6681, Val: 0.9328\n",
      "Epoch: 305, Loss: 0.6678, Val: 0.9329\n",
      "Epoch: 306, Loss: 0.6677, Val: 0.9330\n",
      "Epoch: 307, Loss: 0.6683, Val: 0.9330\n",
      "Epoch: 308, Loss: 0.6679, Val: 0.9331\n",
      "Epoch: 309, Loss: 0.6677, Val: 0.9332\n",
      "Epoch: 310, Loss: 0.6685, Val: 0.9333\n",
      "Epoch: 311, Loss: 0.6675, Val: 0.9333\n",
      "Epoch: 312, Loss: 0.6679, Val: 0.9334\n",
      "Epoch: 313, Loss: 0.6676, Val: 0.9335\n",
      "Epoch: 314, Loss: 0.6680, Val: 0.9336\n",
      "Epoch: 315, Loss: 0.6676, Val: 0.9336\n",
      "Epoch: 316, Loss: 0.6680, Val: 0.9337\n",
      "Epoch: 317, Loss: 0.6673, Val: 0.9338\n",
      "Epoch: 318, Loss: 0.6680, Val: 0.9339\n",
      "Epoch: 319, Loss: 0.6680, Val: 0.9339\n",
      "Epoch: 320, Loss: 0.6676, Val: 0.9340\n",
      "Epoch: 321, Loss: 0.6678, Val: 0.9341\n",
      "Epoch: 322, Loss: 0.6672, Val: 0.9342\n",
      "Epoch: 323, Loss: 0.6678, Val: 0.9342\n",
      "Epoch: 324, Loss: 0.6682, Val: 0.9343\n",
      "Epoch: 325, Loss: 0.6675, Val: 0.9344\n",
      "Epoch: 326, Loss: 0.6669, Val: 0.9345\n",
      "Epoch: 327, Loss: 0.6676, Val: 0.9345\n",
      "Epoch: 328, Loss: 0.6672, Val: 0.9346\n",
      "Epoch: 329, Loss: 0.6675, Val: 0.9346\n",
      "Epoch: 330, Loss: 0.6674, Val: 0.9347\n",
      "Epoch: 331, Loss: 0.6679, Val: 0.9348\n",
      "Epoch: 332, Loss: 0.6671, Val: 0.9348\n",
      "Epoch: 333, Loss: 0.6674, Val: 0.9349\n",
      "Epoch: 334, Loss: 0.6679, Val: 0.9350\n",
      "Epoch: 335, Loss: 0.6672, Val: 0.9350\n",
      "Epoch: 336, Loss: 0.6673, Val: 0.9351\n",
      "Epoch: 337, Loss: 0.6673, Val: 0.9352\n",
      "Epoch: 338, Loss: 0.6672, Val: 0.9352\n",
      "Epoch: 339, Loss: 0.6674, Val: 0.9353\n",
      "Epoch: 340, Loss: 0.6675, Val: 0.9354\n",
      "Epoch: 341, Loss: 0.6675, Val: 0.9354\n",
      "Epoch: 342, Loss: 0.6672, Val: 0.9355\n",
      "Epoch: 343, Loss: 0.6678, Val: 0.9356\n",
      "Epoch: 344, Loss: 0.6673, Val: 0.9356\n",
      "Epoch: 345, Loss: 0.6677, Val: 0.9357\n",
      "Epoch: 346, Loss: 0.6670, Val: 0.9358\n",
      "Epoch: 347, Loss: 0.6667, Val: 0.9358\n",
      "Epoch: 348, Loss: 0.6673, Val: 0.9359\n",
      "Epoch: 349, Loss: 0.6674, Val: 0.9359\n",
      "Epoch: 350, Loss: 0.6671, Val: 0.9360\n",
      "Epoch: 351, Loss: 0.6674, Val: 0.9361\n",
      "Epoch: 352, Loss: 0.6672, Val: 0.9361\n",
      "Epoch: 353, Loss: 0.6669, Val: 0.9362\n",
      "Epoch: 354, Loss: 0.6671, Val: 0.9363\n",
      "Epoch: 355, Loss: 0.6670, Val: 0.9364\n",
      "Epoch: 356, Loss: 0.6671, Val: 0.9365\n",
      "Epoch: 357, Loss: 0.6668, Val: 0.9365\n",
      "Epoch: 358, Loss: 0.6674, Val: 0.9365\n",
      "Epoch: 359, Loss: 0.6670, Val: 0.9366\n",
      "Epoch: 360, Loss: 0.6673, Val: 0.9367\n",
      "Epoch: 361, Loss: 0.6669, Val: 0.9368\n",
      "Epoch: 362, Loss: 0.6667, Val: 0.9368\n",
      "Epoch: 363, Loss: 0.6670, Val: 0.9369\n",
      "Epoch: 364, Loss: 0.6668, Val: 0.9370\n",
      "Epoch: 365, Loss: 0.6671, Val: 0.9370\n",
      "Epoch: 366, Loss: 0.6668, Val: 0.9370\n",
      "Epoch: 367, Loss: 0.6672, Val: 0.9371\n",
      "Epoch: 368, Loss: 0.6671, Val: 0.9372\n",
      "Epoch: 369, Loss: 0.6668, Val: 0.9373\n",
      "Epoch: 370, Loss: 0.6670, Val: 0.9373\n",
      "Epoch: 371, Loss: 0.6671, Val: 0.9374\n",
      "Epoch: 372, Loss: 0.6665, Val: 0.9375\n",
      "Epoch: 373, Loss: 0.6670, Val: 0.9375\n",
      "Epoch: 374, Loss: 0.6668, Val: 0.9376\n",
      "Epoch: 375, Loss: 0.6668, Val: 0.9376\n",
      "Epoch: 376, Loss: 0.6667, Val: 0.9376\n",
      "Epoch: 377, Loss: 0.6672, Val: 0.9377\n",
      "Epoch: 378, Loss: 0.6669, Val: 0.9378\n",
      "Epoch: 379, Loss: 0.6666, Val: 0.9378\n",
      "Epoch: 380, Loss: 0.6669, Val: 0.9379\n",
      "Epoch: 381, Loss: 0.6674, Val: 0.9380\n",
      "Epoch: 382, Loss: 0.6669, Val: 0.9381\n",
      "Epoch: 383, Loss: 0.6670, Val: 0.9381\n",
      "Epoch: 384, Loss: 0.6661, Val: 0.9381\n",
      "Epoch: 385, Loss: 0.6668, Val: 0.9382\n",
      "Epoch: 386, Loss: 0.6665, Val: 0.9382\n",
      "Epoch: 387, Loss: 0.6664, Val: 0.9383\n",
      "Epoch: 388, Loss: 0.6667, Val: 0.9384\n",
      "Epoch: 389, Loss: 0.6669, Val: 0.9384\n",
      "Epoch: 390, Loss: 0.6663, Val: 0.9385\n",
      "Epoch: 391, Loss: 0.6674, Val: 0.9386\n",
      "Epoch: 392, Loss: 0.6658, Val: 0.9386\n",
      "Epoch: 393, Loss: 0.6671, Val: 0.9387\n",
      "Epoch: 394, Loss: 0.6664, Val: 0.9387\n",
      "Epoch: 395, Loss: 0.6664, Val: 0.9388\n",
      "Epoch: 396, Loss: 0.6668, Val: 0.9388\n",
      "Epoch: 397, Loss: 0.6666, Val: 0.9389\n",
      "Epoch: 398, Loss: 0.6658, Val: 0.9389\n",
      "Epoch: 399, Loss: 0.6660, Val: 0.9389\n",
      "Epoch: 400, Loss: 0.6664, Val: 0.9390\n",
      "Epoch: 401, Loss: 0.6668, Val: 0.9391\n",
      "Epoch: 402, Loss: 0.6661, Val: 0.9391\n",
      "Epoch: 403, Loss: 0.6667, Val: 0.9392\n",
      "Epoch: 404, Loss: 0.6662, Val: 0.9392\n",
      "Epoch: 405, Loss: 0.6664, Val: 0.9393\n",
      "Epoch: 406, Loss: 0.6662, Val: 0.9393\n",
      "Epoch: 407, Loss: 0.6667, Val: 0.9394\n",
      "Epoch: 408, Loss: 0.6655, Val: 0.9394\n",
      "Epoch: 409, Loss: 0.6665, Val: 0.9395\n",
      "Epoch: 410, Loss: 0.6665, Val: 0.9395\n",
      "Epoch: 411, Loss: 0.6666, Val: 0.9396\n",
      "Epoch: 412, Loss: 0.6664, Val: 0.9396\n",
      "Epoch: 413, Loss: 0.6659, Val: 0.9397\n",
      "Epoch: 414, Loss: 0.6663, Val: 0.9397\n",
      "Epoch: 415, Loss: 0.6665, Val: 0.9398\n",
      "Epoch: 416, Loss: 0.6662, Val: 0.9398\n",
      "Epoch: 417, Loss: 0.6668, Val: 0.9398\n",
      "Epoch: 418, Loss: 0.6659, Val: 0.9399\n",
      "Epoch: 419, Loss: 0.6667, Val: 0.9400\n",
      "Epoch: 420, Loss: 0.6667, Val: 0.9400\n",
      "Epoch: 421, Loss: 0.6663, Val: 0.9401\n",
      "Epoch: 422, Loss: 0.6661, Val: 0.9401\n",
      "Epoch: 423, Loss: 0.6658, Val: 0.9402\n",
      "Epoch: 424, Loss: 0.6662, Val: 0.9402\n",
      "Epoch: 425, Loss: 0.6660, Val: 0.9403\n",
      "Epoch: 426, Loss: 0.6660, Val: 0.9404\n",
      "Epoch: 427, Loss: 0.6658, Val: 0.9404\n",
      "Epoch: 428, Loss: 0.6659, Val: 0.9405\n",
      "Epoch: 429, Loss: 0.6660, Val: 0.9405\n",
      "Epoch: 430, Loss: 0.6664, Val: 0.9405\n",
      "Epoch: 431, Loss: 0.6658, Val: 0.9406\n",
      "Epoch: 432, Loss: 0.6660, Val: 0.9406\n",
      "Epoch: 433, Loss: 0.6664, Val: 0.9407\n",
      "Epoch: 434, Loss: 0.6661, Val: 0.9407\n",
      "Epoch: 435, Loss: 0.6662, Val: 0.9408\n",
      "Epoch: 436, Loss: 0.6656, Val: 0.9409\n",
      "Epoch: 437, Loss: 0.6655, Val: 0.9409\n",
      "Epoch: 438, Loss: 0.6659, Val: 0.9410\n",
      "Epoch: 439, Loss: 0.6659, Val: 0.9410\n",
      "Epoch: 440, Loss: 0.6659, Val: 0.9410\n",
      "Epoch: 441, Loss: 0.6660, Val: 0.9411\n",
      "Epoch: 442, Loss: 0.6661, Val: 0.9411\n",
      "Epoch: 443, Loss: 0.6659, Val: 0.9411\n",
      "Epoch: 444, Loss: 0.6657, Val: 0.9412\n",
      "Epoch: 445, Loss: 0.6659, Val: 0.9412\n",
      "Epoch: 446, Loss: 0.6659, Val: 0.9413\n",
      "Epoch: 447, Loss: 0.6653, Val: 0.9413\n",
      "Epoch: 448, Loss: 0.6656, Val: 0.9414\n",
      "Epoch: 449, Loss: 0.6653, Val: 0.9415\n",
      "Epoch: 450, Loss: 0.6662, Val: 0.9415\n",
      "Epoch: 451, Loss: 0.6661, Val: 0.9416\n",
      "Epoch: 452, Loss: 0.6660, Val: 0.9416\n",
      "Epoch: 453, Loss: 0.6655, Val: 0.9416\n",
      "Epoch: 454, Loss: 0.6657, Val: 0.9417\n",
      "Epoch: 455, Loss: 0.6658, Val: 0.9417\n",
      "Epoch: 456, Loss: 0.6656, Val: 0.9418\n",
      "Epoch: 457, Loss: 0.6662, Val: 0.9418\n",
      "Epoch: 458, Loss: 0.6656, Val: 0.9419\n",
      "Epoch: 459, Loss: 0.6663, Val: 0.9419\n",
      "Epoch: 460, Loss: 0.6655, Val: 0.9420\n",
      "Epoch: 461, Loss: 0.6657, Val: 0.9420\n",
      "Epoch: 462, Loss: 0.6655, Val: 0.9421\n",
      "Epoch: 463, Loss: 0.6656, Val: 0.9421\n",
      "Epoch: 464, Loss: 0.6653, Val: 0.9421\n",
      "Epoch: 465, Loss: 0.6657, Val: 0.9422\n",
      "Epoch: 466, Loss: 0.6655, Val: 0.9422\n",
      "Epoch: 467, Loss: 0.6659, Val: 0.9423\n",
      "Epoch: 468, Loss: 0.6650, Val: 0.9423\n",
      "Epoch: 469, Loss: 0.6660, Val: 0.9424\n",
      "Epoch: 470, Loss: 0.6660, Val: 0.9424\n",
      "Epoch: 471, Loss: 0.6652, Val: 0.9424\n",
      "Epoch: 472, Loss: 0.6661, Val: 0.9425\n",
      "Epoch: 473, Loss: 0.6656, Val: 0.9425\n",
      "Epoch: 474, Loss: 0.6659, Val: 0.9426\n",
      "Epoch: 475, Loss: 0.6655, Val: 0.9426\n",
      "Epoch: 476, Loss: 0.6652, Val: 0.9427\n",
      "Epoch: 477, Loss: 0.6659, Val: 0.9427\n",
      "Epoch: 478, Loss: 0.6653, Val: 0.9428\n",
      "Epoch: 479, Loss: 0.6655, Val: 0.9428\n",
      "Epoch: 480, Loss: 0.6660, Val: 0.9428\n",
      "Epoch: 481, Loss: 0.6653, Val: 0.9429\n",
      "Epoch: 482, Loss: 0.6655, Val: 0.9429\n",
      "Epoch: 483, Loss: 0.6653, Val: 0.9430\n",
      "Epoch: 484, Loss: 0.6656, Val: 0.9430\n",
      "Epoch: 485, Loss: 0.6660, Val: 0.9431\n",
      "Epoch: 486, Loss: 0.6657, Val: 0.9431\n",
      "Epoch: 487, Loss: 0.6663, Val: 0.9431\n",
      "Epoch: 488, Loss: 0.6654, Val: 0.9432\n",
      "Epoch: 489, Loss: 0.6650, Val: 0.9432\n",
      "Epoch: 490, Loss: 0.6658, Val: 0.9433\n",
      "Epoch: 491, Loss: 0.6653, Val: 0.9433\n",
      "Epoch: 492, Loss: 0.6659, Val: 0.9434\n",
      "Epoch: 493, Loss: 0.6651, Val: 0.9434\n",
      "Epoch: 494, Loss: 0.6650, Val: 0.9434\n",
      "Epoch: 495, Loss: 0.6653, Val: 0.9435\n",
      "Epoch: 496, Loss: 0.6652, Val: 0.9435\n",
      "Epoch: 497, Loss: 0.6652, Val: 0.9436\n",
      "Epoch: 498, Loss: 0.6655, Val: 0.9436\n",
      "Epoch: 499, Loss: 0.6654, Val: 0.9436\n",
      "Epoch: 500, Loss: 0.6656, Val: 0.9437\n",
      "Epoch: 501, Loss: 0.6658, Val: 0.9438\n",
      "Epoch: 502, Loss: 0.6652, Val: 0.9438\n",
      "Epoch: 503, Loss: 0.6653, Val: 0.9438\n",
      "Epoch: 504, Loss: 0.6652, Val: 0.9439\n",
      "Epoch: 505, Loss: 0.6652, Val: 0.9439\n",
      "Epoch: 506, Loss: 0.6649, Val: 0.9439\n",
      "Epoch: 507, Loss: 0.6651, Val: 0.9440\n",
      "Epoch: 508, Loss: 0.6654, Val: 0.9440\n",
      "Epoch: 509, Loss: 0.6654, Val: 0.9441\n",
      "Epoch: 510, Loss: 0.6659, Val: 0.9442\n",
      "Epoch: 511, Loss: 0.6646, Val: 0.9442\n",
      "Epoch: 512, Loss: 0.6648, Val: 0.9442\n",
      "Epoch: 513, Loss: 0.6652, Val: 0.9442\n",
      "Epoch: 514, Loss: 0.6644, Val: 0.9442\n",
      "Epoch: 515, Loss: 0.6652, Val: 0.9443\n",
      "Epoch: 516, Loss: 0.6650, Val: 0.9443\n",
      "Epoch: 517, Loss: 0.6652, Val: 0.9444\n",
      "Epoch: 518, Loss: 0.6652, Val: 0.9444\n",
      "Epoch: 519, Loss: 0.6649, Val: 0.9445\n",
      "Epoch: 520, Loss: 0.6651, Val: 0.9445\n",
      "Epoch: 521, Loss: 0.6656, Val: 0.9445\n",
      "Epoch: 522, Loss: 0.6653, Val: 0.9445\n",
      "Epoch: 523, Loss: 0.6641, Val: 0.9445\n",
      "Epoch: 524, Loss: 0.6645, Val: 0.9446\n",
      "Epoch: 525, Loss: 0.6645, Val: 0.9446\n",
      "Epoch: 526, Loss: 0.6650, Val: 0.9447\n",
      "Epoch: 527, Loss: 0.6651, Val: 0.9447\n",
      "Epoch: 528, Loss: 0.6653, Val: 0.9447\n",
      "Epoch: 529, Loss: 0.6651, Val: 0.9448\n",
      "Epoch: 530, Loss: 0.6645, Val: 0.9448\n",
      "Epoch: 531, Loss: 0.6650, Val: 0.9448\n",
      "Epoch: 532, Loss: 0.6652, Val: 0.9449\n",
      "Epoch: 533, Loss: 0.6648, Val: 0.9449\n",
      "Epoch: 534, Loss: 0.6647, Val: 0.9449\n",
      "Epoch: 535, Loss: 0.6645, Val: 0.9449\n",
      "Epoch: 536, Loss: 0.6649, Val: 0.9450\n",
      "Epoch: 537, Loss: 0.6654, Val: 0.9450\n",
      "Epoch: 538, Loss: 0.6646, Val: 0.9451\n",
      "Epoch: 539, Loss: 0.6648, Val: 0.9451\n",
      "Epoch: 540, Loss: 0.6645, Val: 0.9452\n",
      "Epoch: 541, Loss: 0.6646, Val: 0.9452\n",
      "Epoch: 542, Loss: 0.6647, Val: 0.9452\n",
      "Epoch: 543, Loss: 0.6652, Val: 0.9453\n",
      "Epoch: 544, Loss: 0.6637, Val: 0.9453\n",
      "Epoch: 545, Loss: 0.6644, Val: 0.9453\n",
      "Epoch: 546, Loss: 0.6648, Val: 0.9454\n",
      "Epoch: 547, Loss: 0.6652, Val: 0.9454\n",
      "Epoch: 548, Loss: 0.6645, Val: 0.9455\n",
      "Epoch: 549, Loss: 0.6647, Val: 0.9455\n",
      "Epoch: 550, Loss: 0.6647, Val: 0.9456\n",
      "Epoch: 551, Loss: 0.6648, Val: 0.9456\n",
      "Epoch: 552, Loss: 0.6644, Val: 0.9456\n",
      "Epoch: 553, Loss: 0.6643, Val: 0.9456\n",
      "Epoch: 554, Loss: 0.6639, Val: 0.9457\n",
      "Epoch: 555, Loss: 0.6652, Val: 0.9457\n",
      "Epoch: 556, Loss: 0.6647, Val: 0.9458\n",
      "Epoch: 557, Loss: 0.6644, Val: 0.9458\n",
      "Epoch: 558, Loss: 0.6649, Val: 0.9459\n",
      "Epoch: 559, Loss: 0.6648, Val: 0.9459\n",
      "Epoch: 560, Loss: 0.6644, Val: 0.9459\n",
      "Epoch: 561, Loss: 0.6643, Val: 0.9460\n",
      "Epoch: 562, Loss: 0.6646, Val: 0.9460\n",
      "Epoch: 563, Loss: 0.6650, Val: 0.9460\n",
      "Epoch: 564, Loss: 0.6647, Val: 0.9461\n",
      "Epoch: 565, Loss: 0.6650, Val: 0.9461\n",
      "Epoch: 566, Loss: 0.6643, Val: 0.9461\n",
      "Epoch: 567, Loss: 0.6637, Val: 0.9462\n",
      "Epoch: 568, Loss: 0.6639, Val: 0.9462\n",
      "Epoch: 569, Loss: 0.6639, Val: 0.9463\n",
      "Epoch: 570, Loss: 0.6645, Val: 0.9463\n",
      "Epoch: 571, Loss: 0.6644, Val: 0.9463\n",
      "Epoch: 572, Loss: 0.6647, Val: 0.9464\n",
      "Epoch: 573, Loss: 0.6648, Val: 0.9464\n",
      "Epoch: 574, Loss: 0.6641, Val: 0.9464\n",
      "Epoch: 575, Loss: 0.6645, Val: 0.9464\n",
      "Epoch: 576, Loss: 0.6649, Val: 0.9464\n",
      "Epoch: 577, Loss: 0.6648, Val: 0.9465\n",
      "Epoch: 578, Loss: 0.6640, Val: 0.9465\n",
      "Epoch: 579, Loss: 0.6647, Val: 0.9466\n",
      "Epoch: 580, Loss: 0.6648, Val: 0.9466\n",
      "Epoch: 581, Loss: 0.6645, Val: 0.9466\n",
      "Epoch: 582, Loss: 0.6644, Val: 0.9466\n",
      "Epoch: 583, Loss: 0.6645, Val: 0.9467\n",
      "Epoch: 584, Loss: 0.6637, Val: 0.9467\n",
      "Epoch: 585, Loss: 0.6640, Val: 0.9468\n",
      "Epoch: 586, Loss: 0.6645, Val: 0.9468\n",
      "Epoch: 587, Loss: 0.6644, Val: 0.9469\n",
      "Epoch: 588, Loss: 0.6643, Val: 0.9469\n",
      "Epoch: 589, Loss: 0.6648, Val: 0.9469\n",
      "Epoch: 590, Loss: 0.6641, Val: 0.9469\n",
      "Epoch: 591, Loss: 0.6638, Val: 0.9469\n",
      "Epoch: 592, Loss: 0.6642, Val: 0.9470\n",
      "Epoch: 593, Loss: 0.6645, Val: 0.9470\n",
      "Epoch: 594, Loss: 0.6640, Val: 0.9471\n",
      "Epoch: 595, Loss: 0.6647, Val: 0.9471\n",
      "Epoch: 596, Loss: 0.6645, Val: 0.9471\n",
      "Epoch: 597, Loss: 0.6646, Val: 0.9472\n",
      "Epoch: 598, Loss: 0.6649, Val: 0.9472\n",
      "Epoch: 599, Loss: 0.6643, Val: 0.9472\n",
      "Epoch: 600, Loss: 0.6637, Val: 0.9472\n",
      "Epoch: 601, Loss: 0.6643, Val: 0.9473\n",
      "Epoch: 602, Loss: 0.6640, Val: 0.9473\n",
      "Epoch: 603, Loss: 0.6640, Val: 0.9474\n",
      "Epoch: 604, Loss: 0.6635, Val: 0.9475\n",
      "Epoch: 605, Loss: 0.6639, Val: 0.9475\n",
      "Epoch: 606, Loss: 0.6642, Val: 0.9476\n",
      "Epoch: 607, Loss: 0.6638, Val: 0.9476\n",
      "Epoch: 608, Loss: 0.6647, Val: 0.9476\n",
      "Epoch: 609, Loss: 0.6642, Val: 0.9476\n",
      "Epoch: 610, Loss: 0.6641, Val: 0.9476\n",
      "Epoch: 611, Loss: 0.6643, Val: 0.9476\n",
      "Epoch: 612, Loss: 0.6644, Val: 0.9477\n",
      "Epoch: 613, Loss: 0.6643, Val: 0.9477\n",
      "Epoch: 614, Loss: 0.6639, Val: 0.9478\n",
      "Epoch: 615, Loss: 0.6648, Val: 0.9478\n",
      "Epoch: 616, Loss: 0.6647, Val: 0.9479\n",
      "Epoch: 617, Loss: 0.6643, Val: 0.9479\n",
      "Epoch: 618, Loss: 0.6638, Val: 0.9480\n",
      "Epoch: 619, Loss: 0.6645, Val: 0.9480\n",
      "Epoch: 620, Loss: 0.6639, Val: 0.9481\n",
      "Epoch: 621, Loss: 0.6637, Val: 0.9481\n",
      "Epoch: 622, Loss: 0.6638, Val: 0.9481\n",
      "Epoch: 623, Loss: 0.6642, Val: 0.9481\n",
      "Epoch: 624, Loss: 0.6644, Val: 0.9481\n",
      "Epoch: 625, Loss: 0.6637, Val: 0.9481\n",
      "Epoch: 626, Loss: 0.6638, Val: 0.9482\n",
      "Epoch: 627, Loss: 0.6642, Val: 0.9482\n",
      "Epoch: 628, Loss: 0.6644, Val: 0.9483\n",
      "Epoch: 629, Loss: 0.6639, Val: 0.9483\n",
      "Epoch: 630, Loss: 0.6637, Val: 0.9483\n",
      "Epoch: 631, Loss: 0.6638, Val: 0.9483\n",
      "Epoch: 632, Loss: 0.6634, Val: 0.9483\n",
      "Epoch: 633, Loss: 0.6646, Val: 0.9484\n",
      "Epoch: 634, Loss: 0.6645, Val: 0.9484\n",
      "Epoch: 635, Loss: 0.6636, Val: 0.9485\n",
      "Epoch: 636, Loss: 0.6638, Val: 0.9485\n",
      "Epoch: 637, Loss: 0.6640, Val: 0.9486\n",
      "Epoch: 638, Loss: 0.6636, Val: 0.9486\n",
      "Epoch: 639, Loss: 0.6639, Val: 0.9486\n",
      "Epoch: 640, Loss: 0.6643, Val: 0.9486\n",
      "Epoch: 641, Loss: 0.6633, Val: 0.9487\n",
      "Epoch: 642, Loss: 0.6638, Val: 0.9487\n",
      "Epoch: 643, Loss: 0.6641, Val: 0.9488\n",
      "Epoch: 644, Loss: 0.6634, Val: 0.9488\n",
      "Epoch: 645, Loss: 0.6636, Val: 0.9488\n",
      "Epoch: 646, Loss: 0.6635, Val: 0.9488\n",
      "Epoch: 647, Loss: 0.6649, Val: 0.9488\n",
      "Epoch: 648, Loss: 0.6635, Val: 0.9489\n",
      "Epoch: 649, Loss: 0.6647, Val: 0.9489\n",
      "Epoch: 650, Loss: 0.6636, Val: 0.9490\n",
      "Epoch: 651, Loss: 0.6640, Val: 0.9490\n",
      "Epoch: 652, Loss: 0.6642, Val: 0.9490\n",
      "Epoch: 653, Loss: 0.6642, Val: 0.9490\n",
      "Epoch: 654, Loss: 0.6644, Val: 0.9491\n",
      "Epoch: 655, Loss: 0.6630, Val: 0.9491\n",
      "Epoch: 656, Loss: 0.6638, Val: 0.9491\n",
      "Epoch: 657, Loss: 0.6640, Val: 0.9492\n",
      "Epoch: 658, Loss: 0.6642, Val: 0.9492\n",
      "Epoch: 659, Loss: 0.6636, Val: 0.9493\n",
      "Epoch: 660, Loss: 0.6644, Val: 0.9493\n",
      "Epoch: 661, Loss: 0.6635, Val: 0.9493\n",
      "Epoch: 662, Loss: 0.6640, Val: 0.9493\n",
      "Epoch: 663, Loss: 0.6644, Val: 0.9493\n",
      "Epoch: 664, Loss: 0.6638, Val: 0.9494\n",
      "Epoch: 665, Loss: 0.6630, Val: 0.9495\n",
      "Epoch: 666, Loss: 0.6633, Val: 0.9495\n",
      "Epoch: 667, Loss: 0.6625, Val: 0.9495\n",
      "Epoch: 668, Loss: 0.6632, Val: 0.9496\n",
      "Epoch: 669, Loss: 0.6637, Val: 0.9496\n",
      "Epoch: 670, Loss: 0.6638, Val: 0.9496\n",
      "Epoch: 671, Loss: 0.6642, Val: 0.9496\n",
      "Epoch: 672, Loss: 0.6634, Val: 0.9497\n",
      "Epoch: 673, Loss: 0.6639, Val: 0.9497\n",
      "Epoch: 674, Loss: 0.6636, Val: 0.9497\n",
      "Epoch: 675, Loss: 0.6638, Val: 0.9498\n",
      "Epoch: 676, Loss: 0.6642, Val: 0.9498\n",
      "Epoch: 677, Loss: 0.6635, Val: 0.9498\n",
      "Epoch: 678, Loss: 0.6636, Val: 0.9498\n",
      "Epoch: 679, Loss: 0.6634, Val: 0.9499\n",
      "Epoch: 680, Loss: 0.6632, Val: 0.9499\n",
      "Epoch: 681, Loss: 0.6632, Val: 0.9500\n",
      "Epoch: 682, Loss: 0.6633, Val: 0.9500\n",
      "Epoch: 683, Loss: 0.6636, Val: 0.9500\n",
      "Epoch: 684, Loss: 0.6632, Val: 0.9500\n",
      "Epoch: 685, Loss: 0.6643, Val: 0.9501\n",
      "Epoch: 686, Loss: 0.6638, Val: 0.9501\n",
      "Epoch: 687, Loss: 0.6633, Val: 0.9501\n",
      "Epoch: 688, Loss: 0.6637, Val: 0.9501\n",
      "Epoch: 689, Loss: 0.6635, Val: 0.9501\n",
      "Epoch: 690, Loss: 0.6634, Val: 0.9502\n",
      "Epoch: 691, Loss: 0.6631, Val: 0.9502\n",
      "Epoch: 692, Loss: 0.6636, Val: 0.9502\n",
      "Epoch: 693, Loss: 0.6632, Val: 0.9503\n",
      "Epoch: 694, Loss: 0.6631, Val: 0.9503\n",
      "Epoch: 695, Loss: 0.6636, Val: 0.9503\n",
      "Epoch: 696, Loss: 0.6635, Val: 0.9503\n",
      "Epoch: 697, Loss: 0.6633, Val: 0.9504\n",
      "Epoch: 698, Loss: 0.6634, Val: 0.9504\n",
      "Epoch: 699, Loss: 0.6641, Val: 0.9504\n",
      "Epoch: 700, Loss: 0.6636, Val: 0.9505\n",
      "Epoch: 701, Loss: 0.6635, Val: 0.9505\n",
      "Epoch: 702, Loss: 0.6632, Val: 0.9506\n",
      "Epoch: 703, Loss: 0.6641, Val: 0.9506\n",
      "Epoch: 704, Loss: 0.6635, Val: 0.9506\n",
      "Epoch: 705, Loss: 0.6635, Val: 0.9507\n",
      "Epoch: 706, Loss: 0.6636, Val: 0.9507\n",
      "Epoch: 707, Loss: 0.6636, Val: 0.9508\n",
      "Epoch: 708, Loss: 0.6639, Val: 0.9508\n",
      "Epoch: 709, Loss: 0.6640, Val: 0.9509\n",
      "Epoch: 710, Loss: 0.6635, Val: 0.9509\n",
      "Epoch: 711, Loss: 0.6637, Val: 0.9509\n",
      "Epoch: 712, Loss: 0.6631, Val: 0.9509\n",
      "Epoch: 713, Loss: 0.6631, Val: 0.9509\n",
      "Epoch: 714, Loss: 0.6631, Val: 0.9510\n",
      "Epoch: 715, Loss: 0.6634, Val: 0.9511\n",
      "Epoch: 716, Loss: 0.6632, Val: 0.9511\n",
      "Epoch: 717, Loss: 0.6633, Val: 0.9510\n",
      "Epoch: 718, Loss: 0.6635, Val: 0.9510\n",
      "Epoch: 719, Loss: 0.6628, Val: 0.9510\n",
      "Epoch: 720, Loss: 0.6634, Val: 0.9510\n",
      "Epoch: 721, Loss: 0.6631, Val: 0.9511\n",
      "Epoch: 722, Loss: 0.6633, Val: 0.9511\n",
      "Epoch: 723, Loss: 0.6630, Val: 0.9512\n",
      "Epoch: 724, Loss: 0.6625, Val: 0.9512\n",
      "Epoch: 725, Loss: 0.6630, Val: 0.9512\n",
      "Epoch: 726, Loss: 0.6628, Val: 0.9512\n",
      "Epoch: 727, Loss: 0.6635, Val: 0.9512\n",
      "Epoch: 728, Loss: 0.6630, Val: 0.9512\n",
      "Epoch: 729, Loss: 0.6628, Val: 0.9512\n",
      "Epoch: 730, Loss: 0.6634, Val: 0.9512\n",
      "Epoch: 731, Loss: 0.6634, Val: 0.9512\n",
      "Epoch: 732, Loss: 0.6636, Val: 0.9513\n",
      "Epoch: 733, Loss: 0.6634, Val: 0.9513\n",
      "Epoch: 734, Loss: 0.6632, Val: 0.9513\n",
      "Epoch: 735, Loss: 0.6634, Val: 0.9513\n",
      "Epoch: 736, Loss: 0.6626, Val: 0.9513\n",
      "Epoch: 737, Loss: 0.6632, Val: 0.9513\n",
      "Epoch: 738, Loss: 0.6625, Val: 0.9513\n",
      "Epoch: 739, Loss: 0.6629, Val: 0.9514\n",
      "Epoch: 740, Loss: 0.6631, Val: 0.9514\n",
      "Epoch: 741, Loss: 0.6635, Val: 0.9514\n",
      "Epoch: 742, Loss: 0.6633, Val: 0.9515\n",
      "Epoch: 743, Loss: 0.6630, Val: 0.9515\n",
      "Epoch: 744, Loss: 0.6625, Val: 0.9516\n",
      "Epoch: 745, Loss: 0.6638, Val: 0.9516\n",
      "Epoch: 746, Loss: 0.6631, Val: 0.9517\n",
      "Epoch: 747, Loss: 0.6635, Val: 0.9517\n",
      "Epoch: 748, Loss: 0.6627, Val: 0.9517\n",
      "Epoch: 749, Loss: 0.6632, Val: 0.9517\n",
      "Epoch: 750, Loss: 0.6634, Val: 0.9518\n",
      "Epoch: 751, Loss: 0.6637, Val: 0.9518\n",
      "Epoch: 752, Loss: 0.6634, Val: 0.9519\n",
      "Epoch: 753, Loss: 0.6635, Val: 0.9519\n",
      "Epoch: 754, Loss: 0.6626, Val: 0.9520\n",
      "Epoch: 755, Loss: 0.6629, Val: 0.9520\n",
      "Epoch: 756, Loss: 0.6639, Val: 0.9520\n",
      "Epoch: 757, Loss: 0.6636, Val: 0.9520\n",
      "Epoch: 758, Loss: 0.6633, Val: 0.9520\n",
      "Epoch: 759, Loss: 0.6625, Val: 0.9520\n",
      "Epoch: 760, Loss: 0.6629, Val: 0.9521\n",
      "Epoch: 761, Loss: 0.6633, Val: 0.9522\n",
      "Epoch: 762, Loss: 0.6631, Val: 0.9522\n",
      "Epoch: 763, Loss: 0.6628, Val: 0.9522\n",
      "Epoch: 764, Loss: 0.6637, Val: 0.9522\n",
      "Epoch: 765, Loss: 0.6628, Val: 0.9523\n",
      "Epoch: 766, Loss: 0.6629, Val: 0.9523\n",
      "Epoch: 767, Loss: 0.6624, Val: 0.9523\n",
      "Epoch: 768, Loss: 0.6633, Val: 0.9523\n",
      "Epoch: 769, Loss: 0.6629, Val: 0.9524\n",
      "Epoch: 770, Loss: 0.6635, Val: 0.9524\n",
      "Epoch: 771, Loss: 0.6629, Val: 0.9524\n",
      "Epoch: 772, Loss: 0.6626, Val: 0.9525\n",
      "Epoch: 773, Loss: 0.6623, Val: 0.9525\n",
      "Epoch: 774, Loss: 0.6627, Val: 0.9525\n",
      "Epoch: 775, Loss: 0.6637, Val: 0.9526\n",
      "Epoch: 776, Loss: 0.6633, Val: 0.9526\n",
      "Epoch: 777, Loss: 0.6627, Val: 0.9526\n",
      "Epoch: 778, Loss: 0.6627, Val: 0.9526\n",
      "Epoch: 779, Loss: 0.6628, Val: 0.9526\n",
      "Epoch: 780, Loss: 0.6629, Val: 0.9526\n",
      "Epoch: 781, Loss: 0.6624, Val: 0.9527\n",
      "Epoch: 782, Loss: 0.6631, Val: 0.9527\n",
      "Epoch: 783, Loss: 0.6634, Val: 0.9528\n",
      "Epoch: 784, Loss: 0.6627, Val: 0.9528\n",
      "Epoch: 785, Loss: 0.6631, Val: 0.9528\n",
      "Epoch: 786, Loss: 0.6631, Val: 0.9528\n",
      "Epoch: 787, Loss: 0.6631, Val: 0.9528\n",
      "Epoch: 788, Loss: 0.6624, Val: 0.9529\n",
      "Epoch: 789, Loss: 0.6630, Val: 0.9529\n",
      "Epoch: 790, Loss: 0.6630, Val: 0.9530\n",
      "Epoch: 791, Loss: 0.6630, Val: 0.9530\n",
      "Epoch: 792, Loss: 0.6625, Val: 0.9530\n",
      "Epoch: 793, Loss: 0.6631, Val: 0.9530\n",
      "Epoch: 794, Loss: 0.6622, Val: 0.9530\n",
      "Epoch: 795, Loss: 0.6627, Val: 0.9530\n",
      "Epoch: 796, Loss: 0.6626, Val: 0.9531\n",
      "Epoch: 797, Loss: 0.6621, Val: 0.9531\n",
      "Epoch: 798, Loss: 0.6626, Val: 0.9531\n",
      "Epoch: 799, Loss: 0.6632, Val: 0.9531\n",
      "Epoch: 800, Loss: 0.6632, Val: 0.9531\n",
      "Epoch: 801, Loss: 0.6623, Val: 0.9531\n",
      "Epoch: 802, Loss: 0.6625, Val: 0.9531\n",
      "Epoch: 803, Loss: 0.6627, Val: 0.9532\n",
      "Epoch: 804, Loss: 0.6630, Val: 0.9532\n",
      "Epoch: 805, Loss: 0.6625, Val: 0.9533\n",
      "Epoch: 806, Loss: 0.6626, Val: 0.9533\n",
      "Epoch: 807, Loss: 0.6627, Val: 0.9533\n",
      "Epoch: 808, Loss: 0.6630, Val: 0.9533\n",
      "Epoch: 809, Loss: 0.6626, Val: 0.9533\n",
      "Epoch: 810, Loss: 0.6623, Val: 0.9533\n",
      "Epoch: 811, Loss: 0.6626, Val: 0.9534\n",
      "Epoch: 812, Loss: 0.6633, Val: 0.9534\n",
      "Epoch: 813, Loss: 0.6629, Val: 0.9534\n",
      "Epoch: 814, Loss: 0.6625, Val: 0.9534\n",
      "Epoch: 815, Loss: 0.6625, Val: 0.9534\n",
      "Epoch: 816, Loss: 0.6629, Val: 0.9534\n",
      "Epoch: 817, Loss: 0.6627, Val: 0.9535\n",
      "Epoch: 818, Loss: 0.6626, Val: 0.9535\n",
      "Epoch: 819, Loss: 0.6627, Val: 0.9536\n",
      "Epoch: 820, Loss: 0.6624, Val: 0.9536\n",
      "Epoch: 821, Loss: 0.6626, Val: 0.9536\n",
      "Epoch: 822, Loss: 0.6630, Val: 0.9536\n",
      "Epoch: 823, Loss: 0.6627, Val: 0.9536\n",
      "Epoch: 824, Loss: 0.6623, Val: 0.9536\n",
      "Epoch: 825, Loss: 0.6623, Val: 0.9537\n",
      "Epoch: 826, Loss: 0.6631, Val: 0.9537\n",
      "Epoch: 827, Loss: 0.6622, Val: 0.9538\n",
      "Epoch: 828, Loss: 0.6626, Val: 0.9538\n",
      "Epoch: 829, Loss: 0.6619, Val: 0.9538\n",
      "Epoch: 830, Loss: 0.6628, Val: 0.9538\n",
      "Epoch: 831, Loss: 0.6626, Val: 0.9538\n",
      "Epoch: 832, Loss: 0.6611, Val: 0.9538\n",
      "Epoch: 833, Loss: 0.6629, Val: 0.9538\n",
      "Epoch: 834, Loss: 0.6624, Val: 0.9539\n",
      "Epoch: 835, Loss: 0.6628, Val: 0.9539\n",
      "Epoch: 836, Loss: 0.6623, Val: 0.9539\n",
      "Epoch: 837, Loss: 0.6623, Val: 0.9539\n",
      "Epoch: 838, Loss: 0.6622, Val: 0.9539\n",
      "Epoch: 839, Loss: 0.6630, Val: 0.9540\n",
      "Epoch: 840, Loss: 0.6628, Val: 0.9540\n",
      "Epoch: 841, Loss: 0.6620, Val: 0.9540\n",
      "Epoch: 842, Loss: 0.6621, Val: 0.9541\n",
      "Epoch: 843, Loss: 0.6630, Val: 0.9541\n",
      "Epoch: 844, Loss: 0.6617, Val: 0.9541\n",
      "Epoch: 845, Loss: 0.6631, Val: 0.9541\n",
      "Epoch: 846, Loss: 0.6625, Val: 0.9541\n",
      "Epoch: 847, Loss: 0.6631, Val: 0.9542\n",
      "Epoch: 848, Loss: 0.6625, Val: 0.9542\n",
      "Epoch: 849, Loss: 0.6617, Val: 0.9542\n",
      "Epoch: 850, Loss: 0.6625, Val: 0.9542\n",
      "Epoch: 851, Loss: 0.6618, Val: 0.9542\n",
      "Epoch: 852, Loss: 0.6626, Val: 0.9542\n",
      "Epoch: 853, Loss: 0.6624, Val: 0.9543\n",
      "Epoch: 854, Loss: 0.6622, Val: 0.9543\n",
      "Epoch: 855, Loss: 0.6623, Val: 0.9543\n",
      "Epoch: 856, Loss: 0.6631, Val: 0.9543\n",
      "Epoch: 857, Loss: 0.6629, Val: 0.9544\n",
      "Epoch: 858, Loss: 0.6625, Val: 0.9544\n",
      "Epoch: 859, Loss: 0.6620, Val: 0.9544\n",
      "Epoch: 860, Loss: 0.6622, Val: 0.9544\n",
      "Epoch: 861, Loss: 0.6625, Val: 0.9544\n",
      "Epoch: 862, Loss: 0.6627, Val: 0.9544\n",
      "Epoch: 863, Loss: 0.6619, Val: 0.9544\n",
      "Epoch: 864, Loss: 0.6622, Val: 0.9545\n",
      "Epoch: 865, Loss: 0.6629, Val: 0.9545\n",
      "Epoch: 866, Loss: 0.6629, Val: 0.9545\n",
      "Epoch: 867, Loss: 0.6622, Val: 0.9545\n",
      "Epoch: 868, Loss: 0.6627, Val: 0.9545\n",
      "Epoch: 869, Loss: 0.6629, Val: 0.9546\n",
      "Epoch: 870, Loss: 0.6625, Val: 0.9546\n",
      "Epoch: 871, Loss: 0.6624, Val: 0.9547\n",
      "Epoch: 872, Loss: 0.6622, Val: 0.9547\n",
      "Epoch: 873, Loss: 0.6629, Val: 0.9547\n",
      "Epoch: 874, Loss: 0.6623, Val: 0.9546\n",
      "Epoch: 875, Loss: 0.6620, Val: 0.9546\n",
      "Epoch: 876, Loss: 0.6621, Val: 0.9547\n",
      "Epoch: 877, Loss: 0.6623, Val: 0.9548\n",
      "Epoch: 878, Loss: 0.6621, Val: 0.9548\n",
      "Epoch: 879, Loss: 0.6620, Val: 0.9548\n",
      "Epoch: 880, Loss: 0.6621, Val: 0.9548\n",
      "Epoch: 881, Loss: 0.6624, Val: 0.9548\n",
      "Epoch: 882, Loss: 0.6623, Val: 0.9548\n",
      "Epoch: 883, Loss: 0.6622, Val: 0.9548\n",
      "Epoch: 884, Loss: 0.6621, Val: 0.9548\n",
      "Epoch: 885, Loss: 0.6619, Val: 0.9549\n",
      "Epoch: 886, Loss: 0.6622, Val: 0.9549\n",
      "Epoch: 887, Loss: 0.6624, Val: 0.9549\n",
      "Epoch: 888, Loss: 0.6614, Val: 0.9549\n",
      "Epoch: 889, Loss: 0.6622, Val: 0.9549\n",
      "Epoch: 890, Loss: 0.6620, Val: 0.9549\n",
      "Epoch: 891, Loss: 0.6622, Val: 0.9549\n",
      "Epoch: 892, Loss: 0.6623, Val: 0.9550\n",
      "Epoch: 893, Loss: 0.6626, Val: 0.9550\n",
      "Epoch: 894, Loss: 0.6612, Val: 0.9550\n",
      "Epoch: 895, Loss: 0.6620, Val: 0.9551\n",
      "Epoch: 896, Loss: 0.6615, Val: 0.9551\n",
      "Epoch: 897, Loss: 0.6619, Val: 0.9551\n",
      "Epoch: 898, Loss: 0.6617, Val: 0.9551\n",
      "Epoch: 899, Loss: 0.6620, Val: 0.9551\n",
      "Epoch: 900, Loss: 0.6622, Val: 0.9552\n",
      "Epoch: 901, Loss: 0.6624, Val: 0.9552\n",
      "Epoch: 902, Loss: 0.6618, Val: 0.9551\n",
      "Epoch: 903, Loss: 0.6619, Val: 0.9551\n",
      "Epoch: 904, Loss: 0.6623, Val: 0.9552\n",
      "Epoch: 905, Loss: 0.6621, Val: 0.9552\n",
      "Epoch: 906, Loss: 0.6626, Val: 0.9552\n",
      "Epoch: 907, Loss: 0.6625, Val: 0.9553\n",
      "Epoch: 908, Loss: 0.6622, Val: 0.9553\n",
      "Epoch: 909, Loss: 0.6619, Val: 0.9553\n",
      "Epoch: 910, Loss: 0.6620, Val: 0.9553\n",
      "Epoch: 911, Loss: 0.6618, Val: 0.9553\n",
      "Epoch: 912, Loss: 0.6623, Val: 0.9554\n",
      "Epoch: 913, Loss: 0.6623, Val: 0.9554\n",
      "Epoch: 914, Loss: 0.6614, Val: 0.9554\n",
      "Epoch: 915, Loss: 0.6627, Val: 0.9555\n",
      "Epoch: 916, Loss: 0.6622, Val: 0.9555\n",
      "Epoch: 917, Loss: 0.6623, Val: 0.9555\n",
      "Epoch: 918, Loss: 0.6628, Val: 0.9555\n",
      "Epoch: 919, Loss: 0.6622, Val: 0.9555\n",
      "Epoch: 920, Loss: 0.6619, Val: 0.9555\n",
      "Epoch: 921, Loss: 0.6622, Val: 0.9556\n",
      "Epoch: 922, Loss: 0.6622, Val: 0.9556\n",
      "Epoch: 923, Loss: 0.6619, Val: 0.9557\n",
      "Epoch: 924, Loss: 0.6621, Val: 0.9557\n",
      "Epoch: 925, Loss: 0.6620, Val: 0.9557\n",
      "Epoch: 926, Loss: 0.6617, Val: 0.9557\n",
      "Epoch: 927, Loss: 0.6615, Val: 0.9557\n",
      "Epoch: 928, Loss: 0.6623, Val: 0.9558\n",
      "Epoch: 929, Loss: 0.6622, Val: 0.9558\n",
      "Epoch: 930, Loss: 0.6618, Val: 0.9558\n",
      "Epoch: 931, Loss: 0.6623, Val: 0.9558\n",
      "Epoch: 932, Loss: 0.6617, Val: 0.9558\n",
      "Epoch: 933, Loss: 0.6616, Val: 0.9559\n",
      "Epoch: 934, Loss: 0.6624, Val: 0.9559\n",
      "Epoch: 935, Loss: 0.6623, Val: 0.9559\n",
      "Epoch: 936, Loss: 0.6624, Val: 0.9559\n",
      "Epoch: 937, Loss: 0.6620, Val: 0.9559\n",
      "Epoch: 938, Loss: 0.6624, Val: 0.9560\n",
      "Epoch: 939, Loss: 0.6613, Val: 0.9560\n",
      "Epoch: 940, Loss: 0.6620, Val: 0.9561\n",
      "Epoch: 941, Loss: 0.6608, Val: 0.9561\n",
      "Epoch: 942, Loss: 0.6614, Val: 0.9561\n",
      "Epoch: 943, Loss: 0.6619, Val: 0.9561\n",
      "Epoch: 944, Loss: 0.6611, Val: 0.9561\n",
      "Epoch: 945, Loss: 0.6621, Val: 0.9561\n",
      "Epoch: 946, Loss: 0.6622, Val: 0.9562\n",
      "Epoch: 947, Loss: 0.6619, Val: 0.9562\n",
      "Epoch: 948, Loss: 0.6618, Val: 0.9562\n",
      "Epoch: 949, Loss: 0.6622, Val: 0.9562\n",
      "Epoch: 950, Loss: 0.6620, Val: 0.9562\n",
      "Epoch: 951, Loss: 0.6621, Val: 0.9562\n",
      "Epoch: 952, Loss: 0.6618, Val: 0.9562\n",
      "Epoch: 953, Loss: 0.6619, Val: 0.9563\n",
      "Epoch: 954, Loss: 0.6623, Val: 0.9563\n",
      "Epoch: 955, Loss: 0.6617, Val: 0.9563\n",
      "Epoch: 956, Loss: 0.6620, Val: 0.9563\n",
      "Epoch: 957, Loss: 0.6626, Val: 0.9563\n",
      "Epoch: 958, Loss: 0.6624, Val: 0.9563\n",
      "Epoch: 959, Loss: 0.6620, Val: 0.9563\n",
      "Epoch: 960, Loss: 0.6618, Val: 0.9563\n",
      "Epoch: 961, Loss: 0.6616, Val: 0.9563\n",
      "Epoch: 962, Loss: 0.6617, Val: 0.9564\n",
      "Epoch: 963, Loss: 0.6617, Val: 0.9564\n",
      "Epoch: 964, Loss: 0.6620, Val: 0.9564\n",
      "Epoch: 965, Loss: 0.6621, Val: 0.9564\n",
      "Epoch: 966, Loss: 0.6620, Val: 0.9564\n",
      "Epoch: 967, Loss: 0.6615, Val: 0.9565\n",
      "Epoch: 968, Loss: 0.6608, Val: 0.9565\n",
      "Epoch: 969, Loss: 0.6618, Val: 0.9565\n",
      "Epoch: 970, Loss: 0.6621, Val: 0.9565\n",
      "Epoch: 971, Loss: 0.6620, Val: 0.9565\n",
      "Epoch: 972, Loss: 0.6620, Val: 0.9566\n",
      "Epoch: 973, Loss: 0.6618, Val: 0.9566\n",
      "Epoch: 974, Loss: 0.6613, Val: 0.9567\n",
      "Epoch: 975, Loss: 0.6618, Val: 0.9567\n",
      "Epoch: 976, Loss: 0.6621, Val: 0.9567\n",
      "Epoch: 977, Loss: 0.6616, Val: 0.9567\n",
      "Epoch: 978, Loss: 0.6626, Val: 0.9567\n",
      "Epoch: 979, Loss: 0.6614, Val: 0.9567\n",
      "Epoch: 980, Loss: 0.6621, Val: 0.9567\n",
      "Epoch: 981, Loss: 0.6611, Val: 0.9567\n",
      "Epoch: 982, Loss: 0.6613, Val: 0.9567\n",
      "Epoch: 983, Loss: 0.6620, Val: 0.9567\n",
      "Epoch: 984, Loss: 0.6615, Val: 0.9567\n",
      "Epoch: 985, Loss: 0.6623, Val: 0.9567\n",
      "Epoch: 986, Loss: 0.6614, Val: 0.9568\n",
      "Epoch: 987, Loss: 0.6612, Val: 0.9568\n",
      "Epoch: 988, Loss: 0.6617, Val: 0.9568\n",
      "Epoch: 989, Loss: 0.6612, Val: 0.9568\n",
      "Epoch: 990, Loss: 0.6616, Val: 0.9568\n",
      "Epoch: 991, Loss: 0.6620, Val: 0.9568\n",
      "Epoch: 992, Loss: 0.6618, Val: 0.9567\n",
      "Epoch: 993, Loss: 0.6613, Val: 0.9568\n",
      "Epoch: 994, Loss: 0.6614, Val: 0.9568\n",
      "Epoch: 995, Loss: 0.6606, Val: 0.9569\n",
      "Epoch: 996, Loss: 0.6614, Val: 0.9569\n",
      "Epoch: 997, Loss: 0.6616, Val: 0.9569\n",
      "Epoch: 998, Loss: 0.6607, Val: 0.9569\n",
      "Epoch: 999, Loss: 0.6613, Val: 0.9569\n",
      "Epoch: 1000, Loss: 0.6622, Val: 0.9569\n",
      "  \n",
      "result：\n",
      "loss: 0.6621735692024231\n",
      "val_auc: 0.9569024445451257\n",
      "精确度： 0.05925925925925873\n",
      "召回率： 0.17686376999472977\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构建训练的data\n",
    "x_curLink = torch.tensor(HeterHyper_id_vec_list, dtype=torch.float32)\n",
    "edge_index = [[], []]\n",
    "for uid1, uid2 in zip(friendship_old_df['uid1'], friendship_old_df['uid2']):\n",
    "    edge_index[0].append(uid1)\n",
    "    edge_index[1].append(uid2)\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "edge_new_index = [[], []]\n",
    "for uid1, uid2 in zip(friendship_new_df['uid1'], friendship_new_df['uid2']):\n",
    "    edge_new_index[0].append(uid1)\n",
    "    edge_new_index[1].append(uid2)\n",
    "edge_new_index = torch.tensor(edge_new_index, dtype=torch.long)\n",
    "data = Data(x=x_curLink, edge_index=edge_index, edge_new_index=edge_new_index)  # 构建data\n",
    "\n",
    "# 网络数据放入GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 使用GPU\n",
    "ground_truth_edge_index = data.edge_index.to(device)  # 数据放入GPU\n",
    "# 样本负采样,测试集验证集分裂,按学习难度分化数据集\n",
    "data = train_test_split_edges_m(data, val_ratio=0.1, neg_candidates_num=int(num_u * 0.1))\n",
    "# data = train_Diff_split_edges(data, node_diffASC_list, NUM_diff_leve)  # 根据学习难度，对边数据进行分级\n",
    "data = data.to(device)  # 将数据放入device\n",
    "\n",
    "# 构建网络\n",
    "num_node_features = len(data.x[0])\n",
    "model = GATNet(num_node_features, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "\n",
    "x_epoch = []\n",
    "y_loss = []\n",
    "y_val_auc = []\n",
    "num_fit = 10\n",
    "fit_x = np.array([i + 1 for i in range(num_fit)])\n",
    "for epoch in range(1, 1000+1):\n",
    "    loss = train(data, model, optimizer)\n",
    "    val_auc = val(data, model)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}')\n",
    "    x_epoch.append(epoch)\n",
    "    y_loss.append(float(loss))\n",
    "    y_val_auc.append(float(val_auc))\n",
    "\n",
    "    # 验证集用来控制何时结束训练,拟合直线斜率小于等于0则停止\n",
    "    if len(y_val_auc) > num_fit:\n",
    "        fit_y = np.array(y_val_auc[-num_fit:])\n",
    "        f1 = np.polyfit(fit_x, fit_y, 1)\n",
    "        if f1[0] <= 0: break\n",
    "\n",
    "print(\"  \")\n",
    "print(\"result：\")\n",
    "print(\"loss:\", y_loss[-1])\n",
    "print(\"val_auc:\", y_val_auc[-1])\n",
    "zzz = model.encode(data.x, data.train_pos_edge_index)\n",
    "prob_adj = zzz @ zzz.t()\n",
    "for i in range(len(prob_adj)):\n",
    "    prob_adj[i][i] = 0\n",
    "\n",
    "K = 10\n",
    "P_K, R_K, F1_ = count_o2n_Acc_Recall(K, prob_adj.cpu(), link_new_labels_M)\n",
    "print(\"精确度：\", P_K)\n",
    "print(\"召回率：\", R_K)\n",
    "print(\"F1_：\", F1_)\n",
    "\n",
    "x_epoch = [i + 1 for i in range(len(y_val_auc))]\n",
    "drawLossVal(x_epoch, y_loss, \"loss\", \"LOSS_Experiment\", \"epoch\", \"auc\")\n",
    "drawLossVal(x_epoch, y_val_auc, \"val\", \"val_Experiment\", \"epoch\", \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34011a9d-b91f-43b2-9587-ce1f85280493",
   "metadata": {
    "tags": []
   },
   "source": [
    "# baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79df8e58-af6d-4472-9915-68895f0e079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- 超二部图结果 ----------\n",
      "超二部图_精确度： 0.17407407407407574\n",
      "超二部图_召回率： 0.3893713798358406\n",
      "超二部图_F1： 0.24058926004470269\n"
     ]
    }
   ],
   "source": [
    "# 超二部图结果\n",
    "print(\"-\" * 10, \"超二部图结果\", \"-\" * 10)\n",
    "K = 10\n",
    "prob_adj = cosinematrix(torch.tensor(np.array(hyperBip_id_vec_list))) # 先转ndarrays再转tensor更快\n",
    "for i in range(len(prob_adj)):\n",
    "    prob_adj[i][i] = 0\n",
    "P_K, R_K, F1 = count_o2n_Acc_Recall(K, prob_adj, link_new_labels_M)\n",
    "print(\"超二部图_精确度：\", P_K)\n",
    "print(\"超二部图_召回率：\", R_K)\n",
    "print(\"超二部图_F1：\", F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1084aa33-5a14-4f5b-882d-7a92dcaeb92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- deepwalk结果 ----------\n",
      "精确度： 0.06763468013467948\n",
      "召回率： 0.20806249372357044\n",
      "F1： 0.10208476216192701\n"
     ]
    }
   ],
   "source": [
    "# deepwalk结果\n",
    "print(\"-\" * 10, \"deepwalk结果\", \"-\" * 10)\n",
    "K = 10\n",
    "prob_adj = cosinematrix(torch.tensor(np.array(social_id_vec_list)))\n",
    "for i in range(len(prob_adj)):\n",
    "    prob_adj[i][i] = 0\n",
    "P_K, R_K, F1 = count_o2n_Acc_Recall(K, prob_adj, link_new_labels_M)\n",
    "print(\"精确度：\", P_K)\n",
    "print(\"召回率：\", R_K)\n",
    "print(\"F1：\", F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c009b4a7-c329-4686-97a3-d10729582403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- 异构超图结果 ----------\n",
      "精确度： 0.36832721552176023\n",
      "召回率： 0.7124537539541479\n",
      "F1： 0.4856046040655348\n"
     ]
    }
   ],
   "source": [
    "# 异构超图结果\n",
    "print(\"-\" * 10, \"异构超图结果\", \"-\" * 10)\n",
    "K = 10\n",
    "prob_adj = cosinematrix(torch.tensor(np.array(HeterHyper_id_vec_list)))\n",
    "for i in range(len(prob_adj)):\n",
    "    prob_adj[i][i] = 0\n",
    "P_K, R_K, F1 = count_o2n_Acc_Recall(K, prob_adj, link_new_labels_M)\n",
    "print(\"精确度：\", P_K)\n",
    "print(\"召回率：\", R_K)\n",
    "print(\"F1：\", F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3856ec53-38f2-4ed9-92e1-576171099fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afef3c94-16c9-40c5-bafe-61eadd2af600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
